{"$defs":{"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.carbonexporter.Config":{"additionalProperties":false,"description":"Config defines configuration for Carbon exporter.","markdownDescription":"# Carbon Exporter\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [contrib], [observiq], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe [Carbon](https://github.com/graphite-project/carbon) exporter supports\nCarbon's [plaintext\nprotocol](https://graphite.readthedocs.io/en/stable/feeding-carbon.html#the-plaintext-protocol).\n\n## Configuration\n\nThe following settings are required:\n\n- `endpoint` (default = `localhost:2003`): Address and port that the\n  exporter should send data to.\n- `timeout` (default = `5s`): Maximum duration allowed to connect\n  and send data to the configured `endpoint`.\n\nExample:\n\n```yaml\nexporters:\n  carbon:\n    # by default it will export to localhost:2003 using tcp\n  carbon/allsettings:\n    # use endpoint to specify alternative destinations for the exporter,\n    # the default is localhost:2003\n    endpoint: localhost:8080\n    # timeout is the maximum duration allowed to connecting and sending the\n    # data to the configured endpoint.\n    # The default is 5 seconds.\n    timeout: 10s\n```\n\nThe full list of settings exposed for this receiver are documented [here](./config.go)\nwith detailed sample configurations [here](./testdata/config.yaml).","properties":{"endpoint":{"description":"Endpoint specifies host and port to send metrics in the Carbon plaintext\nformat. The default value is defined by the DefaultEndpoint constant.","title":"endpoint","type":"string"},"timeout":{"description":"Timeout is the maximum duration allowed to connecting and sending the\ndata to the Carbon/Graphite backend.\nThe default value is defined by the DefaultSendTimeout constant.","title":"timeout","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.fileexporter.Config":{"additionalProperties":false,"description":"Config defines configuration for file exporter.","markdownDescription":"# File Exporter\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [alpha]: traces, metrics, logs   |\n| Distributions | [core], [contrib], [aws], [observiq], [splunk], [sumo] |\n\n[alpha]: https://github.com/open-telemetry/opentelemetry-collector#alpha\n[core]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nExporter supports the following featuresï¼š\n\n+ Support for writing pipeline data to a file.\n\n+ Support for rotation of telemetry files.\n\n+ Support for compressing the telemetry data before exporting.\n\n\nPlease note that there is no guarantee that exact field names will remain stable.\nThis intended for primarily for debugging Collector without setting up backends.\n\nThe official [opentelemetry-collector-contrib container](https://hub.docker.com/r/otel/opentelemetry-collector-contrib/tags#!) does not have a writable filesystem by default since it's built on the `scratch` layer.\nAs such, you will need to create a writable directory for the path, potentially by mounting writable volumes or creating a custom image.\n## Configuration options:\n\nThe following settings are required:\n\n- `path` [no default]: where to write information.\n\nThe following settings are optional:\n\n- `rotation` settings to rotate telemetry files.\n\n  - max_megabytes:  [default: 100]: the maximum size in megabytes of the telemetry file before it is rotated.\n  - max_days: [no default (unlimited)]: the maximum number of days to retain telemetry files based on the timestamp encoded in their filename.\n  - max_backups: [default: 100]: the maximum number of old telemetry files to retain.\n  - localtime : [default: false (use UTC)] whether or not the timestamps in backup files is formatted according to the host's local time.\n\n- `format`[default: json]: define the data format of encoded telemetry data. The setting can be overridden with `proto`.\n- `compression`[no default]: the compression algorithm used when exporting telemetry data to file. Supported compression algorithms:`zstd`\n- `flush_interval`[default: 1s]: `time.Duration` interval between flushes. See [time.ParseDuration](https://pkg.go.dev/time#ParseDuration) for valid formats. \nNOTE: a value without unit is in nanoseconds and `flush_interval` is ignored and writes are not buffered if `rotation` is set.\n\n## File Rotation\nTelemetry data is exported to a single file by default.\n`fileexporter` only enables file rotation when the user specifies `rotation:` in the config. However, if specified, related default settings would apply.\n\nTelemetry is first written to a file that exactly matches the `path` setting. \nWhen the file size exceeds `max_megabytes` or age exceeds `max_days`, the file will be rotated.\n\nWhen a file is rotated, **it is renamed by putting the current time in a timestamp**\nin the name immediately before the file's extension (or the end of the filename if there's no extension).\n**A new telemetry file will be created at the original `path`.**\n\nFor example, if your `path` is `data.json` and rotation is triggered, this file will be renamed to `data-2022-09-14T05-02-14.173.json`, and a new telemetry file created with `data.json`\n\n## File Compression\nTelemetry data is compressed according to the `compression` setting.\n`fileexporter` does not compress data by default. \n\nCurrently, `fileexporter` support the `zstd` compression algorithm, and we will support more compression algorithms in the future.\n\n##  File Format \n\nTelemetry data is encoded according to the `format` setting and then written to the file.\n\nWhen `format` is json and `compression` is none , telemetry data is written to file in JSON format. Each line in the file is a JSON object.\n\nOtherwise, when using `proto` format or any kind of encoding, each encoded object is preceded by 4 bytes (an unsigned 32 bit integer) which represent the number of bytes contained in the encoded object.When we need read the messages back in, we read the size, then read the bytes into a separate buffer, then parse from that buffer.\n\n\n## Example:\n\n```yaml\nexporters:\n  file/no_rotation:\n    path: ./foo\n\n  file/rotation_with_default_settings:\n    path: ./foo\n    rotation:\n\n  file/rotation_with_custom_settings:\n    path: ./foo\n    rotation:\n      max_megabytes: 10\n      max_days: 3\n      max_backups: 3\n      localtime: true\n    format: proto\n    compression: zstd\n\n  file/flush_every_5_seconds:\n    path: ./foo\n    flush_interval: 5\n```\n\n## Get Started in an existing cluster\nWe will follow the [documentation](https://opentelemetry.io/docs/k8s-operator/) to first install the operator in an existing cluster\nand then create an OpenTelemetry Collector (otelcol) instance, \nmounting an additional volume under `/data` under which the file exporter will write `metrics.json`:\n``` shell\nkubectl apply -f - \u003c\u003cEOF\napiVersion: opentelemetry.io/v1alpha1\nkind: OpenTelemetryCollector\nmetadata:\n  name: fileexporter\nspec:\n  config: |\n    receivers:\n      otlp:\n        protocols:\n          grpc:\n          http:\n    processors:\n\n    exporters:\n      logging:\n      file:\n        path: /data/metrics.json\n\n    service:\n      pipelines:\n        metrics:\n          receivers: [otlp]\n          processors: []\n          exporters: [logging,file]\n  volumes:\n    - name: file\n      emptyDir: {}\n  volumeMounts: \n    - name: file\n      mountPath: /data\nEOF\n```","properties":{"compression":{"description":"Compression Codec used to export telemetry data\nSupported compression algorithms:`zstd`","title":"compression","type":"string"},"flush_interval":{"description":"FlushInterval is the duration between flushes.\nSee time.ParseDuration for valid values.","title":"flush_interval","type":"string"},"format":{"description":"FormatType define the data format of encoded telemetry data\nOptions:\n- json[default]:  OTLP json bytes.\n- proto:  OTLP binary protobuf bytes.","title":"format","type":"string"},"path":{"description":"Path of the file to write to. Path is relative to current directory.","title":"path","type":"string"},"rotation":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.fileexporter.Rotation","description":"Rotation defines an option about rotation of telemetry files","title":"rotation"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.fileexporter.Rotation":{"additionalProperties":false,"description":"Rotation an option to rolling log files","properties":{"localtime":{"description":"LocalTime determines if the time used for formatting the timestamps in\nbackup files is the computer's local time.  The default is to use UTC\ntime.","title":"localtime","type":"boolean"},"max_backups":{"description":"MaxBackups is the maximum number of old log files to retain. The default\nis to 100 files.","title":"max_backups","type":"integer"},"max_days":{"description":"MaxDays is the maximum number of days to retain old log files based on the\ntimestamp encoded in their filename.  Note that a day is defined as 24\nhours and may not exactly correspond to calendar days due to daylight\nsavings, leap seconds, etc. The default is not to remove old log files\nbased on age.","title":"max_days","type":"integer"},"max_megabytes":{"description":"MaxMegabytes is the maximum size in megabytes of the file before it gets\nrotated. It defaults to 100 megabytes.","title":"max_megabytes","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.jaegerexporter.Config":{"additionalProperties":false,"description":"Config defines configuration for Jaeger gRPC exporter.","markdownDescription":"# Deprecated Jaeger gRPC Exporter\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [deprecated]: traces   |\n| Distributions | [core], [contrib], [redhat] |\n\n[deprecated]: https://github.com/open-telemetry/opentelemetry-collector#deprecated\n[core]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[redhat]: https://github.com/os-observability/redhat-opentelemetry-collector\n\u003c!-- end autogenerated section --\u003e\n\nThis exporter is being deprecated and will be removed in July 2023 as Jaeger support OTLP directly. \n\nExports data via gRPC to [Jaeger](https://www.jaegertracing.io/) destinations.\nBy default, this exporter requires TLS and offers queued retry capabilities.\n\n## Getting Started\n\nThe following settings are required:\n\n- `endpoint` (no default): host:port to which the exporter is going to send Jaeger trace data,\nusing the gRPC protocol. The valid syntax is described\n[here](https://github.com/grpc/grpc/blob/master/doc/naming.md)\n\nBy default, TLS is enabled and must be configured under `tls:`:\n\n- `insecure` (default = `false`): whether to enable client transport security for\n  the exporter's connection.\n\nAs a result, the following parameters are also required under `tls:`:\n\n- `cert_file` (no default): path to the TLS cert to use for TLS required connections. Should\n  only be used if `insecure` is set to false.\n- `key_file` (no default): path to the TLS key to use for TLS required connections. Should\n  only be used if `insecure` is set to false.\n\nExample:\n\n```yaml\nexporters:\n  jaeger:\n    endpoint: jaeger-all-in-one:14250\n    tls:\n      cert_file: file.cert\n      key_file: file.key\n  jaeger/2:\n    endpoint: jaeger-all-in-one:14250\n    tls:\n      insecure: true\n```\n\n## Advanced Configuration\n\nSeveral helper files are leveraged to provide additional capabilities automatically:\n\n- [gRPC settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/configgrpc/README.md)\n- [TLS and mTLS settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/configtls/README.md)\n- [Queuing, retry and timeout settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/exporter/exporterhelper/README.md)","properties":{"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth configuration for outgoing RPCs.","title":"auth"},"balancer_name":{"description":"Sets the balancer in grpclb_policy to discover the servers. Default is pick_first.\nhttps://github.com/grpc/grpc-go/blob/master/examples/features/load_balancing/README.md","title":"balancer_name","type":"string"},"compression":{"description":"The compression key for supported compression types within collector.","title":"compression","type":"string"},"endpoint":{"description":"The target to which the exporter is going to send traces or metrics,\nusing the gRPC protocol. The valid syntax is described at\nhttps://github.com/grpc/grpc/blob/master/doc/naming.md.","title":"endpoint","type":"string"},"headers":{"description":"The headers associated with gRPC requests.","patternProperties":{".*":{"type":"string"}},"title":"headers","type":"object"},"keepalive":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configgrpc.KeepaliveClientConfig","description":"The keepalive parameters for gRPC client. See grpc.WithKeepaliveParams.\n(https://godoc.org/google.golang.org/grpc#WithKeepaliveParams).","title":"keepalive"},"read_buffer_size":{"description":"ReadBufferSize for gRPC client. See grpc.WithReadBufferSize.\n(https://godoc.org/google.golang.org/grpc#WithReadBufferSize).","title":"read_buffer_size","type":"integer"},"retry_on_failure":{"$ref":"#/$defs/go.opentelemetry.io.collector.exporter.exporterhelper.RetrySettings","title":"retry_on_failure"},"sending_queue":{"$ref":"#/$defs/go.opentelemetry.io.collector.exporter.exporterhelper.QueueSettings","title":"sending_queue"},"timeout":{"description":"Timeout is the timeout for every attempt to send data to the backend.","title":"timeout","type":"string"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","description":"TLSSetting struct exposes TLS client configuration.","title":"tls"},"wait_for_ready":{"description":"WaitForReady parameter configures client to wait for ready state before sending data.\n(https://github.com/grpc/grpc/blob/master/doc/wait-for-ready.md)","title":"wait_for_ready","type":"boolean"},"write_buffer_size":{"description":"WriteBufferSize for gRPC gRPC. See grpc.WithWriteBufferSize.\n(https://godoc.org/google.golang.org/grpc#WithWriteBufferSize).","title":"write_buffer_size","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.jaegerthrifthttpexporter.Config":{"additionalProperties":false,"description":"Config defines configuration for Jaeger Thrift over HTTP exporter.","markdownDescription":"# Deprecated Jaeger Thrift Exporter\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [deprecated]: traces   |\n| Distributions | [contrib] |\n\n[deprecated]: https://github.com/open-telemetry/opentelemetry-collector#deprecated\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n\u003c!-- end autogenerated section --\u003e\n\nThis exporter is being deprecated and will be removed in July 2023 as Jaeger support OTLP directly.\n\nThis exporter supports sending trace data to [Jaeger](https://www.jaegertracing.io) over Thrift HTTP.\n\n*WARNING:* The [Jaeger gRPC Exporter](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter/jaegerexporter) is the recommended one for exporting traces from an OpenTelemetry Collector to Jaeger. This Jaeger Thrift Exporter should only be used to export traces to a Jaeger Collector that is unable to expose the [gRPC API](https://www.jaegertracing.io/docs/1.27/apis/#protobuf-via-grpc-stable).\n\n## Configuration\n\nThe following settings are required:\n\n- `endpoint` (no default): target to which the exporter is going to send Jaeger trace data,\nusing the Thrift HTTP protocol.\n\nThe following settings can be optionally configured:\n\n- `timeout` (default = 5s): the maximum time to wait for a HTTP request to complete\n- `headers` (no default): headers to be added to the HTTP request\n\nExample:\n\n```yaml\nexporters:\n  jaeger_thrift:\n    endpoint: \"http://jaeger.example.com/api/traces\"\n    timeout: 2s\n    headers:\n      added-entry: \"added value\"\n      dot.test: test\n```\n\nThe full list of settings exposed for this exporter are documented [here](config.go)\nwith detailed sample configurations [here](testdata/config.yaml).\n\nThis exporter also offers proxy support as documented\n[here](https://github.com/open-telemetry/opentelemetry-collector/tree/main/exporter#proxy-support).","properties":{"CustomRoundTripper":{"description":"Custom Round Tripper to allow for individual components to intercept HTTP requests","title":"CustomRoundTripper"},"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth configuration for outgoing HTTP calls.","title":"auth"},"compression":{"description":"The compression key for supported compression types within collector.","title":"compression","type":"string"},"endpoint":{"description":"The target URL to send data to (e.g.: http://some.url:9411/v1/traces).","title":"endpoint","type":"string"},"headers":{"description":"Additional headers attached to each HTTP request sent by the client.\nExisting header values are overwritten if collision happens.\nHeader values are opaque since they may be sensitive.","patternProperties":{".*":{"type":"string"}},"title":"headers","type":"object"},"idle_conn_timeout":{"description":"IdleConnTimeout is the maximum amount of time a connection will remain open before closing itself.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"idle_conn_timeout","type":"string"},"max_conns_per_host":{"description":"MaxConnsPerHost limits the total number of connections per host, including connections in the dialing,\nactive, and idle states.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_conns_per_host","type":"integer"},"max_idle_conns":{"description":"MaxIdleConns is used to set a limit to the maximum idle HTTP connections the client can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns","type":"integer"},"max_idle_conns_per_host":{"description":"MaxIdleConnsPerHost is used to set a limit to the maximum idle HTTP connections the host can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns_per_host","type":"integer"},"read_buffer_size":{"description":"ReadBufferSize for HTTP client. See http.Transport.ReadBufferSize.","title":"read_buffer_size","type":"integer"},"timeout":{"description":"Timeout parameter configures `http.Client.Timeout`.","title":"timeout","type":"string"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","description":"TLSSetting struct exposes TLS client configuration.","title":"tls"},"write_buffer_size":{"description":"WriteBufferSize for HTTP client. See http.Transport.WriteBufferSize.","title":"write_buffer_size","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.kafkaexporter.AWSMSKConfig":{"additionalProperties":false,"description":"AWSMSKConfig defines the additional SASL authentication measures needed to use AWS_MSK_IAM mechanism","properties":{"broker_addr":{"description":"BrokerAddr is the client is connecting to in order to perform the auth required","title":"broker_addr","type":"string"},"region":{"description":"Region is the AWS region the MSK cluster is based in","title":"region","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.kafkaexporter.Authentication":{"additionalProperties":false,"description":"Authentication defines authentication.","markdownDescription":"# Kafka Exporter\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: traces, metrics, logs   |\n| Distributions | [contrib], [aws], [observiq], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nKafka exporter exports logs, metrics, and traces to Kafka. This exporter uses a synchronous producer\nthat blocks and does not batch messages, therefore it should be used with batch and queued retry\nprocessors for higher throughput and resiliency. Message payload encoding is configurable.\n\nThe following settings are required:\n- `protocol_version` (no default): Kafka protocol version e.g. 2.0.0\n\nThe following settings can be optionally configured:\n- `brokers` (default = localhost:9092): The list of kafka brokers\n- `topic` (default = otlp_spans for traces, otlp_metrics for metrics, otlp_logs for logs): The name of the kafka topic to export to.\n- `encoding` (default = otlp_proto): The encoding of the traces sent to kafka. All available encodings:\n  - `otlp_proto`: payload is Protobuf serialized from `ExportTraceServiceRequest` if set as a traces exporter or `ExportMetricsServiceRequest` for metrics or `ExportLogsServiceRequest` for logs.\n  - `otlp_json`:  ** EXPERIMENTAL ** payload is JSON serialized from `ExportTraceServiceRequest` if set as a traces exporter or `ExportMetricsServiceRequest` for metrics or `ExportLogsServiceRequest` for logs. \n  - The following encodings are valid *only* for **traces**.\n    - `jaeger_proto`: the payload is serialized to a single Jaeger proto `Span`, and keyed by TraceID.\n    - `jaeger_json`: the payload is serialized to a single Jaeger JSON Span using `jsonpb`, and keyed by TraceID.\\\n  - The following encodings are valid *only* for **logs**.\n    - `raw`: if the log record body is a byte array, it is sent as is. Otherwise, it is serialized to JSON. Resource and record attributes are discarded.\n- `auth`\n  - `plain_text`\n    - `username`: The username to use.\n    - `password`: The password to use\n  - `sasl`\n    - `username`: The username to use.\n    - `password`: The password to use\n    - `mechanism`: The sasl mechanism to use (SCRAM-SHA-256, SCRAM-SHA-512, AWS_MSK_IAM or PLAIN)\n    - `aws_msk.region`: AWS Region in case of AWS_MSK_IAM mechanism\n    - `aws_msk.broker_addr`: MSK Broker address in case of AWS_MSK_IAM mechanism\n  - `tls`\n    - `ca_file`: path to the CA cert. For a client this verifies the server certificate. Should\n      only be used if `insecure` is set to true.\n    - `cert_file`: path to the TLS cert to use for TLS required connections. Should\n      only be used if `insecure` is set to true.\n    - `key_file`: path to the TLS key to use for TLS required connections. Should\n      only be used if `insecure` is set to true.\n    - `insecure` (default = false): Disable verifying the server's certificate chain and host \n      name (`InsecureSkipVerify` in the tls config)\n    - `server_name_override`: ServerName indicates the name of the server requested by the client\n      in order to support virtual hosting.\n  - `kerberos`\n    - `service_name`: Kerberos service name\n    - `realm`: Kerberos realm\n    - `use_keytab`:  Use of keytab instead of password, if this is true, keytab file will be used instead of password\n    - `username`: The Kerberos username used for authenticate with KDC\n    - `password`: The Kerberos password used for authenticate with KDC\n    - `config_file`: Path to Kerberos configuration. i.e /etc/krb5.conf\n    - `keytab_file`: Path to keytab file. i.e /etc/security/kafka.keytab\n- `metadata`\n  - `full` (default = true): Whether to maintain a full set of metadata. \n                                    When disabled the client does not make the initial request to broker at the startup.\n  - `retry`\n    - `max` (default = 3): The number of retries to get metadata\n    - `backoff` (default = 250ms): How long to wait between metadata retries\n- `timeout` (default = 5s): Is the timeout for every attempt to send data to the backend.\n- `retry_on_failure`\n  - `enabled` (default = true)\n  - `initial_interval` (default = 5s): Time to wait after the first failure before retrying; ignored if `enabled` is `false`\n  - `max_interval` (default = 30s): Is the upper bound on backoff; ignored if `enabled` is `false`\n  - `max_elapsed_time` (default = 120s): Is the maximum amount of time spent trying to send a batch; ignored if `enabled` is `false`\n- `sending_queue`\n  - `enabled` (default = true)\n  - `num_consumers` (default = 10): Number of consumers that dequeue batches; ignored if `enabled` is `false`\n  - `queue_size` (default = 1000): Maximum number of batches kept in memory before dropping data; ignored if `enabled` is `false`;\n  User should calculate this as `num_seconds * requests_per_second` where:\n    - `num_seconds` is the number of seconds to buffer in case of a backend outage\n    - `requests_per_second` is the average number of requests per seconds.\n- `producer`\n  - `max_message_bytes` (default = 1000000) the maximum permitted size of a message in bytes\n  - `required_acks` (default = 1) controls when a message is regarded as transmitted.   https://pkg.go.dev/github.com/Shopify/sarama@v1.30.0#RequiredAcks\n  - `compression` (default = 'none') the compression used when producing messages to kafka. The options are: `none`, `gzip`, `snappy`, `lz4`, and `zstd` https://pkg.go.dev/github.com/Shopify/sarama@v1.30.0#CompressionCodec\n  - `flush_max_messages` (default = 0) The maximum number of messages the producer will send in a single broker request.\n\nExample configuration:\n\n```yaml\nexporters:\n  kafka:\n    brokers:\n      - localhost:9092\n    protocol_version: 2.0.0\n```","properties":{"kerberos":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.kafkaexporter.KerberosConfig","title":"kerberos"},"plain_text":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.kafkaexporter.PlainTextConfig","title":"plain_text"},"sasl":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.kafkaexporter.SASLConfig","title":"sasl"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","title":"tls"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.kafkaexporter.Config":{"additionalProperties":false,"description":"Config defines configuration for Kafka exporter.","markdownDescription":"# Kafka Exporter\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: traces, metrics, logs   |\n| Distributions | [contrib], [aws], [observiq], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nKafka exporter exports logs, metrics, and traces to Kafka. This exporter uses a synchronous producer\nthat blocks and does not batch messages, therefore it should be used with batch and queued retry\nprocessors for higher throughput and resiliency. Message payload encoding is configurable.\n\nThe following settings are required:\n- `protocol_version` (no default): Kafka protocol version e.g. 2.0.0\n\nThe following settings can be optionally configured:\n- `brokers` (default = localhost:9092): The list of kafka brokers\n- `topic` (default = otlp_spans for traces, otlp_metrics for metrics, otlp_logs for logs): The name of the kafka topic to export to.\n- `encoding` (default = otlp_proto): The encoding of the traces sent to kafka. All available encodings:\n  - `otlp_proto`: payload is Protobuf serialized from `ExportTraceServiceRequest` if set as a traces exporter or `ExportMetricsServiceRequest` for metrics or `ExportLogsServiceRequest` for logs.\n  - `otlp_json`:  payload is JSON serialized from `ExportTraceServiceRequest` if set as a traces exporter or `ExportMetricsServiceRequest` for metrics or `ExportLogsServiceRequest` for logs. \n  - The following encodings are valid *only* for **traces**.\n    - `jaeger_proto`: the payload is serialized to a single Jaeger proto `Span`, and keyed by TraceID.\n    - `jaeger_json`: the payload is serialized to a single Jaeger JSON Span using `jsonpb`, and keyed by TraceID.\\\n  - The following encodings are valid *only* for **logs**.\n    - `raw`: if the log record body is a byte array, it is sent as is. Otherwise, it is serialized to JSON. Resource and record attributes are discarded.\n- `auth`\n  - `plain_text`\n    - `username`: The username to use.\n    - `password`: The password to use\n  - `sasl`\n    - `username`: The username to use.\n    - `password`: The password to use\n    - `mechanism`: The sasl mechanism to use (SCRAM-SHA-256, SCRAM-SHA-512, AWS_MSK_IAM or PLAIN)\n    - `aws_msk.region`: AWS Region in case of AWS_MSK_IAM mechanism\n    - `aws_msk.broker_addr`: MSK Broker address in case of AWS_MSK_IAM mechanism\n  - `tls`\n    - `ca_file`: path to the CA cert. For a client this verifies the server certificate. Should\n      only be used if `insecure` is set to true.\n    - `cert_file`: path to the TLS cert to use for TLS required connections. Should\n      only be used if `insecure` is set to true.\n    - `key_file`: path to the TLS key to use for TLS required connections. Should\n      only be used if `insecure` is set to true.\n    - `insecure` (default = false): Disable verifying the server's certificate chain and host \n      name (`InsecureSkipVerify` in the tls config)\n    - `server_name_override`: ServerName indicates the name of the server requested by the client\n      in order to support virtual hosting.\n  - `kerberos`\n    - `service_name`: Kerberos service name\n    - `realm`: Kerberos realm\n    - `use_keytab`:  Use of keytab instead of password, if this is true, keytab file will be used instead of password\n    - `username`: The Kerberos username used for authenticate with KDC\n    - `password`: The Kerberos password used for authenticate with KDC\n    - `config_file`: Path to Kerberos configuration. i.e /etc/krb5.conf\n    - `keytab_file`: Path to keytab file. i.e /etc/security/kafka.keytab\n- `metadata`\n  - `full` (default = true): Whether to maintain a full set of metadata. \n                                    When disabled the client does not make the initial request to broker at the startup.\n  - `retry`\n    - `max` (default = 3): The number of retries to get metadata\n    - `backoff` (default = 250ms): How long to wait between metadata retries\n- `timeout` (default = 5s): Is the timeout for every attempt to send data to the backend.\n- `retry_on_failure`\n  - `enabled` (default = true)\n  - `initial_interval` (default = 5s): Time to wait after the first failure before retrying; ignored if `enabled` is `false`\n  - `max_interval` (default = 30s): Is the upper bound on backoff; ignored if `enabled` is `false`\n  - `max_elapsed_time` (default = 120s): Is the maximum amount of time spent trying to send a batch; ignored if `enabled` is `false`\n- `sending_queue`\n  - `enabled` (default = true)\n  - `num_consumers` (default = 10): Number of consumers that dequeue batches; ignored if `enabled` is `false`\n  - `queue_size` (default = 1000): Maximum number of batches kept in memory before dropping data; ignored if `enabled` is `false`;\n  User should calculate this as `num_seconds * requests_per_second` where:\n    - `num_seconds` is the number of seconds to buffer in case of a backend outage\n    - `requests_per_second` is the average number of requests per seconds.\n- `producer`\n  - `max_message_bytes` (default = 1000000) the maximum permitted size of a message in bytes\n  - `required_acks` (default = 1) controls when a message is regarded as transmitted.   https://pkg.go.dev/github.com/Shopify/sarama@v1.30.0#RequiredAcks\n  - `compression` (default = 'none') the compression used when producing messages to kafka. The options are: `none`, `gzip`, `snappy`, `lz4`, and `zstd` https://pkg.go.dev/github.com/Shopify/sarama@v1.30.0#CompressionCodec\n  - `flush_max_messages` (default = 0) The maximum number of messages the producer will send in a single broker request.\n\nExample configuration:\n\n```yaml\nexporters:\n  kafka:\n    brokers:\n      - localhost:9092\n    protocol_version: 2.0.0\n```","properties":{"auth":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.kafkaexporter.Authentication","description":"Authentication defines used authentication mechanism.","title":"auth"},"brokers":{"description":"The list of kafka brokers (default localhost:9092)","items":{"type":"string"},"title":"brokers","type":"array"},"encoding":{"description":"Encoding of messages (default \"otlp_proto\")","title":"encoding","type":"string"},"metadata":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.kafkaexporter.Metadata","description":"Metadata is the namespace for metadata management properties used by the\nClient, and shared by the Producer/Consumer.","title":"metadata"},"producer":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.kafkaexporter.Producer","description":"Producer is the namespaces for producer properties used only by the Producer","title":"producer"},"protocol_version":{"description":"Kafka protocol version","title":"protocol_version","type":"string"},"retry_on_failure":{"$ref":"#/$defs/go.opentelemetry.io.collector.exporter.exporterhelper.RetrySettings","title":"retry_on_failure"},"sending_queue":{"$ref":"#/$defs/go.opentelemetry.io.collector.exporter.exporterhelper.QueueSettings","title":"sending_queue"},"timeout":{"description":"Timeout is the timeout for every attempt to send data to the backend.","title":"timeout","type":"string"},"topic":{"description":"The name of the kafka topic to export to (default otlp_spans for traces, otlp_metrics for metrics)","title":"topic","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.kafkaexporter.KerberosConfig":{"additionalProperties":false,"description":"KerberosConfig defines kereros configuration.","properties":{"config_file":{"title":"config_file","type":"string"},"keytab_file":{"title":"keytab_file","type":"string"},"password":{"title":"password","type":"string"},"realm":{"title":"realm","type":"string"},"service_name":{"title":"service_name","type":"string"},"use_keytab":{"title":"use_keytab","type":"boolean"},"username":{"title":"username","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.kafkaexporter.Metadata":{"additionalProperties":false,"description":"Metadata defines configuration for retrieving metadata from the broker.","properties":{"full":{"description":"Whether to maintain a full set of metadata for all topics, or just\nthe minimal set that has been necessary so far. The full set is simpler\nand usually more convenient, but can take up a substantial amount of\nmemory if you have many topics and partitions. Defaults to true.","title":"full","type":"boolean"},"retry":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.kafkaexporter.MetadataRetry","description":"Retry configuration for metadata.\nThis configuration is useful to avoid race conditions when broker\nis starting at the same time as collector.","title":"retry"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.kafkaexporter.MetadataRetry":{"additionalProperties":false,"description":"MetadataRetry defines retry configuration for Metadata.","properties":{"backoff":{"description":"How long to wait for leader election to occur before retrying\n(default 250ms). Similar to the JVM's `retry.backoff.ms`.","title":"backoff","type":"string"},"max":{"description":"The total number of times to retry a metadata request when the\ncluster is in the middle of a leader election or at startup (default 3).","title":"max","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.kafkaexporter.PlainTextConfig":{"additionalProperties":false,"description":"PlainTextConfig defines plaintext authentication.","properties":{"password":{"title":"password","type":"string"},"username":{"title":"username","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.kafkaexporter.Producer":{"additionalProperties":false,"description":"Producer defines configuration for producer","properties":{"compression":{"description":"Compression Codec used to produce messages\nhttps://pkg.go.dev/github.com/Shopify/sarama@v1.30.0#CompressionCodec\nThe options are: 'none', 'gzip', 'snappy', 'lz4', and 'zstd'","title":"compression","type":"string"},"flush_max_messages":{"description":"The maximum number of messages the producer will send in a single\nbroker request. Defaults to 0 for unlimited. Similar to\n`queue.buffering.max.messages` in the JVM producer.","title":"flush_max_messages","type":"integer"},"max_message_bytes":{"description":"Maximum message bytes the producer will accept to produce.","title":"max_message_bytes","type":"integer"},"required_acks":{"description":"RequiredAcks Number of acknowledgements required to assume that a message has been sent.\nhttps://pkg.go.dev/github.com/Shopify/sarama@v1.30.0#RequiredAcks\nThe options are:\n  0 -\u003e NoResponse.  doesn't send any response\n  1 -\u003e WaitForLocal. waits for only the local commit to succeed before responding ( default )\n  -1 -\u003e WaitForAll. waits for all in-sync replicas to commit before responding.","title":"required_acks","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.kafkaexporter.SASLConfig":{"additionalProperties":false,"description":"SASLConfig defines the configuration for the SASL authentication.","properties":{"aws_msk":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.kafkaexporter.AWSMSKConfig","title":"aws_msk"},"mechanism":{"description":"SASL Mechanism to be used, possible values are: (PLAIN, AWS_MSK_IAM, SCRAM-SHA-256 or SCRAM-SHA-512).","title":"mechanism","type":"string"},"password":{"description":"Password to be used on authentication","title":"password","type":"string"},"username":{"description":"Username to be used on authentication","title":"username","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.loadbalancingexporter.Config":{"additionalProperties":false,"description":"Config defines configuration for the exporter.","markdownDescription":"# Trace ID/Service-name aware load-balancing exporter\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: traces, logs   |\n| Distributions | [contrib], [observiq], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThis is an exporter that will consistently export spans and logs depending on the `routing_key` configured. If no `routing_key` is configured, the default routing mechanism is `traceID`. This means that spans belonging to the same `traceID` (or `service.name`, when `service` is used as the `routing_key`) will be sent to the same backend.\n\nIt requires a source of backend information to be provided: static, with a fixed list of backends, or DNS, with a hostname that will resolve to all IP addresses to use. The DNS resolver will periodically check for updates.\n\nNote that either the Trace ID or Service name is used for the decision on which backend to use: the actual backend load isn't taken into consideration. Even though this load-balancer won't do round-robin balancing of the batches, the load distribution should be very similar among backends with a standard deviation under 5% at the current configuration.\n\nThis load balancer is especially useful for backends configured with tail-based samplers or red-metrics-collectors, which make a decision based on the view of the full trace.\n\nWhen a list of backends is updated, around 1/n of the space will be changed, so that the same trace ID might be directed to a different backend, where n is the number of backends. This should be stable enough for most cases, and the higher the number of backends, the less disruption it should cause. Still, if routing stability is important for your use case and your list of backends are constantly changing, consider using the `groupbytrace` processor. This way, traces are dispatched atomically to this exporter, and the same decision about the backend is made for the trace as a whole.\n\nThis also supports service name based exporting for traces. If you have two or more collectors that collect traces and then use spanmetrics processor to generate metrics and push to prometheus, there is a high chance of facing label collisions on prometheus if the routing is based on `traceID` because every collector sees the `service+operation` label. With service name based routing, each collector can only see one service name and can push metrics without any label collisions.\n## Configuration\n\nRefer to [config.yaml](./testdata/config.yaml) for detailed examples on using the processor.\n\n* The `otlp` property configures the template used for building the OTLP exporter. Refer to the OTLP Exporter documentation for information on which options are available. Note that the `endpoint` property should not be set and will be overridden by this exporter with the backend endpoint.\n* The `resolver` accepts either a `static` node, or a `dns`. If both are specified, `dns` takes precedence.\n* The `hostname` property inside a `dns` node specifies the hostname to query in order to obtain the list of IP addresses.\n* The `dns` node also accepts the following optional properties:\n  * `hostname` DNS hostname to resolve.\n  * `port` port to be used for exporting the traces to the IP addresses resolved from `hostname`. If `port` is not specified, the default port 4317 is used.\n  * `interval` resolver interval in go-Duration format, e.g. `5s`, `1d`, `30m`. If not specified, `5s` will be used.\n  * `timeout` resolver timeout in go-Duration format, e.g. `5s`, `1d`, `30m`. If not specified, `1s` will be used.\n* The `routing_key` property is used to route spans to exporters based on different parameters. This functionality is currently enabled only for `trace` pipeline types. It supports one of the following values:\n    * `service`: exports spans based on their service name. This is useful when using processors like the span metrics, so all spans for each service are sent to consistent collector instances for metric collection. Otherwise, metrics for the same services are sent to different collectors, making aggregations inaccurate. \n    * `traceID` (default): exports spans based on their `traceID`.\n    * If not configured, defaults to `traceID` based routing.\n\nSimple example\n```yaml\nreceivers:\n  otlp:\n    protocols:\n      grpc:\n        endpoint: localhost:4317\n\nprocessors:\n\nexporters:\n  logging:\n  loadbalancing:\n    routing_key: \"service\"\n    protocol:\n      otlp:\n        # all options from the OTLP exporter are supported\n        # except the endpoint\n        timeout: 1s\n    resolver:\n      static:\n        hostnames:\n        - backend-1:4317\n        - backend-2:4317\n        - backend-3:4317\n        - backend-4:4317\n\nservice:\n  pipelines:\n    traces:\n      receivers:\n        - otlp\n      processors: []\n      exporters:\n        - loadbalancing\n    logs:\n      receivers:\n        - otlp\n      processors: []\n      exporters:\n        - loadbalancing\n```\n\nFor testing purposes, the following configuration can be used, where both the load balancer and all backends are running locally:\n```yaml\nreceivers:\n  otlp/loadbalancer:\n    protocols:\n      grpc:\n        endpoint: localhost:4317\n  otlp/backend-1:\n    protocols:\n      grpc:\n        endpoint: localhost:55690\n  otlp/backend-2:\n    protocols:\n      grpc:\n        endpoint: localhost:55700\n  otlp/backend-3:\n    protocols:\n      grpc:\n        endpoint: localhost:55710\n  otlp/backend-4:\n    protocols:\n      grpc:\n        endpoint: localhost:55720\n\nprocessors:\n\nexporters:\n  logging:\n  loadbalancing:\n    protocol:\n      otlp:\n        timeout: 1s\n        tls:\n          insecure: true\n    resolver:\n      static:\n        hostnames:\n        - localhost:55690\n        - localhost:55700\n        - localhost:55710\n        - localhost:55720\n\nservice:\n  pipelines:\n    traces/loadbalancer:\n      receivers:\n        - otlp/loadbalancer\n      processors: []\n      exporters:\n        - loadbalancing\n\n    traces/backend-1:\n      receivers:\n        - otlp/backend-1\n      processors: []\n      exporters:\n        - logging\n\n    traces/backend-2:\n      receivers:\n        - otlp/backend-2\n      processors: []\n      exporters:\n        - logging\n\n    traces/backend-3:\n      receivers:\n        - otlp/backend-3\n      processors: []\n      exporters:\n        - logging\n\n    traces/backend-4:\n      receivers:\n        - otlp/backend-4\n      processors: []\n      exporters:\n        - logging\n\n    logs/loadbalancer:\n      receivers:\n        - otlp/loadbalancer\n      processors: []\n      exporters:\n        - loadbalancing\n    logs/backend-1:\n      receivers:\n        - otlp/backend-1\n      processors: []\n      exporters:\n        - logging\n    logs/backend-2:\n      receivers:\n        - otlp/backend-2\n      processors: []\n      exporters:\n        - logging\n    logs/backend-3:\n      receivers:\n        - otlp/backend-3\n      processors: []\n      exporters:\n        - logging\n    logs/backend-4:\n      receivers:\n        - otlp/backend-4\n      processors: []\n      exporters:\n        - logging\n```\n\n## Metrics\n\nThe following metrics are recorded by this processor:\n\n* `otelcol_loadbalancer_num_resolutions` represents the total number of resolutions performed by the resolver specified in the tag `resolver`, split by their outcome (`success=true|false`). For the static resolver, this should always be `1` with the tag `success=true`.\n* `otelcol_loadbalancer_num_backends` informs how many backends are currently in use. It should always match the number of items specified in the configuration file in case the `static` resolver is used, and should eventually (seconds) catch up with the DNS changes. Note that DNS caches that might exist between the load balancer and the record authority will influence how long it takes for the load balancer to see the change.\n* `otelcol_loadbalancer_num_backend_updates` records how many of the resolutions resulted in a new list of backends. Use this information to understand how frequent your backend updates are and how often the ring is rebalanced. If the DNS hostname is always returning the same list of IP addresses but this metric keeps increasing, it might indicate a bug in the load balancer.\n* `otelcol_loadbalancer_backend_latency` measures the latency for each backend.\n* `otelcol_loadbalancer_backend_outcome` counts what the outcomes were for each endpoint, `success=true|false`.","properties":{"protocol":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.loadbalancingexporter.Protocol","title":"protocol"},"resolver":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.loadbalancingexporter.ResolverSettings","title":"resolver"},"routing_key":{"title":"routing_key","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.loadbalancingexporter.DNSResolver":{"additionalProperties":false,"description":"DNSResolver defines the configuration for the DNS resolver","properties":{"hostname":{"title":"hostname","type":"string"},"interval":{"title":"interval","type":"string"},"port":{"title":"port","type":"string"},"timeout":{"title":"timeout","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.loadbalancingexporter.Protocol":{"additionalProperties":false,"description":"Protocol holds the individual protocol-specific settings.","properties":{"otlp":{"$ref":"#/$defs/go.opentelemetry.io.collector.exporter.otlpexporter.Config","title":"otlp"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.loadbalancingexporter.ResolverSettings":{"additionalProperties":false,"description":"ResolverSettings defines the configurations for the backend resolver","properties":{"dns":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.loadbalancingexporter.DNSResolver","title":"dns"},"static":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.loadbalancingexporter.StaticResolver","title":"static"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.loadbalancingexporter.StaticResolver":{"additionalProperties":false,"description":"StaticResolver defines the configuration for the resolver providing a fixed list of backends","properties":{"hostnames":{"items":{"type":"string"},"title":"hostnames","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.opencensusexporter.Config":{"additionalProperties":false,"description":"Config defines configuration for OpenCensus exporter.","markdownDescription":"# OpenCensus gRPC Exporter\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: traces, metrics   |\n| Distributions | [contrib], [observiq] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nExports traces and/or metrics via gRPC using\n[OpenCensus](https://opencensus.io/) format.\n\n## Getting Started\n\nThe following settings are required:\n\n- `endpoint` (no default): host:port to which the exporter is going to send Jaeger trace data,\nusing the gRPC protocol. The valid syntax is described\n[here](https://github.com/grpc/grpc/blob/master/doc/naming.md)\n\nBy default, TLS is enabled and must be configured under `tls:`:\n\n- `insecure` (default = `false`): whether to enable client transport security for\n  the exporter's connection.\n\nAs a result, the following parameters are also required under `tls:`:\n\n- `cert_file` (no default): path to the TLS cert to use for TLS required connections. Should\n  only be used if `insecure` is set to false.\n- `key_file` (no default): path to the TLS key to use for TLS required connections. Should\n  only be used if `insecure` is set to false.\n\nExample:\n\n```yaml\nexporters:\n  opencensus:\n    endpoint: opencensus2:55678\n    tls:\n      cert_file: file.cert\n      key_file: file.key\n  opencensus/2:\n    endpoint: opencensus2:55678\n    tls:\n      insecure: true\n```\n\n## Advanced Configuration\n\nSeveral helper files are leveraged to provide additional capabilities automatically:\n\n- [gRPC settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/configgrpc/README.md)\n- [TLS and mTLS settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/configtls/README.md)\n- [Queuing, retry and timeout settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/exporter/exporterhelper/README.md)","properties":{"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth configuration for outgoing RPCs.","title":"auth"},"balancer_name":{"description":"Sets the balancer in grpclb_policy to discover the servers. Default is pick_first.\nhttps://github.com/grpc/grpc-go/blob/master/examples/features/load_balancing/README.md","title":"balancer_name","type":"string"},"compression":{"description":"The compression key for supported compression types within collector.","title":"compression","type":"string"},"endpoint":{"description":"The target to which the exporter is going to send traces or metrics,\nusing the gRPC protocol. The valid syntax is described at\nhttps://github.com/grpc/grpc/blob/master/doc/naming.md.","title":"endpoint","type":"string"},"headers":{"description":"The headers associated with gRPC requests.","patternProperties":{".*":{"type":"string"}},"title":"headers","type":"object"},"keepalive":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configgrpc.KeepaliveClientConfig","description":"The keepalive parameters for gRPC client. See grpc.WithKeepaliveParams.\n(https://godoc.org/google.golang.org/grpc#WithKeepaliveParams).","title":"keepalive"},"num_workers":{"description":"The number of workers that send the gRPC requests.","title":"num_workers","type":"integer"},"read_buffer_size":{"description":"ReadBufferSize for gRPC client. See grpc.WithReadBufferSize.\n(https://godoc.org/google.golang.org/grpc#WithReadBufferSize).","title":"read_buffer_size","type":"integer"},"retry_on_failure":{"$ref":"#/$defs/go.opentelemetry.io.collector.exporter.exporterhelper.RetrySettings","title":"retry_on_failure"},"sending_queue":{"$ref":"#/$defs/go.opentelemetry.io.collector.exporter.exporterhelper.QueueSettings","title":"sending_queue"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","description":"TLSSetting struct exposes TLS client configuration.","title":"tls"},"wait_for_ready":{"description":"WaitForReady parameter configures client to wait for ready state before sending data.\n(https://github.com/grpc/grpc/blob/master/doc/wait-for-ready.md)","title":"wait_for_ready","type":"boolean"},"write_buffer_size":{"description":"WriteBufferSize for gRPC gRPC. See grpc.WithWriteBufferSize.\n(https://godoc.org/google.golang.org/grpc#WithWriteBufferSize).","title":"write_buffer_size","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.parquetexporter.Config":{"additionalProperties":false,"markdownDescription":"# Parquet File Exporter\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [development]: traces, metrics, logs   |\n| Distributions | [contrib] |\n\n[development]: https://github.com/open-telemetry/opentelemetry-collector#development\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n\u003c!-- end autogenerated section --\u003e\n\nSends pipeline data to Parquet files.\n\n## Configuration\n\nThe following configuration options are required:\n\n- `path` (no default): Export Parquet file path.\n\nThe following configuration options can also be configured:\n\nTODO\n\nExample:\n\n```yaml\nexporters:\n  parquet:\n    path: /var/output/log.parquet\n```\n\nThe full list of settings exposed for this exporter is going to be documented later\nwith detailed sample configurations [here](testdata/config.yaml).","properties":{"path":{"title":"path","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.prometheusexporter.Config":{"additionalProperties":false,"description":"Config defines configuration for Prometheus exporter.","markdownDescription":"# Prometheus Exporter\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [core], [contrib], [aws], [observiq], [redhat], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[core]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[redhat]: https://github.com/os-observability/redhat-opentelemetry-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nExports data in the [Prometheus format](https://prometheus.io/docs/concepts/data_model/), which allows it to be scraped by a [Prometheus](https://prometheus.io/) server.\n\n## Getting Started\n\nThe following settings are required:\n\n- `endpoint` (no default): the address on which metrics will be exposed, using path `/metrics`. For full list of `HTTPServerSettings` refer [here](https://github.com/open-telemetry/opentelemetry-collector/tree/main/config/confighttp).\n\nThe following settings can be optionally configured:\n\n- `const_labels` (no default): key/values that are applied for every exported metric.\n- `namespace` (no default): if set, exports metrics under the provided value.\n- `send_timestamps` (default = `false`): if true, sends the timestamp of the underlying metric sample in the response.\n- `metric_expiration` (default = `5m`): defines how long metrics are exposed without updates\n- `resource_to_telemetry_conversion`\n  - `enabled` (default = false): If `enabled` is `true`, all the resource attributes will be converted to metric labels by default.\n- `enable_open_metrics`: (default = `false`): If true, metrics will be exported using the OpenMetrics format. Exemplars are only exported in the OpenMetrics format, and only for histogram and monotonic sum (i.e. counter) metrics.\n\nExample:\n\n```yaml\nexporters:\n  prometheus:\n    endpoint: \"1.2.3.4:1234\"\n    tls:\n      ca_file: \"/path/to/ca.pem\"\n      cert_file: \"/path/to/cert.pem\"\n      key_file: \"/path/to/key.pem\"\n    namespace: test-space\n    const_labels:\n      label1: value1\n      \"another label\": spaced value\n    send_timestamps: true\n    metric_expiration: 180m\n    enable_open_metrics: true\n    resource_to_telemetry_conversion:\n      enabled: true\n```\n\nGiven the example, metrics will be available at `https://1.2.3.4:1234/metrics`.\n\n## Metric names and labels normalization\n\nOpenTelemetry metric names and attributes are normalized to be compliant with Prometheus naming rules. [Details on this normalization process are described in the Prometheus translator module](../../pkg/translator/prometheus/).","properties":{"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth for this receiver","title":"auth"},"const_labels":{"$ref":"#/$defs/github.com.prometheus.client_golang.prometheus.Labels","description":"ConstLabels are values that are applied for every exported metric.","title":"const_labels"},"cors":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.confighttp.CORSSettings","description":"CORS configures the server for HTTP cross-origin resource sharing (CORS).","title":"cors"},"enable_open_metrics":{"description":"EnableOpenMetrics enables the use of the OpenMetrics encoding option for the prometheus exporter.","title":"enable_open_metrics","type":"boolean"},"endpoint":{"description":"Endpoint configures the listening address for the server.","title":"endpoint","type":"string"},"include_metadata":{"description":"IncludeMetadata propagates the client metadata from the incoming requests to the downstream consumers\nExperimental: *NOTE* this option is subject to change or removal in the future.","title":"include_metadata","type":"boolean"},"max_request_body_size":{"description":"MaxRequestBodySize sets the maximum request body size in bytes","title":"max_request_body_size","type":"integer"},"metric_expiration":{"description":"MetricExpiration defines how long metrics are kept without updates","title":"metric_expiration","type":"string"},"namespace":{"description":"Namespace if set, exports metrics under the provided value.","title":"namespace","type":"string"},"resource_to_telemetry_conversion":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.pkg.resourcetotelemetry.Settings","description":"ResourceToTelemetrySettings defines configuration for converting resource attributes to metric labels.","title":"resource_to_telemetry_conversion"},"response_headers":{"description":"Additional headers attached to each HTTP response sent to the client.\nHeader values are opaque since they may be sensitive.","patternProperties":{".*":{"type":"string"}},"title":"response_headers","type":"object"},"send_timestamps":{"description":"SendTimestamps will send the underlying scrape timestamp with the export","title":"send_timestamps","type":"boolean"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSServerSetting","description":"TLSSetting struct exposes TLS client configuration.","title":"tls"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.prometheusremotewriteexporter.Config":{"additionalProperties":false,"description":"Config defines configuration for Remote Write exporter.","properties":{"CustomRoundTripper":{"description":"Custom Round Tripper to allow for individual components to intercept HTTP requests","title":"CustomRoundTripper"},"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth configuration for outgoing HTTP calls.","title":"auth"},"compression":{"description":"The compression key for supported compression types within collector.","title":"compression","type":"string"},"endpoint":{"description":"The target URL to send data to (e.g.: http://some.url:9411/v1/traces).","title":"endpoint","type":"string"},"export_created_metric":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.prometheusremotewriteexporter.CreatedMetric","description":"CreatedMetric allows customizing creation of _created metrics","title":"export_created_metric"},"external_labels":{"description":"ExternalLabels defines a map of label keys and values that are allowed to start with reserved prefix \"__\"","patternProperties":{".*":{"type":"string"}},"title":"external_labels","type":"object"},"headers":{"description":"Additional headers attached to each HTTP request sent by the client.\nExisting header values are overwritten if collision happens.\nHeader values are opaque since they may be sensitive.","patternProperties":{".*":{"type":"string"}},"title":"headers","type":"object"},"idle_conn_timeout":{"description":"IdleConnTimeout is the maximum amount of time a connection will remain open before closing itself.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"idle_conn_timeout","type":"string"},"max_conns_per_host":{"description":"MaxConnsPerHost limits the total number of connections per host, including connections in the dialing,\nactive, and idle states.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_conns_per_host","type":"integer"},"max_idle_conns":{"description":"MaxIdleConns is used to set a limit to the maximum idle HTTP connections the client can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns","type":"integer"},"max_idle_conns_per_host":{"description":"MaxIdleConnsPerHost is used to set a limit to the maximum idle HTTP connections the host can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns_per_host","type":"integer"},"namespace":{"description":"prefix attached to each exported metric name\nSee: https://prometheus.io/docs/practices/naming/#metric-names","title":"namespace","type":"string"},"read_buffer_size":{"description":"ReadBufferSize for HTTP client. See http.Transport.ReadBufferSize.","title":"read_buffer_size","type":"integer"},"remote_write_queue":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.prometheusremotewriteexporter.RemoteWriteQueue","description":"QueueConfig allows users to fine tune the queues\nthat handle outgoing requests.","title":"remote_write_queue"},"resource_to_telemetry_conversion":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.pkg.resourcetotelemetry.Settings","description":"ResourceToTelemetrySettings is the option for converting resource attributes to telemetry attributes.\n\"Enabled\" - A boolean field to enable/disable this option. Default is `false`.\nIf enabled, all the resource attributes will be converted to metric labels by default.","title":"resource_to_telemetry_conversion"},"retry_on_failure":{"$ref":"#/$defs/go.opentelemetry.io.collector.exporter.exporterhelper.RetrySettings","title":"retry_on_failure"},"target_info":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.prometheusremotewriteexporter.TargetInfo","description":"TargetInfo allows customizing the target_info metric","title":"target_info"},"timeout":{"description":"Timeout parameter configures `http.Client.Timeout`.","title":"timeout","type":"string"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","description":"TLSSetting struct exposes TLS client configuration.","title":"tls"},"wal":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.prometheusremotewriteexporter.WALConfig","title":"wal"},"write_buffer_size":{"description":"WriteBufferSize for HTTP client. See http.Transport.WriteBufferSize.","title":"write_buffer_size","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.prometheusremotewriteexporter.CreatedMetric":{"additionalProperties":false,"properties":{"enabled":{"description":"Enabled if true the _created metrics could be exported","title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.prometheusremotewriteexporter.RemoteWriteQueue":{"additionalProperties":false,"description":"RemoteWriteQueue allows to configure the remote write queue.","properties":{"enabled":{"description":"Enabled if false the queue is not enabled, the export requests\nare executed synchronously.","title":"enabled","type":"boolean"},"num_consumers":{"description":"NumWorkers configures the number of workers used by\nthe collector to fan out remote write requests.","title":"num_consumers","type":"integer"},"queue_size":{"description":"QueueSize is the maximum number of OTLP metric batches allowed\nin the queue at a given time. Ignored if Enabled is false.","title":"queue_size","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.prometheusremotewriteexporter.TargetInfo":{"additionalProperties":false,"properties":{"enabled":{"description":"Enabled if false the target_info metric is not generated by the exporter","title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.prometheusremotewriteexporter.WALConfig":{"additionalProperties":false,"markdownDescription":"# Prometheus Remote Write Exporter\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [core], [contrib], [aws], [observiq] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[core]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nPrometheus Remote Write Exporter sends OpenTelemetry metrics\nto Prometheus [remote write compatible\nbackends](https://prometheus.io/docs/operating/integrations/)\nsuch as Cortex, Mimir, and Thanos.\nBy default, this exporter requires TLS and offers queued retry capabilities.\n\n:warning: Non-cumulative monotonic, histogram, and summary OTLP metrics are\ndropped by this exporter.\n\nA [design doc](DESIGN.md) is available to document in detail\nhow this exporter works.\n\n## Getting Started\n\nThe following settings are required:\n\n- `endpoint` (no default): The remote write URL to send remote write samples.\n\nBy default, TLS is enabled and must be configured under `tls:`:\n\n- `insecure` (default = `false`): whether to enable client transport security for\n  the exporter's connection.\n\nAs a result, the following parameters are also required under `tls:`:\n\n- `cert_file` (no default): path to the TLS cert to use for TLS required connections. Should\n  only be used if `insecure` is set to false.\n- `key_file` (no default): path to the TLS key to use for TLS required connections. Should\n  only be used if `insecure` is set to false.\n\nThe following settings can be optionally configured:\n\n- `external_labels`: map of labels names and values to be attached to each metric data point\n- `headers`: additional headers attached to each HTTP request.\n  - *Note the following headers cannot be changed: `Content-Encoding`, `Content-Type`, `X-Prometheus-Remote-Write-Version`, and `User-Agent`.*\n- `namespace`: prefix attached to each exported metric name.\n- `remote_write_queue`: fine tuning for queueing and sending of the outgoing remote writes.\n  - `enabled`: enable the sending queue\n  - `queue_size`: number of OTLP metrics that can be queued. Ignored if `enabled` is `false`\n  - `num_consumers`: minimum number of workers to use to fan out the outgoing requests.\n- `resource_to_telemetry_conversion`\n  - `enabled` (default = false): If `enabled` is `true`, all the resource attributes will be converted to metric labels by default.\n- `target_info`: customize `target_info` metric\n  - `enabled` (default = true): If `enabled` is `true`, a `target_info` metric will be generated for each resource metric (see https://github.com/open-telemetry/opentelemetry-specification/pull/2381).\n- `export_created_metric`:\n  - `enabled` (default = false): If `enabled` is `true`, a `_created` metric is\n    exported for Summary, Histogram, and Monotonic Sum metric points if\n    `StartTimeUnixNano` is set.\n\nExample:\n\n```yaml\nexporters:\n  prometheusremotewrite:\n    endpoint: \"https://my-cortex:7900/api/v1/push\"\n    wal: # Enabling the Write-Ahead-Log for the exporter.\n      directory: ./prom_rw # The directory to store the WAL in\n      buffer_size: 100 # Optional count of elements to be read from the WAL before truncating; default of 300\n      truncate_frequency: 45s # Optional frequency for how often the WAL should be truncated. It is a time.ParseDuration; default of 1m\n    resource_to_telemetry_conversion:\n      enabled: true # Convert resource attributes to metric labels\n```\n\nExample:\n\n```yaml\nexporters:\n  prometheusremotewrite:\n    endpoint: \"https://my-cortex:7900/api/v1/push\"\n    external_labels:\n      label_name1: label_value1\n      label_name2: label_value2\n```\n\n## Advanced Configuration\n\nSeveral helper files are leveraged to provide additional capabilities automatically:\n\n- [HTTP settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/confighttp/README.md)\n- [TLS and mTLS settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/configtls/README.md)\n- [Retry and timeout settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/exporter/exporterhelper/README.md), note that the exporter doesn't support `sending_queue` but provides `remote_write_queue`.\n\n## Metric names and labels normalization\n\nOpenTelemetry metric names and attributes are normalized to be compliant with Prometheus naming rules. [Details on this normalization process are described in the Prometheus translator module](../../pkg/translator/prometheus/).\n\n[beta]:https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]:https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[core]:https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol","properties":{"buffer_size":{"title":"buffer_size","type":"integer"},"directory":{"title":"directory","type":"string"},"truncate_frequency":{"title":"truncate_frequency","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.pulsarexporter.Athenz":{"additionalProperties":false,"properties":{"key_id":{"title":"key_id","type":"string"},"principal_header":{"title":"principal_header","type":"string"},"private_key":{"title":"private_key","type":"string"},"provider_domain":{"title":"provider_domain","type":"string"},"tenant_domain":{"title":"tenant_domain","type":"string"},"tenant_service":{"title":"tenant_service","type":"string"},"zts_url":{"title":"zts_url","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.pulsarexporter.Authentication":{"additionalProperties":false,"properties":{"athenz":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.pulsarexporter.Athenz","title":"athenz"},"oauth2":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.pulsarexporter.OAuth2","title":"oauth2"},"tls":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.pulsarexporter.TLS","title":"tls"},"token":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.pulsarexporter.Token","title":"token"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.pulsarexporter.Config":{"additionalProperties":false,"description":"Config defines configuration for Pulsar exporter.","markdownDescription":"# Pulsar Exporter\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [alpha]: traces, metrics, logs   |\n| Distributions | [contrib] |\n\n[alpha]: https://github.com/open-telemetry/opentelemetry-collector#alpha\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n\u003c!-- end autogenerated section --\u003e\n\nPulsar exporter exports logs, metrics, and traces to Pulsar. This exporter uses a synchronous producer\nthat blocks and able to batch messages.\n\n## Get Started\n\nThe following settings can be optionally configured:\n- `endpoint` (default = pulsar://localhost:6650): The url of pulsar cluster.\n- `topic` (default = otlp_spans for traces, otlp_metrics for metrics, otlp_logs for logs): The name of the pulsar topic to export to.\n- `encoding` (default = otlp_proto): The encoding of the traces sent to pulsar. All available encodings:\n    - `otlp_proto`: payload is Protobuf serialized from `ExportTraceServiceRequest` if set as a traces exporter or `ExportMetricsServiceRequest` for metrics or `ExportLogsServiceRequest` for logs.\n    - `otlp_json`:  ** EXPERIMENTAL ** payload is JSON serialized from `ExportTraceServiceRequest` if set as a traces exporter or `ExportMetricsServiceRequest` for metrics or `ExportLogsServiceRequest` for logs.\n    - The following encodings are valid *only* for **traces**.\n        - `jaeger_proto`: the payload is serialized to a single Jaeger proto `Span`, and keyed by TraceID.\n        - `jaeger_json`: the payload is serialized to a single Jaeger JSON Span using `jsonpb`, and keyed by TraceID.\n- `auth`\n    - `tls`\n        - `cert_file`:\n        - `key_file`:\n    - `token`\n        - `token`\n    - `oauth2`\n        - `issuer_url`:\n        - `client_id`:\n        - `audience`:\n    - `athenz`\n        - `provider_domain`:\n        - `tenant_domain`:\n        - `tenant_service`:\n        - `private_key`:\n        - `key_id`:\n        - `principal_header`:\n        - `zts_url`:\n- `producer`\n    - `max_reconnect_broker`: specifies the maximum retry number of reconnectToBroker. (default: ultimate)\n    - `hashing_scheme`: used to define the partition on where to publish a particular message. Can be set to `java_string_hash` (default) or `murmur3_32hash`. \n    - `compression_level`: one of 'default' (default), 'faster', or 'better'.\n    - `compression_type`: one of 'none' (default), 'lz4', 'zlib', or 'zstd'.\n    - `max_pending_messages\"`: specifies the max size of the queue holding the messages pending to receive an acknowledgment from the broker.\n    - `batch_builder_type\"`: one of 'default' (default) or 'key_based'.\n    - `partitions_auto_discovery_interval\"`: the time interval for the background process to discover new partitions\n    - `batching_max_publish_delay\"`: specifies the time period within which the messages sent will be batched (default: 10ms)\n    - `batching_max_messages\"`: specifies the maximum number of messages permitted in a batch. (default: 1000)\n    - `batching_max_size\"`: specifies the maximum number of bytes permitted in a batch. (default 128 KB)\n    - `disable_block_if_queue_full\"`: controls whether Send and SendAsync block if producer's message queue is full. Defaults to false.\n    - `disable_batching\"`: controls whether automatic batching of messages is enabled for the producer. Defaults to false.\n- `tls_trust_certs_file_path`: path to the CA cert. For a client this verifies the server certificate. Should\n  only be used if `insecure` is set to true.\n- `tls_allow_insecure_connection`: configure whether the Pulsar client accept untrusted TLS certificate from broker (default: false)\n- `timeout`: send pulsar message timeout (default: 5s)\n- `operation_timeout`: sets producer-create, subscribe and unsubscribe operations timeout (default: 30 seconds)\n- `connection_timeout`: timeout for the establishment of a TCP connection (default: 5 seconds)\n- `map_connections_per_broker`: max number of connections to a single broker that will kept in the pool. (default: 1 connection)\n- `retry_on_failure`\n    - `enabled` (default = true)\n    - `initial_interval` (default = 5s): Time to wait after the first failure before retrying; ignored if `enabled` is `false`\n    - `max_interval` (default = 30s): Is the upper bound on backoff; ignored if `enabled` is `false`\n    - `max_elapsed_time` (default = 120s): Is the maximum amount of time spent trying to send a batch; ignored if `enabled` is `false`\n- `sending_queue`\n    - `enabled` (default = true)\n    - `num_consumers` (default = 10): Number of consumers that dequeue batches; ignored if `enabled` is `false`\n    - `queue_size` (default = 1000): Maximum number of batches kept in memory before dropping data; ignored if `enabled` is `false`;\n      User should calculate this as `num_seconds * requests_per_second` where:\n        - `num_seconds` is the number of seconds to buffer in case of a backend outage\n        - `requests_per_second` is the average number of requests per seconds.\n\nExample configuration:\n```yaml\nexporters:\n  pulsar:\n    service_url: pulsar://localhost:6650\n    topic: otlp-spans\n    encoding: otlp_proto\n    auth:\n      tls:\n        cert_file: cert.pem\n        key_file: key.pem\n    timeout: 10s\n    tls_allow_insecure_connection: false\n    tls_trust_certs_file_path: ca.pem\n```","properties":{"auth":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.pulsarexporter.Authentication","title":"auth"},"connection_timeout":{"title":"connection_timeout","type":"string"},"encoding":{"description":"Encoding of messages (default \"otlp_proto\")","title":"encoding","type":"string"},"endpoint":{"description":"Endpoint of pulsar broker (default \"pulsar://localhost:6650\")","title":"endpoint","type":"string"},"map_connections_per_broker":{"title":"map_connections_per_broker","type":"integer"},"operation_timeout":{"title":"operation_timeout","type":"string"},"producer":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.pulsarexporter.Producer","description":"Producer configuration of the Pulsar producer","title":"producer"},"retry_on_failure":{"$ref":"#/$defs/go.opentelemetry.io.collector.exporter.exporterhelper.RetrySettings","title":"retry_on_failure"},"sending_queue":{"$ref":"#/$defs/go.opentelemetry.io.collector.exporter.exporterhelper.QueueSettings","title":"sending_queue"},"timeout":{"description":"Timeout is the timeout for every attempt to send data to the backend.","title":"timeout","type":"string"},"tls_allow_insecure_connection":{"description":"Configure whether the Pulsar client accept untrusted TLS certificate from broker (default: false)","title":"tls_allow_insecure_connection","type":"boolean"},"tls_trust_certs_file_path":{"description":"Set the path to the trusted TLS certificate file","title":"tls_trust_certs_file_path","type":"string"},"topic":{"description":"The name of the pulsar topic to export to (default otlp_spans for traces, otlp_metrics for metrics)","title":"topic","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.pulsarexporter.OAuth2":{"additionalProperties":false,"properties":{"audience":{"title":"audience","type":"string"},"client_id":{"title":"client_id","type":"string"},"issuer_url":{"title":"issuer_url","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.pulsarexporter.Producer":{"additionalProperties":false,"description":"Producer defines configuration for producer","properties":{"batch_builder_type":{"title":"batch_builder_type","type":"string"},"batching_max_messages":{"title":"batching_max_messages","type":"integer"},"batching_max_publish_delay":{"title":"batching_max_publish_delay","type":"string"},"batching_max_size":{"title":"batching_max_size","type":"integer"},"compression_level":{"title":"compression_level","type":"string"},"compression_type":{"title":"compression_type","type":"string"},"disable_batching":{"title":"disable_batching","type":"boolean"},"disable_block_if_queue_full":{"title":"disable_block_if_queue_full","type":"boolean"},"hashing_scheme":{"title":"hashing_scheme","type":"string"},"max_pending_messages":{"title":"max_pending_messages","type":"integer"},"max_reconnect_broker":{"title":"max_reconnect_broker","type":"integer"},"partitions_auto_discovery_interval":{"title":"partitions_auto_discovery_interval","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.pulsarexporter.TLS":{"additionalProperties":false,"properties":{"cert_file":{"title":"cert_file","type":"string"},"key_file":{"title":"key_file","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.pulsarexporter.Token":{"additionalProperties":false,"properties":{"token":{"title":"token","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.exporter.zipkinexporter.Config":{"additionalProperties":false,"description":"Config defines configuration settings for the Zipkin exporter.","markdownDescription":"# Zipkin Exporter\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: traces   |\n| Distributions | [core], [contrib], [observiq] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[core]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nExports data to a [Zipkin](https://zipkin.io/) back-end.\nBy default, this exporter requires TLS and offers queued retry capabilities.\n\n## Getting Started\n\nThe following settings are required:\n\n- `endpoint` (no default): URL to which the exporter is going to send Zipkin trace data. For example: `http://localhost:9411/api/v2/spans`.\n\nThe following settings are optional:\n\n- `format` (default = `json`): The format to sent events in. Can be set to `json` or `proto`.\n- `default_service_name` (default = `\u003cmissing service name\u003e`): What to name\n  services missing this information.\n\nTo use TLS, specify `https://` as the protocol scheme in the URL passed to the `endpoint` property.\nSee [Advanced Configuration](#advanced-configuration) for more TLS options.\n\nExample:\n\n```yaml\nexporters:\n  zipkin/nontls:\n    endpoint: \"http://some.url:9411/api/v2/spans\"\n    format: proto\n    default_service_name: unknown-service\n\n  zipkin/withtls:\n    endpoint: \"https://some.url:9411/api/v2/spans\"\n\n  zipkin/tlsnoverify:\n    endpoint: \"https://some.url:9411/api/v2/spans\"\n    tls:\n      insecure_skip_verify: true\n```\n\n## Advanced Configuration\n\nSeveral helper files are leveraged to provide additional capabilities automatically:\n\n- [HTTP client settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/confighttp/README.md#client-configuration)\n- [TLS and mTLS settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/configtls/README.md)\n- [Queuing, retry and timeout settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/exporter/exporterhelper/README.md)","properties":{"CustomRoundTripper":{"description":"Custom Round Tripper to allow for individual components to intercept HTTP requests","title":"CustomRoundTripper"},"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth configuration for outgoing HTTP calls.","title":"auth"},"compression":{"description":"The compression key for supported compression types within collector.","title":"compression","type":"string"},"default_service_name":{"title":"default_service_name","type":"string"},"endpoint":{"description":"The target URL to send data to (e.g.: http://some.url:9411/v1/traces).","title":"endpoint","type":"string"},"format":{"title":"format","type":"string"},"headers":{"description":"Additional headers attached to each HTTP request sent by the client.\nExisting header values are overwritten if collision happens.\nHeader values are opaque since they may be sensitive.","patternProperties":{".*":{"type":"string"}},"title":"headers","type":"object"},"idle_conn_timeout":{"description":"IdleConnTimeout is the maximum amount of time a connection will remain open before closing itself.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"idle_conn_timeout","type":"string"},"max_conns_per_host":{"description":"MaxConnsPerHost limits the total number of connections per host, including connections in the dialing,\nactive, and idle states.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_conns_per_host","type":"integer"},"max_idle_conns":{"description":"MaxIdleConns is used to set a limit to the maximum idle HTTP connections the client can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns","type":"integer"},"max_idle_conns_per_host":{"description":"MaxIdleConnsPerHost is used to set a limit to the maximum idle HTTP connections the host can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns_per_host","type":"integer"},"read_buffer_size":{"description":"ReadBufferSize for HTTP client. See http.Transport.ReadBufferSize.","title":"read_buffer_size","type":"integer"},"retry_on_failure":{"$ref":"#/$defs/go.opentelemetry.io.collector.exporter.exporterhelper.RetrySettings","title":"retry_on_failure"},"sending_queue":{"$ref":"#/$defs/go.opentelemetry.io.collector.exporter.exporterhelper.QueueSettings","title":"sending_queue"},"timeout":{"description":"Timeout parameter configures `http.Client.Timeout`.","title":"timeout","type":"string"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","description":"TLSSetting struct exposes TLS client configuration.","title":"tls"},"write_buffer_size":{"description":"WriteBufferSize for HTTP client. See http.Transport.WriteBufferSize.","title":"write_buffer_size","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.extension.basicauthextension.ClientAuthSettings":{"additionalProperties":false,"properties":{"password":{"description":"Password holds the password to use for client authentication.","title":"password","type":"string"},"username":{"description":"Username holds the username to use for client authentication.","title":"username","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.extension.basicauthextension.Config":{"additionalProperties":false,"properties":{"client_auth":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.extension.basicauthextension.ClientAuthSettings","description":"ClientAuth settings","title":"client_auth"},"htpasswd":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.extension.basicauthextension.HtpasswdSettings","description":"Htpasswd settings.","title":"htpasswd"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.extension.basicauthextension.HtpasswdSettings":{"additionalProperties":false,"markdownDescription":"# Basic Authenticator\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]  |\n| Distributions | [contrib], [observiq], [redhat], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[redhat]: https://github.com/os-observability/redhat-opentelemetry-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThis extension implements both `configauth.ServerAuthenticator` and `configauth.ClientAuthenticator` to authenticate clients and servers using Basic Authentication. The authenticator type has to be set to `basicauth`.\n\nWhen used as ServerAuthenticator, if the authentication is successful `client.Info.Auth` will expose the following attributes:\n\n- `username`: The username of the authenticated user.\n- `raw`: Raw base64 encoded credentials.\n\nThe configuration should specify only one instance of `basicauth` extension for either client or server authentication. \n\nThe following are the configuration options:\n\n- `htpasswd.file`:  The path to the htpasswd file.\n- `htpasswd.inline`: The htpasswd file inline content.\n- `client_auth.username`: Username to use for client authentication.\n- `client_auth.password`: Password to use for client authentication.\n\nTo configure the extension as a server authenticator, either one of `htpasswd.file` or `htpasswd.inline` has to be set. If both are configured, `htpasswd.inline` credentials take precedence.\n\nTo configure the extension as a client authenticator, `client_auth` has to be set.\n\nIf both the options are configured, the extension will throw an error.\n## Configuration\n\n```yaml\nextensions:\n  basicauth/server:\n    htpasswd: \n      file: .htpasswd\n      inline: |\n        ${env:BASIC_AUTH_USERNAME}:${env:BASIC_AUTH_PASSWORD}\n  \n  basicauth/client:\n    client_auth: \n      username: username\n      password: password\n\nreceivers:\n  otlp:\n    protocols:\n      http:\n        auth:\n          authenticator: basicauth/server\n\nprocessors:\n\nexporters:\n  otlp:\n    auth:\n      authenticator: basicauth/client\n\nservice:\n  extensions: [basicauth/server, basicauth/client]\n  pipelines:\n    traces:\n      receivers: [otlp]\n      processors: []\n      exporters: [otlp]\n```","properties":{"file":{"description":"Path to the htpasswd file.","title":"file","type":"string"},"inline":{"description":"Inline contents of the htpasswd file.","title":"inline","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.extension.bearertokenauthextension.Config":{"additionalProperties":false,"description":"Config specifies how the Per-RPC bearer token based authentication data should be obtained.","markdownDescription":"# Authenticator - Bearer\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]  |\n| Distributions | [contrib], [observiq], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\n\n\nThis extension implements `configauth.ClientAuthenticator` and can be used in both http and gRPC exporters inside the `auth` settings, as a means to embed a static token for every RPC call that will be made.\n\nThe authenticator type has to be set to `bearertokenauth`.\n\n## Configuration\n\n- `scheme`: Specifies the auth scheme name. Defaults to \"Bearer\". Optional.\n\n- `token`: Static authorization token that needs to be sent on every gRPC client call as metadata.\n\n- `filename`: Name of file that contains a authorization token that needs to be sent in every client call.\n\nEither one of `token` or `filename` field is required. If both are specified, then the `token` field value is **ignored**. In any case, the value of the token will be prepended by `${scheme}` before being sent as a value of \"authorization\" key in the request header in case of HTTP and metadata in case of gRPC.\n\n**Note**: bearertokenauth requires transport layer security enabled on the exporter.\n\n\n```yaml\nextensions:\n  bearertokenauth:\n    token: \"somerandomtoken\"\n    filename: \"file-containing.token\"\n  bearertokenauth/withscheme:\n    scheme: \"Bearer\"\n    token: \"randomtoken\"\n\nreceivers:\n  hostmetrics:\n    scrapers:\n      memory:\n  otlp:\n    protocols:\n      grpc:\n\nexporters:\n  otlp/withauth:\n    endpoint: 0.0.0.0:5000\n    ca_file: /tmp/certs/ca.pem\n    auth:\n      authenticator: bearertokenauth\n\n  otlphttp/withauth:\n    endpoint: http://localhost:9000\n    auth:\n      authenticator: bearertokenauth/withscheme\n\nservice:\n  extensions: [bearertokenauth, bearertokenauth/withscheme]\n  pipelines:\n    metrics:\n      receivers: [hostmetrics]\n      processors: []\n      exporters: [otlp/withauth, otlphttp/withauth]\n```","properties":{"filename":{"description":"Filename points to a file that contains the bearer token to use for every RPC.","title":"filename","type":"string"},"scheme":{"description":"Scheme specifies the auth-scheme for the token. Defaults to \"Bearer\"","title":"scheme","type":"string"},"token":{"description":"BearerToken specifies the bearer token to use for every RPC.","title":"token","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.extension.healthcheckextension.Config":{"additionalProperties":false,"description":"Config has the configuration for the extension enabling the health check extension, used to report the health status of the service.","properties":{"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth for this receiver","title":"auth"},"check_collector_pipeline":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.extension.healthcheckextension.checkCollectorPipelineSettings","description":"CheckCollectorPipeline contains the list of settings of collector pipeline health check","title":"check_collector_pipeline"},"cors":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.confighttp.CORSSettings","description":"CORS configures the server for HTTP cross-origin resource sharing (CORS).","title":"cors"},"endpoint":{"description":"Endpoint configures the listening address for the server.","title":"endpoint","type":"string"},"include_metadata":{"description":"IncludeMetadata propagates the client metadata from the incoming requests to the downstream consumers\nExperimental: *NOTE* this option is subject to change or removal in the future.","title":"include_metadata","type":"boolean"},"max_request_body_size":{"description":"MaxRequestBodySize sets the maximum request body size in bytes","title":"max_request_body_size","type":"integer"},"path":{"description":"Path represents the path the health check service will serve.\nThe default path is \"/\".","title":"path","type":"string"},"response_body":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.extension.healthcheckextension.ResponseBodySettings","description":"ResponseBody represents the body of the response returned by the health check service.\nThis overrides the default response that it would return.","title":"response_body"},"response_headers":{"description":"Additional headers attached to each HTTP response sent to the client.\nHeader values are opaque since they may be sensitive.","patternProperties":{".*":{"type":"string"}},"title":"response_headers","type":"object"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSServerSetting","description":"TLSSetting struct exposes TLS client configuration.","title":"tls"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.extension.healthcheckextension.ResponseBodySettings":{"additionalProperties":false,"markdownDescription":"# Health Check\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]  |\n| Distributions | [core], [contrib], [aws], [observiq], [redhat], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[core]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[redhat]: https://github.com/os-observability/redhat-opentelemetry-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nHealth Check extension enables an HTTP url that can be probed to check the\nstatus of the OpenTelemetry Collector. This extension can be used as a\nliveness and/or readiness probe on Kubernetes.\n\nThere is an optional configuration `check_collector_pipeline` which allows\nusers to enable health check for the collector pipeline. This feature can\nmonitor the number of times that components failed send data to the destinations.\nIt only supports monitoring exporter failures and will support receivers and\nprocessors in the future.\n\nThe following settings are required:\n\n- `endpoint` (default = 0.0.0.0:13133): Address to publish the health check status. For full list of `HTTPServerSettings` refer [here](https://github.com/open-telemetry/opentelemetry-collector/tree/main/config/confighttp).\n- `path` (default = \"/\"): Specifies the path to be configured for the health check server.\n- `response_body` (default = \"\"): Specifies a static body that overrides the default response returned by the health check service. \n- `check_collector_pipeline:` (optional): Settings of collector pipeline health check\n    - `enabled` (default = false): Whether enable collector pipeline check or not\n    - `interval` (default = \"5m\"): Time interval to check the number of failures\n    - `exporter_failure_threshold` (default = 5): The failure number threshold to mark\n      containers as healthy.\n\nExample:\n\n```yaml\nextensions:\n  health_check:\n  health_check/1:\n    endpoint: \"localhost:13\"\n    tls:\n      ca_file: \"/path/to/ca.crt\"\n      cert_file: \"/path/to/cert.crt\"\n      key_file: \"/path/to/key.key\"\n    path: \"/health/status\"\n    check_collector_pipeline:\n      enabled: true\n      interval: \"5m\"\n      exporter_failure_threshold: 5\n```\n\nThe full list of settings exposed for this exporter is documented [here](./config.go)\nwith detailed sample configurations [here](./testdata/config.yaml).","properties":{"healthy":{"description":"Healthy represents the body of the response returned when the collector is healthy.\nThe default value is \"\"","title":"healthy","type":"string"},"unhealthy":{"description":"Unhealthy represents the body of the response returned when the collector is unhealthy.\nThe default value is \"\"","title":"unhealthy","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.extension.healthcheckextension.checkCollectorPipelineSettings":{"additionalProperties":false,"properties":{"enabled":{"title":"enabled","type":"boolean"},"exporter_failure_threshold":{"title":"exporter_failure_threshold","type":"integer"},"interval":{"title":"interval","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.extension.httpforwarder.Config":{"additionalProperties":false,"description":"Config defines configuration for http forwarder extension.","markdownDescription":"# HTTP Forwarder Extension\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]  |\n| Distributions | [contrib], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThis extension accepts HTTP requests, optionally adds headers to them and forwards them.\nThe RequestURIs of the original requests are preserved by the extension.\n\n## Configuration\n\nThe following settings are required:\n\n- `egress`: HTTP config settings to use for forwarding requests.\n  - `endpoint` (no default): The target to which requests should be forwarded to.\n\nThe following settings can be optionally configured:\n\n- `ingress`: HTTP config settings for HTTP server listening to requests.\n  - `endpoint` (default = `0.0.0.0:6060`): The host to which requests should be forwarded to.\n- `egress`: HTTP config settings to use for forwarding requests.\n  - `headers` (default = `nil`): Additional headers to be added to all requests passing through the extension.\n  - `timeout` (default = `10s`): How long to wait for each request to complete.\n\n### Example\n\n```yaml\n  http_forwarder:\n    ingress:\n      endpoint: localhost:7070\n    egress:\n      endpoint: http://target/\n      headers:\n        otel_http_forwarder: dev\n      timeout: 5s\n```\n\nThe full list of settings exposed for this exporter are documented [here](config.go)\nwith detailed sample configurations [here](testdata/config.yaml).","properties":{"egress":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.confighttp.HTTPClientSettings","description":"Egress holds config settings to use for forwarded requests.","title":"egress"},"ingress":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.confighttp.HTTPServerSettings","description":"Ingress holds config settings for HTTP server listening for requests.","title":"ingress"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.extension.jaegerremotesampling.Config":{"additionalProperties":false,"description":"Config has the configuration for the extension enabling the health check extension, used to report the health status of the service.","markdownDescription":"# Jaeger's Remote Sampling extension\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [alpha]  |\n| Distributions | [contrib], [sumo] |\n\n[alpha]: https://github.com/open-telemetry/opentelemetry-collector#alpha\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThis extension allows serving sampling strategies following the Jaeger's remote sampling API. This extension can be configured to proxy requests to a backing remote sampling server, which could potentially be a Jaeger Collector down the pipeline, or a static JSON file from the local file system.\n\nBy default, two listeners are made available:\n- `localhost:5778`, following the legacy remote sampling endpoint as defined by Jaeger\n- `localhost:14250`, following the gRPC remote sampling endpoint, also defined by Jaeger\n\nNote that the port `14250` will clash with the Jaeger Receiver. When both are used, it's recommended to change this extension to use another port.\n\nAlthough this extension is derived from Jaeger, it can be used by any clients who can consume this standard, such as the [OpenTelemetry Java SDK](https://github.com/open-telemetry/opentelemetry-java/tree/v1.9.1/sdk-extensions/jaeger-remote-sampler).\n\nAt this moment, the `reload_interval` option is only effective for the `file` source. In the future, this property will be used to control a local cache for a `remote` source.\n\nThe `file` source can be used to load files from the local file system or from remote HTTP/S sources. The `remote` source must be used with a gRPC server that provides a Jaeger remote sampling service.\n\n## Configuration\n\n```yaml\nextensions:\n  jaegerremotesampling:\n    source:\n      remote:\n        endpoint: jaeger-collector:14250\n  jaegerremotesampling/1:\n    source:\n      reload_interval: 1s\n      file: /etc/otelcol/sampling_strategies.json\n  jaegerremotesampling/2:\n    source:\n      reload_interval: 1s\n      file: http://jaeger.example.com/sampling_strategies.json\n```\n\nA sampling strategy file could look like:\n\n```json\n{\n  \"service_strategies\": [\n    {\n      \"service\": \"foo\",\n      \"type\": \"probabilistic\",\n      \"param\": 0.8,\n      \"operation_strategies\": [\n        {\n          \"operation\": \"op1\",\n          \"type\": \"probabilistic\",\n          \"param\": 0.2\n        },\n        {\n          \"operation\": \"op2\",\n          \"type\": \"probabilistic\",\n          \"param\": 0.4\n        }\n      ]\n    },\n    {\n      \"service\": \"bar\",\n      \"type\": \"ratelimiting\",\n      \"param\": 5\n    }\n  ],\n  \"default_strategy\": {\n    \"type\": \"probabilistic\",\n    \"param\": 0.5,\n    \"operation_strategies\": [\n      {\n        \"operation\": \"/health\",\n        \"type\": \"probabilistic\",\n        \"param\": 0.0\n      },\n      {\n        \"operation\": \"/metrics\",\n        \"type\": \"probabilistic\",\n        \"param\": 0.0\n      }\n    ]\n  }\n}\n```\nSource: https://www.jaegertracing.io/docs/1.28/sampling/#collector-sampling-configuration","properties":{"grpc":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configgrpc.GRPCServerSettings","title":"grpc"},"http":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.confighttp.HTTPServerSettings","title":"http"},"source":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.extension.jaegerremotesampling.Source","description":"Source configures the source for the strategies file. One of `remote` or `file` has to be specified.","title":"source"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.extension.jaegerremotesampling.Source":{"additionalProperties":false,"properties":{"file":{"description":"File specifies a local file as the strategies source","title":"file","type":"string"},"reload_interval":{"description":"ReloadInterval determines the periodicity to refresh the strategies","title":"reload_interval","type":"string"},"remote":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configgrpc.GRPCClientSettings","description":"Remote defines the remote location for the file","title":"remote"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.extension.oauth2clientauthextension.Config":{"additionalProperties":false,"description":"Config stores the configuration for OAuth2 Client Credentials (2-legged OAuth2 flow) setup.","markdownDescription":"# Authenticator - OAuth2 Client Credentials\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]  |\n| Distributions | [contrib], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\n\nThis extension provides OAuth2 Client Credentials flow authenticator for HTTP and gRPC based exporters. The extension\nfetches and refreshes the token after expiry automatically. For further details about OAuth2 Client Credentials flow (2-legged workflow)\nrefer https://datatracker.ietf.org/doc/html/rfc6749#section-4.4.\n\nThe authenticator type has to be set to `oauth2client`.\n\n## Configuration\n\n```yaml\nextensions:\n  oauth2client:\n    client_id: someclientid\n    client_secret: someclientsecret\n    endpoint_params:\n      audience: someaudience\n    token_url: https://example.com/oauth2/default/v1/token\n    scopes: [\"api.metrics\"]\n    # tls settings for the token client\n    tls:\n      insecure: true\n      ca_file: /var/lib/mycert.pem\n      cert_file: certfile\n      key_file: keyfile\n    # timeout for the token client\n    timeout: 2s\n    \nreceivers:\n  hostmetrics:\n    scrapers:\n      memory:\n  otlp:\n    protocols:\n      grpc:\n\nexporters:\n  otlphttp/withauth:\n    endpoint: http://localhost:9000\n    auth:\n      authenticator: oauth2client\n      \n  otlp/withauth:\n    endpoint: 0.0.0.0:5000\n    ca_file: /tmp/certs/ca.pem\n    auth:\n      authenticator: oauth2client\n\nservice:\n  extensions: [oauth2client]\n  pipelines:\n    metrics:\n      receivers: [hostmetrics]\n      processors: []\n      exporters: [otlphttp/withauth, otlp/withauth]\n```\n\nFollowing are the configuration fields\n\n- [**token_url**](https://datatracker.ietf.org/doc/html/rfc6749#section-3.2) - The resource server's token endpoint URLs.\n- [**client_id**](https://datatracker.ietf.org/doc/html/rfc6749#section-2.2) - The client identifier issued to the client.\n- [**client_secret**](https://datatracker.ietf.org/doc/html/rfc6749#section-2.3.1) - The secret string associated with above identifier.\n- [**endpoint_params**](https://github.com/golang/oauth2/blob/master/clientcredentials/clientcredentials.go#L44) - Additional parameters that are sent to the token endpoint.\n- [**scopes**](https://datatracker.ietf.org/doc/html/rfc6749#section-3.3) - **Optional** optional requested permissions associated for the client.\n- [**timeout**](https://golang.org/src/net/http/client.go#L90) -  **Optional** specifies the timeout on the underlying client to authorization server for fetching the tokens (initial and while refreshing).\n  This is optional and not setting this configuration implies there is no timeout on the client.\n\nFor more information on client side TLS settings, see [configtls README](https://github.com/open-telemetry/opentelemetry-collector/tree/main/config/configtls).","properties":{"client_id":{"description":"ClientID is the application's ID.\nSee https://datatracker.ietf.org/doc/html/rfc6749#section-2.2","title":"client_id","type":"string"},"client_secret":{"description":"ClientSecret is the application's secret.\nSee https://datatracker.ietf.org/doc/html/rfc6749#section-2.3.1","title":"client_secret","type":"string"},"endpoint_params":{"$ref":"#/$defs/net.url.Values","description":"EndpointParams specifies additional parameters for requests to the token endpoint.","title":"endpoint_params"},"scopes":{"description":"Scope specifies optional requested permissions.\nSee https://datatracker.ietf.org/doc/html/rfc6749#section-3.3","items":{"type":"string"},"title":"scopes","type":"array"},"timeout":{"description":"Timeout parameter configures `http.Client.Timeout` for the underneath client to authorization\nserver while fetching and refreshing tokens.","title":"timeout","type":"string"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","description":"TLSSetting struct exposes TLS client configuration for the underneath client to authorization server.","title":"tls"},"token_url":{"description":"TokenURL is the resource server's token endpoint\nURL. This is a constant specific to each server.\nSee https://datatracker.ietf.org/doc/html/rfc6749#section-3.2","title":"token_url","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.extension.observer.dockerobserver.Config":{"additionalProperties":false,"description":"Config defines configuration for docker observer","markdownDescription":"# Docker Observer Extension\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]  |\n| Distributions | [contrib], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe Docker observer extension is a [Receiver Creator](../../../receiver/receivercreator/README.md)-compatible \"watch observer\" that will detect and report\ncontainer endpoints discovered through the Docker API. Only containers that are in the state of `Running` and not `Paused` will emit endpoints.\nThis observer watches the Docker engine's stream of events to dynamically create, update, and remove endpoints as events are processed.\n\nRequires Docker API Version 1.22+.\n\nThe collector will need permissions to access the Docker Engine API, specifically it will need\nread access to the Docker socket (default `unix:///var/run/docker.sock`).\n\n\n## Example Config\n\n```yaml\nextensions:\n  docker_observer:\n    # url of the docker socket, default to unix:///var/run/docker.sock\n    endpoint: my/path/to/docker.sock\n    # list of container image names to exclude\n    excluded_images: ['redis', 'another_image_name']\n    # client API version, default to 1.22\n    api_version: 1.24\n    # max amount of time to wait for a response from Docker API , default to 5s\n    timeout: 15s\n\nreceivers:\n  receiver_creator:\n    watch_observers: [docker_observer]\n    receivers:\n      nginx:\n        rule: type == \"container\" and name matches \"nginx\" and port == 80\n        config:\n          endpoint: '`endpoint`/status'\n          collection_interval: 10s\n```\n\n## Configuration\n\n### `endpoint`\n\nThe URL of the docker server.\n\ndefault: `unix:///var/run/docker.sock`\n\n### `timeout`\n\nThe maximum amount of time to wait for docker API responses.\n\ndefault: `5s`\n\n### `excluded_images`\n\nA list of filters whose matching images are to be excluded. Supports literals, globs, and regex.\n\ndefault: `[]`\n\n### `use_hostname_if_present`\n\nIf true, the `Config.Hostname` field (if present) of the docker\ncontainer will be used as the discovered host that is used to configure\nreceivers.  If false or if no hostname is configured, the field\n`NetworkSettings.IPAddress` is used instead. These settings can be found\nin the output of the Docker API's [Container Inspect](https://docs.docker.com/engine/api/v1.41/#operation/ContainerInspect) json.\n\ndefault: `false`\n\n### `use_host_bindings`\n\nIf true, the observer will configure receivers for matching container endpoints\nusing the host bound ip and port.  This is useful if containers exist that are not\naccessible to an instance of the collector running outside of the docker network stack.\n\ndefault: `false`\n\n### `ignore_non_host_bindings`\n\nIf true, the observer will ignore discovered container endpoints that are not bound\nto host ports.  This is useful if containers exist that are not accessible\nto an instance of the collector running outside of the docker network stack.\n\ndefault: `false`\n\n### `cache_sync_interval`\n\nThe time to wait before resyncing the list of containers the observer maintains\nthrough the docker event listener example: `cache_sync_interval: \"20m\"`\n\ndefault: `60m`\n\n## Endpoint Variables\n\nThe following endpoint variables are exposed to the receiver creator to be used in discovery rules:\n\n| Variable | Type | Description |\n|----------|------|-------------|\n| name | string | Primary name of the container |\n| image | string | Name of the container image |\n| port | uint16 | Exposed port of the container |\n| alternate_port | uint16 | Exposed port accessed through redirection, such as a mapped port |\n| command | string | The command used to invoke the process of the container |\n| container_id | string | ID of the container |\n| host | string | Hostname or IP of the underlying host the container is running on |\n| transport | string | Transport protocol used by the endpoint (TCP or UDP) |\n| labels | map[string]string | User-specified metadata labels on the container |","properties":{"api_version":{"description":"Docker client API version. Default is 1.22","title":"api_version","type":"number"},"cache_sync_interval":{"description":"The time to wait before resyncing the list of containers the observer maintains\nthrough the docker event listener example: cache_sync_interval: \"20m\"\nDefault: \"60m\"","title":"cache_sync_interval","type":"string"},"endpoint":{"description":"The URL of the docker server.  Default is \"unix:///var/run/docker.sock\"","title":"endpoint","type":"string"},"excluded_images":{"description":"A list of filters whose matching images are to be excluded.  Supports literals, globs, and regex.","items":{"type":"string"},"title":"excluded_images","type":"array"},"ignore_non_host_bindings":{"description":"If true, the observer will ignore discovered container endpoints that are not bound\nto host ports.  This is useful if containers exist that are not accessible\nto an instance of the agent running outside of the docker network stack.","title":"ignore_non_host_bindings","type":"boolean"},"timeout":{"description":"The maximum amount of time to wait for docker API responses.  Default is 5s","title":"timeout","type":"string"},"use_host_bindings":{"description":"If true, the observer will configure receivers for matching container endpoints\nusing the host bound ip and port.  This is useful if containers exist that are not\naccessible to an instance of the agent running outside of the docker network stack.\nIf UseHostnameIfPresent and this config are both enabled, this setting will take precedence.","title":"use_host_bindings","type":"boolean"},"use_hostname_if_present":{"description":"If true, the \"Config.Hostname\" field (if present) of the docker\ncontainer will be used as the discovered host that is used to configure\nreceivers.  If false or if no hostname is configured, the field\n`NetworkSettings.IPAddress` is used instead.","title":"use_hostname_if_present","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.extension.observer.ecsobserver.Config":{"additionalProperties":false,"properties":{"cluster_name":{"description":"ClusterName is the target ECS cluster name for service discovery.","title":"cluster_name","type":"string"},"cluster_region":{"description":"ClusterRegion is the target ECS cluster's AWS region.","title":"cluster_region","type":"string"},"docker_labels":{"description":"DockerLabels is a list of docker labels for filtering containers within tasks.","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.extension.observer.ecsobserver.DockerLabelConfig"},"title":"docker_labels","type":"array"},"job_label_name":{"description":"JobLabelName is the override for prometheus job label, using `job` literal will cause error\nin otel prometheus receiver. See https://github.com/open-telemetry/opentelemetry-collector/issues/575","title":"job_label_name","type":"string"},"refresh_interval":{"description":"RefreshInterval determines how frequency at which the observer\nneeds to poll for collecting information about new processes.","title":"refresh_interval","type":"string"},"result_file":{"description":"ResultFile is the output path of the discovered targets YAML file (optional).\nThis is mainly used in conjunction with the Prometheus receiver.","title":"result_file","type":"string"},"services":{"description":"Services is a list of service name patterns for filtering tasks.","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.extension.observer.ecsobserver.ServiceConfig"},"title":"services","type":"array"},"task_definitions":{"description":"TaskDefinitions is a list of task definition arn patterns for filtering tasks.","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.extension.observer.ecsobserver.TaskDefinitionConfig"},"title":"task_definitions","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.extension.observer.ecsobserver.DockerLabelConfig":{"additionalProperties":false,"description":"DockerLabelConfig matches all tasks based on their docker label.","properties":{"job_name":{"title":"job_name","type":"string"},"job_name_label":{"title":"job_name_label","type":"string"},"metrics_path":{"title":"metrics_path","type":"string"},"metrics_path_label":{"title":"metrics_path_label","type":"string"},"metrics_ports":{"items":{"type":"integer"},"title":"metrics_ports","type":"array"},"port_label":{"description":"PortLabel is mandatory, empty string means docker label based match is skipped.","title":"port_label","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.extension.observer.ecsobserver.ServiceConfig":{"additionalProperties":false,"markdownDescription":"# Amazon Elastic Container Service Observer\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]  |\n| Distributions | [contrib], [aws], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe `ecsobserver` uses the ECS/EC2 API to discover prometheus scrape targets from all running tasks and filter them\nbased on service names, task definitions and container labels.\n\nNOTE: If you run collector as a sidecar, you should consider\nuse [ECS resource detector](../../../processor/resourcedetectionprocessor/README.md) instead. However, it does not have\nservice, EC2 instances etc. because it only queries local API.\n\n## Config\n\nThe configuration is based on\n[existing cloudwatch agent ECS discovery](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ContainerInsights-Prometheus-Setup-autodiscovery-ecs.html)\n. A full collector config looks like the following:\n\n```yaml\nextensions:\n  ecs_observer:\n    refresh_interval: 60s # format is https://golang.org/pkg/time/#ParseDuration\n    cluster_name: 'Cluster-1' # cluster name need manual config\n    cluster_region: 'us-west-2' # region can be configured directly or use AWS_REGION env var\n    result_file: '/etc/ecs_sd_targets.yaml' # the directory for file must already exists\n    services:\n      - name_pattern: '^retail-.*$'\n    docker_labels:\n      - port_label: 'ECS_PROMETHEUS_EXPORTER_PORT'\n    task_definitions:\n      - job_name: 'task_def_1'\n        metrics_path: '/metrics'\n        metrics_ports:\n          - 9113\n          - 9090\n        arn_pattern: '.*:task-definition/nginx:[0-9]+'\n\nreceivers:\n  prometheus:\n    config:\n      scrape_configs:\n        - job_name: \"ecs-task\"\n          file_sd_configs:\n            - files:\n                - '/etc/ecs_sd_targets.yaml' # MUST match the file name in ecs_observer.result_file\n          relabel_configs: # Relabel here because label with __ prefix will be dropped by receiver.\n            - source_labels: [ __meta_ecs_cluster_name ] # ClusterName\n              action: replace\n              target_label: ClusterName\n            - source_labels: [ __meta_ecs_service_name ] # ServiceName\n              action: replace\n              target_label: ServiceName\n            - action: labelmap # Convert docker labels on container to metric labels\n              regex: ^__meta_ecs_container_labels_(.+)$ # Capture the key using regex, e.g. __meta_ecs_container_labels_Java_EMF_Metrics -\u003e Java_EMF_Metrics\n              replacement: '$$1'\n\nprocessors:\n  batch:\n\n# Use awsemf for CloudWatch Container Insights Prometheus. The extension does not have requirement on exporter.\nexporters:\n  awsemf:\n\nservice:\n  pipelines:\n    metrics:\n      receivers: [ prometheus ]\n      processors: [ batch ]\n      exporters: [ awsemf ]\n  extensions: [ ecs_observer ]\n```\n\n| Name             |           | Description                                                                                                         |\n|------------------|-----------|---------------------------------------------------------------------------------------------------------------------|\n| cluster_name     | Mandatory | target ECS cluster name for service discovery                                                                       |\n| cluster_region   | Mandatory | target ECS cluster's AWS region name                                                                                |\n| refresh_interval | Optional  | how often to look for changes in endpoints (default: 10s)                                                           |\n| result_file      | Mandatory | path of YAML file to write scrape target results. NOTE: the observer always returns empty in initial implementation |\n| services         | Optional  | list of service name patterns [detail](#ecs-service-name-based-filter-configuration)                                |\n| task_definitions | Optional  | list of task definition arn patterns [detail](#ecs-task-definition-based-filter-configuration)                      |\n| docker_labels    | Optional  | list of docker labels [detail](#docker-label-based-filter-configuration)                                            |\n\n### Output configuration\n\n`result_file` specifies where to write the discovered targets. It MUST match the files defined in `file_sd_configs` for\nprometheus receiver. See [output format](#output-format) for the detailed format.\n\n### Filters configuration\n\nThere are three type of filters, and they share the following common optional properties.\n\n- `job_name`\n- `metrics_path`\n- `metrics_ports` an array of port number\n\nExample\n\n```yaml\necs_observer:\n  job_name: 'ecs-sd-job'\n  services:\n    - name_pattern: ^retail-.*$\n      container_name_pattern: ^java-api-v[12]$\n    - name_pattern: game\n      metrics_path: /v3/343\n      job_name: guilty-spark\n  task_definitions:\n    - arn_pattern: '*memcached.*'\n    - arn_pattern: '^proxy-.*$'\n      metrics_ports:\n        - 9113\n        - 9090\n      metrics_path: /internal/metrics\n  docker_labels:\n    - port_label: ECS_PROMETHEUS_EXPORTER_PORT\n    - port_label: ECS_PROMETHEUS_EXPORTER_PORT_V2\n      metrics_path_label: ECS_PROMETHEUS_EXPORTER_METRICS_PATH\n```\n\n#### ECS Service Name based filter Configuration\n\n| Name                   |           | Description                                                                                        |\n|------------------------|-----------|----------------------------------------------------------------------------------------------------|\n| name_pattern           | Mandatory | Regex pattern to match against ECS service name                                                    |\n| metrics_ports          | Mandatory | container ports separated by semicolon. Only containers that expose these ports will be discovered |\n| container_name_pattern | Optional  | ECS task container name regex pattern                                                              |\n\n#### ECS Task Definition based filter Configuration\n\n| Name                   |           | Description                                                                                        |\n|------------------------|-----------|----------------------------------------------------------------------------------------------------|\n| arn_pattern            | Mandatory | Regex pattern to match against ECS task definition ARN                                             |\n| metrics_ports          | Mandatory | container ports separated by semicolon. Only containers that expose these ports will be discovered |\n| container_name_pattern | Optional  | ECS task container name regex pattern                                                              |\n\n#### Docker Label based filter Configuration\n\nSpecify label keys to look up value\n\n| Name               |           | Description                                                                     |\n|--------------------|-----------|---------------------------------------------------------------------------------|\n| port_label         | Mandatory | container's docker label name that specifies the metrics port                   |\n| metrics_path_label | Optional  | container's docker label name that specifies the metrics path. (Default: \"\")    |\n| job_name_label     | Optional  | container's docker label name that specifies the scrape job name. (Default: \"\") |\n\n### Authentication\n\nIt uses the default credential chain, on ECS it is advised to\nuse  [ECS task role](https://docs.aws.amazon.com/AmazonECS/latest/userguide/task-iam-roles.html). You need to deploy the\ncollector as an ECS task/service with\nthe [following permissions](https://docs.amazonaws.cn/en_us/AmazonCloudWatch/latest/monitoring/ContainerInsights-Prometheus-install-ECS.html#ContainerInsights-Prometheus-Setup-ECS-IAM)\n.\n\n**EC2** access is required for getting private IP for ECS EC2. However, EC2 permission can be removed if you are only\nusing Fargate because task ip comes from awsvpc instead of host.\n\n```text\nec2:DescribeInstances\necs:ListTasks\necs:ListServices\necs:DescribeContainerInstances\necs:DescribeServices\necs:DescribeTasks\necs:DescribeTaskDefinition\n```\n\n## Design\n\n- [Discovery](#discovery-mechanism)\n- [Notify receiver](#notify-prometheus-receiver-of-discovered-targets)\n- [Output format](#output-format)\n\n### Discovery mechanism\n\nThe extension polls ECS API periodically to get all running tasks and filter out scrape targets. There are 3 types of\nfilters for discovering targets, targets match the filter are kept. Targets from different filters are merged base\non `address/metrics_path` before updating/creating receiver.\n\n#### ECS Service Name based filter\n\nECS [Service](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs_services.html) is a deployment that\nmanages multiple tasks with same [definition](#ecs-task-definition-based-filter) (like Deployment and DaemonSet in k8s).\n\nThe `service`\nconfiguration matches both service name and container name (if not empty).\n\nNOTE: name of the service is **added** as label value with key `ServiceName`.\n\n```yaml\n# Example 1: Matches all containers that are started by retail-* service\nname_pattern: ^retail-.*$\n---\n# Example 2: Matches all container with name java-api in cash-app service \nname_pattnern: ^cash-app$\ncontainer_name_pattern: ^java-api$\n---\n# Example 3: Override default metrics_path (i.e. /metrics)\nname_pattern: ^log-replay-worker$\nmetrics_path: /v3/metrics\n```\n\n### ECS Task Definition based filter\n\nECS [task definition](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definitions.html) contains one or\nmore containers (like Pod in k8s). Long running applications normally uses [service](#ecs-service-name-based-filter).\nwhile short running (batch) jobs can\nbe [created from task definitions directly](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/scheduling_tasks.html)\n.\n\nThe `task` definition matches both task definition name and container name (of not empty). Optional config\nlike `metrics_path`, `metrics_ports`, `job_name` can override default value.\n\n```yaml\n# Example 1: Matches all the tasks created from task definition that contains memcached in its arn\narn_pattern: \"*memcached.*\"\n```\n\n### Docker Label based filter\n\nDocker label can be specified in task definition. Only `port_label` is used when checking if the container should be\nincluded. Optional config like `metrics_path_label`, `job_name_label` can override default value.\n\n```yaml\n# Example 1: Matches all the container that has label ECS_PROMETHEUS_EXPORTER_PORT_NGINX\nport_label: 'ECS_PROMETHEUS_EXPORTER_PORT_NGINX'\n---\n# Example 2: Override job name based on label MY_APP_JOB_NAME\nport_label: 'ECS_PROMETHEUS_EXPORTER_PORT_MY_APP'\njob_name_label: 'MY_APP_JOB_NAME'\n```\n\n### Notify Prometheus Receiver of discovered targets\n\nThere are three ways to notify a receiver\n\n- Use [file based service discovery](#generate-target-file-for-file-based-discovery) in prometheus config and updates\n  the file.\n- Use [receiver creator framework](#receiver-creator-framework) to create a new receiver for new endpoints.\n- Register as a prometheus discovery plugin.\n\n#### Generate target file for file based discovery\n\n- Status: implemented\n\nThis is current approach used by cloudwatch-agent and\nalso [recommended by prometheus](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#file_sd_config)\n. It's easier to debug and the main drawback is it only works for prometheus. Another minor issue is fsnotify may not\nwork properly occasionally and delay the update.\n\n#### Receiver creator framework\n\n- Status: pending\n\nThis is a generic approach that creates a new receiver at runtime based on discovered endpoints. The main problem is\nperformance issue as described\nin [this issue](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/1395).\n\n#### Register as prometheus discovery plugin\n\n- Status: pending\n\nBecause both the collector and prometheus is written in Go, we can call `discover.RegisterConfig` to make it a valid\nconfig for prometheus (like other in tree plugins like kubernetes). The drawback is the configuration is now under\nprometheus instead of extension and can cause confusion.\n\n## Output Format\n\n[Example in unit test](testdata/ut_targets.expected.yaml).\n\nThe format is based\non [cloudwatch agent](https://github.com/aws/amazon-cloudwatch-agent/tree/master/internal/ecsservicediscovery#example-result)\n, [ec2 sd](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#ec2_sd_config)\nand [kubernetes sd](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#kubernetes_sd_config).\nTask and labels from task definition are always included. EC2 info is only included when task is running on ECS EC2 (\ni.e. not on [Fargate](https://aws.amazon.com/fargate/)).\n\nUnlike cloudwatch agent, all the [additional labels](#additional-labels) starts with `__meta_ecs_` prefix. If they are\nnot renamed during [relabel](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config),\nthey will all get dropped in prometheus receiver and won't pass down along the pipeline.\n\nThe number of dimensions supported by [AWS EMF exporter](../../../exporter/awsemfexporter) is limited by its backend.\nThe labels can be modified/filtered at different stages, prometheus receiver\nrelabel, [Metrics Transform Processor](../../../processor/metricstransformprocessor)\nand [EMF exporter Metric Declaration](../../../exporter/awsemfexporter/README.md#metric_declaration)\n\n### Essential Labels\n\nRequired for prometheus to scrape the target.\n\n| Label Name          | Source                       | Type   | Description                                                               |\n|---------------------|------------------------------|--------|---------------------------------------------------------------------------|\n| `__address__`       | ECS Task and TaskDefinition  | string | `host:port` `host` is private ip from ECS Task, `port` is the mapped port |\n| ` __metrics_path__` | ECS TaskDefinition or Config | string | Default is `/metrics`, changes based on config/label                      |\n| `job`               | ECS TaskDefinition or Config | string | Name for scrape job                                                       |\n\n### Additional Labels\n\nAdditional information from ECS and EC2.\n\n| Label Name                                   | Source             | Type   | Description                                                                                                                                                                                                   |\n|----------------------------------------------|--------------------|--------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `__meta_ecs_task_definition_family`          | ECS TaskDefinition | string | Name for registered task definition                                                                                                                                                                           |\n| `__meta_ecs_task_definition_revision`        | ECS TaskDefinition | int    | Version of the task definition being used to run the task                                                                                                                                                     |\n| `__meta_ecs_task_launch_type`                | ECS Task           | string | `EC2` or `FARGATE`                                                                                                                                                                                            |\n| `__meta_ecs_task_group`                      | ECS Task           | string | [Task Group](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-placement-constraints.html#task-groups) is `service:my-service-name` or specified when launching task directly                  |\n| `__meta_ecs_task_tags_\u003ctagkey\u003e`              | ECS Task           | string | Tags specified in [CreateService](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_CreateService.html) and [RunTask](https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_RunTask.html) |\n| `__meta_ecs_task_container_name`             | ECS Task           | string | Name of container                                                                                                                                                                                             |\n| `__meta_ecs_task_container_label_\u003clabelkey\u003e` | ECS TaskDefinition | string | Docker label specified in task definition                                                                                                                                                                     |\n| `__meta_ecs_task_health_status`              | ECS Task           | string | `HEALTHY` or `UNHEALTHY`. `UNKNOWN` if not configured                                                                                                                                                         |\n| `__meta_ecs_ec2_instance_id`                 | EC2                | string | EC2 instance id for `EC2` launch type                                                                                                                                                                         |\n| `__meta_ecs_ec2_instance_type`               | EC2                | string | EC2 instance type e.g. `t3.medium`, `m6g.xlarge`                                                                                                                                                              |\n| `__meta_ecs_ec2_tags_\u003ctagkey\u003e`               | EC2                | string | Tags specified when creating the EC2 instance                                                                                                                                                                 |\n| `__meta_ecs_ec2_vpc_id`                      | EC2                | string | ID of VPC e.g. `vpc-abcdefeg`                                                                                                                                                                                 |\n| `__meta_ecs_ec2_private_ip`                  | EC2                | string | Private IP                                                                                                                                                                                                    |\n| `__meta_ecs_ec2_public_ip`                   | EC2                | string | Public IP, if available                                                                                                                                                                                       |\n\n### Serialization\n\n- Labels, all the label value are encoded as string. (e.g. strconv.Itoa(123)).\n- Go struct, all the non string types are converted. labels and tags are passed as `map[string]string`\n  instead of `[]KeyValue`\n- Prometheus target, each `taget`\n\n```go\n// PrometheusECSTarget contains address and labels extracted from a running ECS task \n// and its underlying EC2 instance (if available).\n// \n// For serialization\n// - FromLabels and ToLabels converts it between map[string]string.\n// - FromTargetYAML and ToTargetYAML converts it between prometheus file discovery format in YAML. \n// - FromTargetJSON and ToTargetJSON converts it between prometheus file discovery format in JSON. \ntype PrometheusECSTarget struct {\n\tAddress                string            `json:\"address\"`\n\tMetricsPath            string            `json:\"metrics_path\"`\n\tJob                    string            `json:\"job\"`\n\tTaskDefinitionFamily   string            `json:\"task_definition_family\"`\n\tTaskDefinitionRevision int               `json:\"task_definition_revision\"`\n\tTaskLaunchType         string            `json:\"task_launch_type\"`\n\tTaskGroup              string            `json:\"task_group\"`\n\tTaskTags               map[string]string `json:\"task_tags\"`\n\tContainerName          string            `json:\"container_name\"`\n\tContainerLabels        map[string]string `json:\"container_labels\"`\n\tHealthStatus           string            `json:\"health_status\"`\n\tEC2InstanceId          string            `json:\"ec2_instance_id\"`\n\tEC2InstanceType        string            `json:\"ec2_instance_type\"`\n\tEC2Tags                map[string]string `json:\"ec2_tags\"`\n\tEC2VPCId               string            `json:\"ec2_vpc_id\"`\n\tEC2PrivateIP           string            `json:\"ec2_private_ip\"`\n\tEC2PublicIP            string            `json:\"ec2_public_ip\"`\n}\n```\n\n### Delta\n\nDelta is **not** supported because there is no watch API in ECS (unlike k8s, see [known issues](#known-issues)). The\noutput always contains all the targets. Caller/Consumer need to implement their own logic to calculate the targets diff\nif they only want to process new targets.\n\n## Known issues\n\n- There is no list watch API in ECS (unlike k8s), and we fetch ALL the tasks and filter it locally. If the poll interval\n  is too short or there are multiple instances doing discovery, you may hit the (undocumented) API rate limit. In memory\n  caching is implemented to reduce calls for task definition and ec2.\n- A single collector may not be able to handle a large cluster, you can use `hashmod`\n  in [relabel_config](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config) to do\n  static sharding. However, too many collectors may trigger the rate limit on AWS API as each shard is fetching ALL the\n  tasks during discovery regardless of number of shards.\n\n## Implementation\n\nThe implementation has two parts, core ecs service discovery logic and adapter for notifying discovery results.\n\n### Packages\n\n- `extension/observer/ecsobserver` main logic\n- [internal/ecsmock](internal/ecsmock) mock ECS cluster\n- [internal/errctx](internal/errctx) structured error wrapping\n\n### Flow\n\nThe pseudocode showing the overall flow.\n\n```\nNewECSSD() {\n  session := awsconfig.NewSssion()\n  ecsClient := awsecs.NewClient(session)\n  filters := config.NewFileters()\n  decorator := awsec2.NewClient(session)\n  for {\n    select {\n    case \u003c- timer:\n      // Fetch ALL\n      tasks := ecsClient.FaetchAll()\n      // Filter\n      filteredTasks := fileters.Apply(tasks)\n      // Add EC2 info\n      decorator.Apply(filteredTask)\n      // Generate output\n      if writeResultFile {\n         writeFile(fileteredTasks, /etc/ecs_sd.yaml)\n      } else {\n          notifyObserver()\n      }\n    }\n  }\n}\n```\n\n### Metrics\n\nFollowing metrics are logged at debug level. TODO(pingleig): Is there a way for otel plugins to export custom metrics to\notel's own /metrics.\n\n| Name                                 | Type | Description                                                                                                                                                     |\n|--------------------------------------|------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| `discovered_targets`                 | int  | Number of targets exported                                                                                                                                      |\n| `discovered_taskss`                  | int  | Number of tasks that contains scrape target, should be smaller than targets unless each task only contains one target                                           |\n| `ignored_tasks`                      | int  | Tasks ignored by filter, `discovered_tasks` and  `ignored_tasks` should add up to `api_ecs_list_task_results`, one exception is API paging failed in the middle |\n| `targets_matched_by_service`         | int  | ECS Service name based filter                                                                                                                                   |\n| `targets_matched_by_task_definition` | int  | ECS TaskDefinition based filter                                                                                                                                 |\n| `targets_matched_by_docker_label`    | int  | ECS DockerLabel based filter                                                                                                                                    |\n| `target_error_noip`                  | int  | Export failures because private ip not found                                                                                                                    |\n| `api_ecs_list_task_results`          | int  | Total number of tasks returned from ECS ListTask API                                                                                                            |\n| `api_ecs_list_service_results`       | int  | Total number of services returned from ECS ListService API                                                                                                      |\n| `api_error_auth`                     | int  | Total number of error triggered by permission                                                                                                                   |\n| `api_error_rate_limit`               | int  | Total number of error triggered by rate limit                                                                                                                   |\n| `cache_size_container_instances`     | int  | Cached ECS ContainerInstance                                                                                                                                    |\n| `cache_hit_container_instance`       | int  | Cache hit during the latest polling                                                                                                                             |\n| `cache_size_ec2_instance`            | int  | Cached EC2 Instance                                                                                                                                             |\n| `cache_hit_ec2_instance`             | int  | Cache hit during the latest polling                                                                                                                             |\n\n### Error Handling\n\n- Auth and cluster not found error will cause the extension to stop (calling `host.ReportFatalError`). Although IAM role\n  can be updated at runtime without restarting the collector, it's better to fail to make the problem obvious. Same\n  applies to cluster not found. In the future we can add config to downgrade those errors if user want to monitor an ECS\n  cluster with collector running outside the cluster, the collector can run anywhere as long as it can reach scrape\n  targets and AWS API.\n- If we have non-critical error, we overwrite existing file with whatever targets we have, we might not have all the\n  targets due to throttle etc.\n\n### Unit Test\n\nA mock ECS and EC2 server is in [internal/ecsmock](internal/ecsmock), see [fetcher_test](fetcher_test.go) for its usage.\n\n### Integration Test\n\nWill be implemented in [AOT Testing Framework](https://github.com/aws-observability/aws-otel-test-framework) to run\nagainst actual ECS service on both EC2 and Fargate.\n\n## Changelog\n\n- 2021-06-02 first version that actually works on ECS by @pingleig, thanks @anuraaga @Aneurysm9 @jrcamp @mxiamxia for\n  reviewing (all the PRs ...)\n- 2021-02-24 Updated doc by @pingleig\n- 2020-12-29 Initial implementation by [Raphael](https://github.com/theRoughCode)\n  in [#1920](https://github.com/open-telemetry/opentelemetry-collector-contrib/pull/1920)","properties":{"container_name_pattern":{"description":"ContainerNamePattern is optional, empty string means all containers in that service would be exported.\nOtherwise both service and container name petterns need to metch.","title":"container_name_pattern","type":"string"},"job_name":{"title":"job_name","type":"string"},"metrics_path":{"title":"metrics_path","type":"string"},"metrics_ports":{"items":{"type":"integer"},"title":"metrics_ports","type":"array"},"name_pattern":{"description":"NamePattern is mandatory.","title":"name_pattern","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.extension.observer.ecsobserver.TaskDefinitionConfig":{"additionalProperties":false,"properties":{"arn_pattern":{"description":"ArnPattern is mandetory, empty string means arn based match is skipped.","title":"arn_pattern","type":"string"},"container_name_pattern":{"description":"ContainerNamePattern is optional, empty string means all containers in that task definition would be exported.\nOtherwise both service and container name petterns need to metch.","title":"container_name_pattern","type":"string"},"job_name":{"title":"job_name","type":"string"},"metrics_path":{"title":"metrics_path","type":"string"},"metrics_ports":{"items":{"type":"integer"},"title":"metrics_ports","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.extension.observer.ecstaskobserver.Config":{"additionalProperties":false,"markdownDescription":"# ECS Task Observer\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]  |\n| Distributions | [contrib], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe `ecs_task_observer` is a [Receiver Creator](../../../receiver/receivercreator/README.md)-compatible \"watch observer\" that will detect and report\ncontainer endpoints for the running ECS task of which your Collector instance is a member. It is designed for and only supports \"sidecar\" deployments\nto detect co-located containers. For cluster wide use cases you should use the [ECS Observer](../ecsobserver/README.md) with a corresponding Prometheus receiver.\n\nThe Observer works by querying the available [task metadata endpoint](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-metadata-endpoint.html)\nand making all detected running containers available as endpoints for Receiver Creator usage. Because container metadata don't include any port mapping information,\nyou must include service-specific port `dockerLabels` in your task definition container entries. A docker label of `ECS_TASK_OBSERVER_PORT` with a valid port\nvalue will be attempted to be parsed for each reported container by default.\n\n**An instance of the Collector must be running in the ECS task from which you want to detect containers.**\n\n\u003e :construction: This extension is in alpha and configuration fields are subject to change.\n\n## Example Config\n\n```yaml\nextensions:\n  ecs_task_observer:\n    # the task metadata endpoint. If not set, detected by first of ECS_CONTAINER_METADATA_URI_V4 and ECS_CONTAINER_METADATA_URI\n    # environment variables by default.\n    endpoint: http://my.task.metadata.endpoint\n    # the dockerLabels to use to try to extract target application ports. If not set \"ECS_TASK_OBSERVER_PORT\" will be used by default.\n    port_labels: [A_DOCKER_LABEL_CONTAINING_DESIRED_PORT, ANOTHER_DOCKER_LABEL_CONTAINING_DESIRED_PORT]\n    refresh_interval: 10s\n\nreceivers:\n  receiver_creator:\n    receivers:\n      redis:\n        rule: type == \"container\" \u0026\u0026 name matches \"redis\"\n        config:\n          password: `container.labels[\"SECRET\"]`\n    watch_observers: [ecs_task_observer]\n```\n\nThe above config defines a custom task metadata endpoint and provides two port labels that will be used to set the resulting container endpoint's `port`.\nA corresponding redis container definition could look like the following:\n\n```json\n{\n  \"containerDefinitions\": [\n    {\n      \"portMappings\": [\n        {\n          \"containerPort\": 6379,\n          \"hostPort\": 6379\n        }\n      ],\n      \"image\": \"redis\",\n      \"dockerLabels\": {\n        \"A_DOCKER_LABEL_CONTAINING_DESIRED_PORT\": \"6379\",\n        \"SECRET\": \"my-redis-auth\"\n      },\n      \"name\": \"redis\"\n    }\n  ]\n}\n```\n\n\n### Config\n\nAs a rest client-utilizing extension, most of the ECS Task Observer's configuration is inherited from the Collector core\n[HTTP Client Configuration Settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/confighttp/README.md#client-configuration).\n\nAll fields are optional.\n\n| Name | Type | Default | Docs |\n| ---- | ---- | ------- | ---- |\n| endpoint |string| \u003cno value\u003e | The task metadata endpoint, detected from first of `ECS_CONTAINER_METADATA_URI_V4` and `ECS_CONTAINER_METADATA_URI` environment variables by default |\n| tls |[configtls-TLSClientSetting](#configtls-tlsclientsetting)| \u003cno value\u003e | TLSSetting struct exposes TLS client configuration.  |\n| read_buffer_size |int| \u003cno value\u003e | ReadBufferSize for HTTP client. See http.Transport.ReadBufferSize.  |\n| write_buffer_size |int| \u003cno value\u003e | WriteBufferSize for HTTP client. See http.Transport.WriteBufferSize.  |\n| timeout |[time-Duration](#time-duration)| \u003cno value\u003e | Timeout parameter configures `http.Client.Timeout`.  |\n| headers |map[string]string| \u003cno value\u003e | Additional headers attached to each HTTP request sent by the client. Existing header values are overwritten if collision happens.  |\n| customroundtripper |func(http.RoundTripper) (http.RoundTripper, error)| \u003cno value\u003e | Custom Round Tripper to allow for individual components to intercept HTTP requests  |\n| auth |[Authentication]| \u003cno value\u003e | Auth configuration for outgoing HTTP calls.  |\n| refresh_interval |[time-Duration](#time-duration)| 30s | RefreshInterval determines the frequency at which the observer needs to poll for collecting new information about task containers.  |\n| port_labels |[]string| `[ECS_TASK_OBSERVER_PORT]` | PortLabels is a list of container Docker labels from which to obtain the observed Endpoint port. The first label with valid port found will be used.  If no PortLabels provided, default of ECS_TASK_OBSERVER_PORT will be used.  |\n\n### configtls-TLSClientSetting\n\n| Name | Type | Default | Docs |\n| ---- | ---- | ------- | ---- |\n| ca_file |string| \u003cno value\u003e | Path to the CA cert. For a client this verifies the server certificate. For a server this verifies client certificates. If empty uses system root CA. (optional)  |\n| cert_file |string| \u003cno value\u003e | Path to the TLS cert to use for TLS required connections. (optional)  |\n| key_file |string| \u003cno value\u003e | Path to the TLS key to use for TLS required connections. (optional)  |\n| min_version |string| \u003cno value\u003e | MinVersion sets the minimum TLS version that is acceptable. If not set, TLS 1.0 is used. (optional)  |\n| max_version |string| \u003cno value\u003e | MaxVersion sets the maximum TLS version that is acceptable. If not set, TLS 1.3 is used. (optional)  |\n| insecure |bool| \u003cno value\u003e | In gRPC when set to true, this is used to disable the client transport security. See https://godoc.org/google.golang.org/grpc#WithInsecure. In HTTP, this disables verifying the server's certificate chain and host name (InsecureSkipVerify in the tls Config). Please refer to https://godoc.org/crypto/tls#Config for more information. (optional, default false)  |\n| insecure_skip_verify |bool| \u003cno value\u003e | InsecureSkipVerify will enable TLS but not verify the certificate.  |\n| server_name_override |string| \u003cno value\u003e | ServerName requested by client for virtual hosting. This sets the ServerName in the TLSConfig. Please refer to https://godoc.org/crypto/tls#Config for more information. (optional)  |\n\n### time-Duration\nAn optionally signed sequence of decimal numbers, each with a unit suffix, such as `300ms`, `-1.5h`, or `2h45m`. Valid time units are `ns`, `us`, `ms`, `s`, `m`, `h`.\n\n[Authentication]: https://github.com/open-telemetry/opentelemetry-collector/tree/main/config/configauth","properties":{"CustomRoundTripper":{"description":"Custom Round Tripper to allow for individual components to intercept HTTP requests","title":"CustomRoundTripper"},"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth configuration for outgoing HTTP calls.","title":"auth"},"compression":{"description":"The compression key for supported compression types within collector.","title":"compression","type":"string"},"endpoint":{"description":"The target URL to send data to (e.g.: http://some.url:9411/v1/traces).","title":"endpoint","type":"string"},"headers":{"description":"Additional headers attached to each HTTP request sent by the client.\nExisting header values are overwritten if collision happens.\nHeader values are opaque since they may be sensitive.","patternProperties":{".*":{"type":"string"}},"title":"headers","type":"object"},"idle_conn_timeout":{"description":"IdleConnTimeout is the maximum amount of time a connection will remain open before closing itself.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"idle_conn_timeout","type":"string"},"max_conns_per_host":{"description":"MaxConnsPerHost limits the total number of connections per host, including connections in the dialing,\nactive, and idle states.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_conns_per_host","type":"integer"},"max_idle_conns":{"description":"MaxIdleConns is used to set a limit to the maximum idle HTTP connections the client can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns","type":"integer"},"max_idle_conns_per_host":{"description":"MaxIdleConnsPerHost is used to set a limit to the maximum idle HTTP connections the host can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns_per_host","type":"integer"},"port_labels":{"description":"PortLabels is a list of container Docker labels from which to obtain the observed Endpoint port.\nThe first label with valid port found will be used.  If no PortLabels provided, default of\nECS_TASK_OBSERVER_PORT will be used.","items":{"type":"string"},"title":"port_labels","type":"array"},"read_buffer_size":{"description":"ReadBufferSize for HTTP client. See http.Transport.ReadBufferSize.","title":"read_buffer_size","type":"integer"},"refresh_interval":{"description":"RefreshInterval determines the frequency at which the observer\nneeds to poll for collecting new information about task containers.","title":"refresh_interval","type":"string"},"timeout":{"description":"Timeout parameter configures `http.Client.Timeout`.","title":"timeout","type":"string"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","description":"TLSSetting struct exposes TLS client configuration.","title":"tls"},"write_buffer_size":{"description":"WriteBufferSize for HTTP client. See http.Transport.WriteBufferSize.","title":"write_buffer_size","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.extension.observer.hostobserver.Config":{"additionalProperties":false,"description":"Config defines configuration for host observer.","markdownDescription":"# Host Observer Extension\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]  |\n| Distributions | [contrib], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe `host_observer` looks at the current host for listening network endpoints.\n\nIt will look for all listening sockets on TCP and UDP over IPv4 and IPv6.\n\nIt uses the /proc filesystem and requires the SYS_PTRACE and DAC_READ_SEARCH capabilities so that it can determine what processes own the listening sockets.\n\n### Configuration\n\n#### `refresh_interval`\n\nDetermines how often to look for changes in endpoints.\n\ndefault: `10s`\n\n### Endpoint Variables\n\nEndpoint variables exposed by this observer are as follows.\n\n| Variable  | Description                                                                                |\n|-----------|--------------------------------------------------------------------------------------------|\n| type      | `\"port\"`                                                                                     |\n| name      | name of the process associated to the port                                                 |\n| port      | port number                                                                                |\n| command   | full command used to invoke this process, including the executable itself at the beginning |\n| is_ipv6   | `true` if the endpoint is IPv6                                                             |\n| transport | \"TCP\" or \"UDP\"                                                                             |","properties":{"refresh_interval":{"description":"RefreshInterval determines how frequency at which the observer\nneeds to poll for collecting information about new processes.","title":"refresh_interval","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.extension.observer.k8sobserver.Config":{"additionalProperties":false,"description":"Config defines configuration for k8s attributes processor.","markdownDescription":"# Kubernetes Observer\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [alpha]  |\n| Distributions | [contrib], [splunk], [sumo] |\n\n[alpha]: https://github.com/open-telemetry/opentelemetry-collector#alpha\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe `k8s_observer` is a [Receiver Creator](../../../receiver/receivercreator/README.md)-compatible \"watch observer\" that will detect and report\nKubernetes pod, port, and node endpoints via the Kubernetes API.\n\n## Example Config\n\n```yaml\nextensions:\n  k8s_observer:\n    auth_type: serviceAccount\n    node: ${env:K8S_NODE_NAME}\n    observe_pods: true\n    observe_nodes: true\n\nreceivers:\n  receiver_creator:\n    watch_observers: [k8s_observer]\n    receivers:\n      redis:\n        rule: type == \"port\" \u0026\u0026 pod.name matches \"redis\"\n        config:\n          password: '`pod.labels[\"SECRET\"]`'\n      kubeletstats:\n        rule: type == \"k8s.node\"\n        config:\n          auth_type: serviceAccount\n          collection_interval: 10s\n          endpoint: \"`endpoint`:`kubelet_endpoint_port`\"\n          extra_metadata_labels:\n            - container.id\n          metric_groups:\n            - container\n            - pod\n            - node\n```\n\nThe `node` field can be set to the node name to limit discovered endpoints. For example, its name value can be obtained using the downward API inside a Collector pod spec as follows:\n\n```yaml\nenv:\n  - name: K8S_NODE_NAME\n    valueFrom:\n      fieldRef:\n        fieldPath: spec.nodeName\n```\n\nThis spec-determined value would then be available via the `${env:K8S_NODE_NAME}` usage in the observer configuration.\n\n## Config\n\nAll fields are optional.\n\n| Name | Type | Default | Docs |\n| ---- | ---- | ------- | ---- |\n| auth_type | string | `serviceAccount` | How to authenticate to the K8s API server.  This can be one of `none` (for no auth), `serviceAccount` (to use the standard service account token provided to the agent pod), or `kubeConfig` to use credentials from `~/.kube/config`. |\n| node | string | \u003cno value\u003e | The node name to limit the discovery of pod, port, and node endpoints. Providing no value (the default) results in discovering endpoints for all available nodes. |\n| observe_pods | bool | `true` | Whether to report observer pod and port endpoints. If `true` and `node` is specified it will only discover pod and port endpoints whose `spec.nodeName` matches the provided node name. If `true` and `node` isn't specified, it will discover all available pod and port endpoints. Please note that Collector connectivity to pods from other nodes is dependent on your cluster configuration and isn't guaranteed. | \n| observe_nodes | bool | `false` | Whether to report observer k8s.node endpoints. If `true` and `node` is specified it will only discover node endpoints whose `metadata.name` matches the provided node name. If `true` and `node` isn't specified, it will discover all available node endpoints. Please note that Collector connectivity to nodes is dependent on your cluster configuration and isn't guaranteed.|","properties":{"auth_type":{"description":"How to authenticate to the K8s API server.  This can be one of `none`\n(for no auth), `serviceAccount` (to use the standard service account\ntoken provided to the agent pod), or `kubeConfig` to use credentials\nfrom `~/.kube/config`.","title":"auth_type","type":"string"},"node":{"description":"Node is the node name to limit the discovery of pod, port, and node endpoints.\nProviding no value (the default) results in discovering endpoints for all available nodes.\nFor example, node name can be set using the downward API inside the collector\npod spec as follows:\n\nenv:\n  - name: K8S_NODE_NAME\n    valueFrom:\n      fieldRef:\n        fieldPath: spec.nodeName\n\nThen set this value to ${env:K8S_NODE_NAME} in the configuration.","title":"node","type":"string"},"observe_nodes":{"description":"ObserveNodes determines whether to report observer k8s.node endpoints. If `true` and Node is specified\nit will only discover node endpoints whose `metadata.name` matches the provided node name. If `true` and\nNode isn't specified, it will discover all available node endpoints. `false` by default.","title":"observe_nodes","type":"boolean"},"observe_pods":{"description":"ObservePods determines whether to report observer pod and port endpoints. If `true` and Node is specified\nit will only discover pod and port endpoints whose `spec.nodeName` matches the provided node name. If `true` and\nNode isn't specified, it will discover all available pod and port endpoints. `true` by default.","title":"observe_pods","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.extension.oidcauthextension.Config":{"additionalProperties":false,"description":"Config has the configuration for the OIDC Authenticator extension.","markdownDescription":"# Authenticator - OIDC\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]  |\n| Distributions | [contrib], [observiq], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThis extension implements a `configauth.ServerAuthenticator`, to be used in receivers inside the `auth` settings. The authenticator type has to be set to `oidc`.\n\n## Configuration\n\n```yaml\nextensions:\n  oidc:\n    issuer_url: http://localhost:8080/auth/realms/opentelemetry\n    issuer_ca_path: /etc/pki/tls/cert.pem\n    audience: account\n    username_claim: email\n\nreceivers:\n  otlp:\n    protocols:\n      grpc:\n        auth:\n          authenticator: oidc\n\nprocessors:\n\nexporters:\n  logging:\n    logLevel: debug\n\nservice:\n  extensions: [oidc]\n  pipelines:\n    traces:\n      receivers: [otlp]\n      processors: []\n      exporters: [logging]\n```","properties":{"attribute":{"description":"The attribute (header name) to look for auth data. Optional, default value: \"authorization\".","title":"attribute","type":"string"},"audience":{"description":"Audience of the token, used during the verification.\nFor example: \"https://accounts.google.com\" or \"https://login.salesforce.com\".\nRequired.","title":"audience","type":"string"},"groups_claim":{"description":"The claim that holds the subject's group membership information.\nOptional.","title":"groups_claim","type":"string"},"issuer_ca_path":{"description":"The local path for the issuer CA's TLS server cert.\nOptional.","title":"issuer_ca_path","type":"string"},"issuer_url":{"description":"IssuerURL is the base URL for the OIDC provider.\nRequired.","title":"issuer_url","type":"string"},"username_claim":{"description":"The claim to use as the username, in case the token's 'sub' isn't the suitable source.\nOptional.","title":"username_claim","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.extension.pprofextension.Config":{"additionalProperties":false,"description":"Config has the configuration for the extension enabling the golang net/http/pprof (Performance Profiler) extension.","markdownDescription":"# Performance Profiler\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]  |\n| Distributions | [core], [contrib], [aws], [observiq], [redhat], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[core]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[redhat]: https://github.com/os-observability/redhat-opentelemetry-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nPerformance Profiler extension enables the golang `net/http/pprof` endpoint.\nThis is typically used by developers to collect performance profiles and\ninvestigate issues with the service.\n\nThe following settings are required:\n\n- `endpoint` (default = localhost:1777): The endpoint in which the pprof will\nbe listening to. Use localhost:\u003cport\u003e to make it available only locally, or\n\":\u003cport\u003e\" to make it available on all network interfaces.\n- `block_profile_fraction` (default = 0): Fraction of blocking events that\nare profiled. A value \u003c= 0 disables profiling. See\nhttps://golang.org/pkg/runtime/#SetBlockProfileRate for details.\n- `mutex_profile_fraction` (default = 0): Fraction of mutex contention\nevents that are profiled. A value \u003c= 0 disables profiling. See\nhttps://golang.org/pkg/runtime/#SetMutexProfileFraction for details.\n\nThe following settings can be optionally configured:\n\n- `save_to_file`: File name to save the CPU profile to. The profiling starts when the\nCollector starts and is saved to the file when the Collector is terminated.\n\nExample:\n```yaml\n\nextensions:\n  pprof:\n```\n\nThe full list of settings exposed for this exporter are documented [here](./config.go)\nwith detailed sample configurations [here](./testdata/config.yaml).","properties":{"block_profile_fraction":{"description":"Fraction of blocking events that are profiled. A value \u003c= 0 disables\nprofiling. See https://golang.org/pkg/runtime/#SetBlockProfileRate for details.","title":"block_profile_fraction","type":"integer"},"endpoint":{"description":"Endpoint configures the address for this network connection.\nThe address has the form \"host:port\". The host must be a literal IP address, or a host name that can be\nresolved to IP addresses. The port must be a literal port number or a service name.\nIf the host is a literal IPv6 address it must be enclosed in square brackets, as in \"[2001:db8::1]:80\" or\n\"[fe80::1%zone]:80\". The zone specifies the scope of the literal IPv6 address as defined in RFC 4007.","title":"endpoint","type":"string"},"mutex_profile_fraction":{"description":"Fraction of mutex contention events that are profiled. A value \u003c= 0\ndisables profiling. See https://golang.org/pkg/runtime/#SetMutexProfileFraction\nfor details.","title":"mutex_profile_fraction","type":"integer"},"save_to_file":{"description":"Optional file name to save the CPU profile to. The profiling starts when the\nCollector starts and is saved to the file when the Collector is terminated.","title":"save_to_file","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.internal.aws.proxy.Config":{"additionalProperties":false,"description":"Config is the configuration for the local TCP proxy server.","properties":{"aws_endpoint":{"description":"AWSEndpoint is the X-Ray service endpoint which the local\nTCP server forwards requests to.","title":"aws_endpoint","type":"string"},"endpoint":{"description":"Endpoint configures the address for this network connection.\nThe address has the form \"host:port\". The host must be a literal IP address, or a host name that can be\nresolved to IP addresses. The port must be a literal port number or a service name.\nIf the host is a literal IPv6 address it must be enclosed in square brackets, as in \"[2001:db8::1]:80\" or\n\"[fe80::1%zone]:80\". The zone specifies the scope of the literal IPv6 address as defined in RFC 4007.","title":"endpoint","type":"string"},"local_mode":{"description":"LocalMode determines whether the EC2 instance metadata endpoint\nwill be called or not. Set to `true` to skip EC2 instance\nmetadata check.","title":"local_mode","type":"boolean"},"proxy_address":{"description":"ProxyAddress defines the proxy address that the local TCP server\nforwards HTTP requests to AWS X-Ray backend through.","title":"proxy_address","type":"string"},"region":{"description":"Region is the AWS region the local TCP server forwards requests to.","title":"region","type":"string"},"role_arn":{"description":"RoleARN is the IAM role used by the local TCP server when\ncommunicating with the AWS X-Ray service.","title":"role_arn","type":"string"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","description":"TLSSetting struct exposes TLS client configuration when forwarding\ncalls to the AWS X-Ray backend.","title":"tls"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.internal.coreinternal.attraction.ActionKeyValue":{"additionalProperties":false,"description":"ActionKeyValue specifies the attribute key to act upon.","properties":{"action":{"description":"Action specifies the type of action to perform.\nThe set of values are {INSERT, UPDATE, UPSERT, DELETE, HASH}.\nBoth lower case and upper case are supported.\nINSERT -  Inserts the key/value to attributes when the key does not exist.\n          No action is applied to attributes where the key already exists.\n          Either Value, FromAttribute or FromContext must be set.\nUPDATE -  Updates an existing key with a value. No action is applied\n          to attributes where the key does not exist.\n          Either Value, FromAttribute or FromContext must be set.\nUPSERT -  Performs insert or update action depending on the attributes\n          containing the key. The key/value is inserted to attributes\n          that did not originally have the key. The key/value is updated\n          for attributes where the key already existed.\n          Either Value, FromAttribute or FromContext must be set.\nDELETE  - Deletes the attribute. If the key doesn't exist,\n          no action is performed.\nHASH    - Calculates the SHA-1 hash of an existing value and overwrites the\n          value with its SHA-1 hash result. If the feature gate\n          `coreinternal.attraction.hash.sha256` is enabled, it uses SHA2-256\n          instead.\nEXTRACT - Extracts values using a regular expression rule from the input\n          'key' to target keys specified in the 'rule'. If a target key\n          already exists, it will be overridden.\nCONVERT  - converts the type of an existing attribute, if convertable\nThis is a required field.","title":"action","type":"string"},"converted_type":{"description":"ConvertedType specifies the target type of an attribute to be converted\nIf the key doesn't exist, no action is performed.\nIf the value cannot be converted, the original value will be left as-is","title":"converted_type","type":"string"},"from_attribute":{"description":"FromAttribute specifies the attribute to use to populate\nthe value. If the attribute doesn't exist, no action is performed.","title":"from_attribute","type":"string"},"from_context":{"description":"FromContext specifies the context value to use to populate\nthe value. The values would be searched in client.Info.Metadata.\nIf the key doesn't exist, no action is performed.\nIf the key has multiple values the values will be joined with `;` separator.","title":"from_context","type":"string"},"key":{"description":"Key specifies the attribute to act upon.\nThis is a required field.","title":"key","type":"string"},"pattern":{"description":"A regex pattern  must be specified for the action EXTRACT.\nIt uses the attribute specified by `key' to extract values from\nThe target keys are inferred based on the names of the matcher groups\nprovided and the names will be inferred based on the values of the\nmatcher group.\nNote: All subexpressions must have a name.\nNote: The value type of the source key must be a string. If it isn't,\nno extraction will occur.","title":"pattern","type":"string"},"value":{"description":"Value specifies the value to populate for the key.\nThe type of the value is inferred from the configuration.","title":"value"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterconfig.Attribute":{"additionalProperties":false,"description":"Attribute specifies the attribute key and optional value to match against.","properties":{"key":{"description":"Key specifies the attribute key.","title":"key","type":"string"},"value":{"description":"Values specifies the value to match against.\nIf it is not set, any value will match.","title":"value"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterconfig.InstrumentationLibrary":{"additionalProperties":false,"description":"InstrumentationLibrary specifies the instrumentation library and optional version to match against.","properties":{"name":{"title":"name","type":"string"},"version":{"description":"version match\n expected actual  match\n nil      \u003cblank\u003e yes\n nil      1       yes\n \u003cblank\u003e  \u003cblank\u003e yes\n \u003cblank\u003e  1       no\n 1        \u003cblank\u003e no\n 1        1       yes","title":"version","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterconfig.LogSeverityNumberMatchProperties":{"additionalProperties":false,"description":"LogSeverityNumberMatchProperties defines how to match based on a log record's SeverityNumber field.","properties":{"match_undefined":{"description":"MatchUndefined controls whether logs with \"undefined\" severity matches.\nIf this is true, entries with undefined severity will match.","title":"match_undefined","type":"boolean"},"min":{"description":"Min is the lowest severity that may be matched.\ne.g. if this is plog.SeverityNumberInfo, INFO, WARN, ERROR, and FATAL logs will match.","title":"min","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterconfig.MatchConfig":{"additionalProperties":false,"description":"MatchConfig has two optional MatchProperties one to define what is processed by the processor, captured under the 'include' and the second, exclude, to define what is excluded from the processor.","properties":{"exclude":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterconfig.MatchProperties","description":"Exclude specifies when this processor will not be applied to the input data\nwhich match the specified properties.\nNote: The `exclude` properties are checked after the `include` properties,\nif they exist, are checked.\nIf `include` isn't specified, the `exclude` properties are checked against\nall input data.\nThis is an optional field. If neither `include` and `exclude` are set, all input data\nis processed. If `exclude` is set and `include` isn't set, then all the\ninput data that does not match the properties in this structure are processed.","title":"exclude"},"include":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterconfig.MatchProperties","description":"Include specifies the set of input data properties that must be present in order\nfor this processor to apply to it.\nNote: If `exclude` is specified, the input data is compared against those\nproperties after the `include` properties.\nThis is an optional field. If neither `include` and `exclude` are set, all input data\nare processed. If `include` is set and `exclude` isn't set, then all\ninput data matching the properties in this structure are processed.","title":"include"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterconfig.MatchProperties":{"additionalProperties":false,"description":"MatchProperties specifies the set of properties in a spans/log/metric to match against and if the input data should be included or excluded from the processor.","properties":{"attributes":{"description":"Attributes specifies the list of attributes to match against.\nAll of these attributes must match exactly for a match to occur.\nOnly match_type=strict is allowed if \"attributes\" are specified.\nThis is an optional field.","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterconfig.Attribute"},"title":"attributes","type":"array"},"libraries":{"description":"Libraries specify the list of items to match the implementation library against.\nA match occurs if the span's implementation library matches at least one item in this list.\nThis is an optional field.","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterconfig.InstrumentationLibrary"},"title":"libraries","type":"array"},"log_bodies":{"description":"LogBodies is a list of strings that the LogRecord's body field must match\nagainst.","items":{"type":"string"},"title":"log_bodies","type":"array"},"log_severity_number":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterconfig.LogSeverityNumberMatchProperties","description":"LogSeverityNumber defines how to match against a log record's SeverityNumber, if defined.","title":"log_severity_number"},"log_severity_texts":{"description":"LogSeverityTexts is a list of strings that the LogRecord's severity text field must match\nagainst.","items":{"type":"string"},"title":"log_severity_texts","type":"array"},"match_type":{"title":"match_type","type":"string"},"metric_names":{"description":"MetricNames is a list of strings to match metric name against.\nA match occurs if metric name matches at least one item in the list.\nThis field is optional.","items":{"type":"string"},"title":"metric_names","type":"array"},"regexp":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterset.regexp.Config","title":"regexp"},"resources":{"description":"Resources specify the list of items to match the resources against.\nA match occurs if the data's resources match at least one item in this list.\nThis is an optional field.","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterconfig.Attribute"},"title":"resources","type":"array"},"services":{"description":"Services specify the list of items to match service name against.\nA match occurs if the span's service name matches at least one item in this list.\nThis is an optional field.","items":{"type":"string"},"title":"services","type":"array"},"span_kinds":{"description":"SpanKinds specify the list of items to match the span kind against.\nA match occurs if the span's span kind matches at least one item in this list.\nThis is an optional field","items":{"type":"string"},"title":"span_kinds","type":"array"},"span_names":{"description":"SpanNames specify the list of items to match span name against.\nA match occurs if the span name matches at least one item in this list.\nThis is an optional field.","items":{"type":"string"},"title":"span_names","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterconfig.MetricMatchProperties":{"additionalProperties":false,"description":"MetricMatchProperties specifies the set of properties in a metric to match against and the type of string pattern matching to use.","properties":{"expressions":{"description":"Expressions specifies the list of expr expressions to match metrics against.\nA match occurs if any datapoint in a metric matches at least one expression in this list.","items":{"type":"string"},"title":"expressions","type":"array"},"match_type":{"description":"MatchType specifies the type of matching desired","title":"match_type","type":"string"},"metric_names":{"description":"MetricNames specifies the list of string patterns to match metric names against.\nA match occurs if the metric name matches at least one string pattern in this list.","items":{"type":"string"},"title":"metric_names","type":"array"},"regexp":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterset.regexp.Config","description":"RegexpConfig specifies options for the MetricRegexp match type","title":"regexp"},"resource_attributes":{"description":"ResourceAttributes defines a list of possible resource attributes to match metrics against.\nA match occurs if any resource attribute matches all expressions in this given list.","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterconfig.Attribute"},"title":"resource_attributes","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterset.regexp.Config":{"additionalProperties":false,"description":"Config represents the options for a NewFilterSet.","properties":{"cacheenabled":{"description":"CacheEnabled determines whether match results are LRU cached to make subsequent matches faster.\nCache size is unlimited unless CacheMaxNumEntries is also specified.","title":"cacheenabled","type":"boolean"},"cachemaxnumentries":{"description":"CacheMaxNumEntries is the max number of entries of the LRU cache that stores match results.\nCacheMaxNumEntries is ignored if CacheEnabled is false.","title":"cachemaxnumentries","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.internal.k8sconfig.APIConfig":{"additionalProperties":false,"description":"APIConfig contains options relevant to connecting to the K8s API","properties":{"auth_type":{"description":"How to authenticate to the K8s API server.  This can be one of `none`\n(for no auth), `serviceAccount` (to use the standard service account\ntoken provided to the agent pod), or `kubeConfig` to use credentials\nfrom `~/.kube/config`.","title":"auth_type","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.pkg.resourcetotelemetry.Settings":{"additionalProperties":false,"description":"Settings defines configuration for converting resource attributes to telemetry attributes.","markdownDescription":"# Resource to Telemetry\n\nThis is an exporter helper for converting resource attributes to telemetry attributes.\nThis helper can be used to wrap other exporters.\n\n\u003e :warning: This exporter helper should not be added to a service pipeline.\n\n## Configuration\n\nThe following configuration options can be modified:\n\n- `resource_to_telemetry_conversion`\n    - `enabled` (default = false): If `enabled` is `true`, all the resource attributes will be converted to metric labels by default.","properties":{"enabled":{"description":"Enabled indicates whether to convert resource attributes to telemetry attributes. Default is `false`.","title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.attributesprocessor.Config":{"additionalProperties":false,"description":"Config specifies the set of attributes to be inserted, updated, upserted and deleted and the properties to include/exclude a span from being processed.","markdownDescription":"# Attributes Processor\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: traces, metrics, logs   |\n| Distributions | [core], [contrib], [aws], [observiq], [splunk], [sumo] |\n| Warnings      | [Identity Conflict](#warnings) |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[core]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe attributes processor modifies attributes of a span, log, or metric. Please refer to\n[config.go](./config.go) for the config spec.\n\nThis processor also supports the ability to filter and match input data to determine\nif they should be [included or excluded](#includeexclude-filtering) for specified actions.\n\nIt takes a list of actions which are performed in order specified in the config.\nThe supported actions are:\n- `insert`: Inserts a new attribute in input data where the key does not already exist.\n- `update`: Updates an attribute in input data where the key does exist.\n- `upsert`: Performs insert or update. Inserts a new attribute in input data where the\n  key does not already exist and updates an attribute in input data where the key\n  does exist.\n- `delete`: Deletes an attribute from the input data.\n- `hash`: Hashes (SHA1) an existing attribute value.\n- `extract`: Extracts values using a regular expression rule from the input key\n  to target keys specified in the rule. If a target key already exists, it will\n  be overridden. Note: It behaves similar to the Span Processor `to_attributes`\n  setting with the existing attribute as the source.\n- `convert`: Converts an existing attribute to a specified type.\n\nFor the actions `insert`, `update` and `upsert`,\n - `key`  is required\n - one of `value`, `from_attribute` or `from_context` is required\n - `action` is required.\n```yaml\n  # Key specifies the attribute to act upon.\n- key: \u003ckey\u003e\n  action: {insert, update, upsert}\n  # Value specifies the value to populate for the key.\n  # The type is inferred from the configuration.\n  value: \u003cvalue\u003e\n\n  # Key specifies the attribute to act upon.\n- key: \u003ckey\u003e\n  action: {insert, update, upsert}\n  # FromAttribute specifies the attribute from the input data to use to populate\n  # the value. If the attribute doesn't exist, no action is performed.\n  from_attribute: \u003cother key\u003e\n\n  # Key specifies the attribute to act upon.\n- key: \u003ckey\u003e\n  action: {insert, update, upsert}\n  # FromContext specifies the context value to use to populate the attribute value. \n  # If the key is prefixed with `metadata.`, the values are searched\n  # in the receiver's transport protocol additional information like gRPC Metadata or HTTP Headers. \n  # If the key is prefixed with `auth.`, the values are searched\n  # in the authentication information set by the server authenticator. \n  # Refer to the server authenticator's documentation part of your pipeline for more information about which attributes are available.\n  # If the key doesn't exist, no action is performed.\n  # If the key has multiple values the values will be joined with `;` separator.\n  from_context: \u003cother key\u003e\n```\n\nFor the `delete` action,\n - `key` and/or `pattern` is required\n - `action: delete` is required.\n```yaml\n# Key specifies the attribute to act upon.\n- key: \u003ckey\u003e\n  action: delete\n  # Rule specifies the regex pattern for attribute names to act upon.\n  pattern: \u003cregular pattern\u003e\n```\n\n\nFor the `hash` action,\n - `key` and/or `pattern` is required\n - `action: hash` is required.\n```yaml\n# Key specifies the attribute to act upon.\n- key: \u003ckey\u003e\n  action: hash\n  # Rule specifies the regex pattern for attribute names to act upon.\n  pattern: \u003cregular pattern\u003e\n```\n\n\nFor the `extract` action,\n - `key` is required\n - `pattern` is required.\n ```yaml\n # Key specifies the attribute to extract values from.\n # The value of `key` is NOT altered.\n- key: \u003ckey\u003e\n  # Rule specifies the regex pattern used to extract attributes from the value\n  # of `key`.\n  # The submatchers must be named.\n  # If attributes already exist, they will be overwritten.\n  pattern: \u003cregular pattern with named matchers\u003e\n  action: extract\n\n ```\n\n\nFor the `convert` action,\n - `key` is required\n - `action: convert` is required.\n - `converted_type` is required and must be one of int, double or string\n```yaml\n# Key specifies the attribute to act upon.\n- key: \u003ckey\u003e\n  action: convert\n  converted_type: \u003cint|double|string\u003e\n```\n\nThe list of actions can be composed to create rich scenarios, such as\nback filling attribute, copying values to a new key, redacting sensitive information.\nThe following is a sample configuration.\n\n```yaml\nprocessors:\n  attributes/example:\n    actions:\n      - key: db.table\n        action: delete\n      - key: redacted_span\n        value: true\n        action: upsert\n      - key: copy_key\n        from_attribute: key_original\n        action: update\n      - key: account_id\n        value: 2245\n        action: insert\n      - key: account_password\n        action: delete\n      - key: account_email\n        action: hash\n      - key: http.status_code\n        action: convert\n        converted_type: int\n\n```\n\nRefer to [config.yaml](./testdata/config.yaml) for detailed\nexamples on using the processor.\n\n### Attributes Processor for Metrics vs. [Metric Transform Processor](../metricstransformprocessor)\n\nRegarding metric support, these two processors have overlapping functionality. They can both do simple modifications\nof metric attribute key-value pairs. As a general rule the attributes processor has more attribute related\nfunctionality, while the metrics transform processor can do much more data manipulation. The attributes processor\nis preferred when the only needed functionality is overlapping, as it natively uses the official OpenTelemetry\ndata model. However, if the metric transform processor is already in use or its extra functionality is necessary,\nthere's no need to migrate away from it.\n\nShared functionality\n* Add attributes\n* Update values of attributes\n\nAttribute processor specific functionality\n* delete\n* hash\n* extract\n\nMetric transform processor specific functionality\n* Rename metrics\n* Delete data points\n* Toggle data type\n* Scale value\n* Aggregate across label sets\n* Aggregate across label values\n\n## Include/Exclude Filtering\n\nThe [attribute processor](README.md) exposes an option to provide a set of properties of a span, log \nor metric record to match against to determine if the input data should be included or excluded from\nthe processor. To configure this option, under `include` and/or `exclude` at least `match_type` and \none of the following is required:\n- For spans, one of `services`, `span_names`, `span_kinds`, `attributes`, `resources` or `libraries` \nmust be specified with a non-empty value for a valid configuration. The `log_bodies`, `log_severity_texts`, \n`log_severity_number` and `metric_names` fields are invalid.\n- For logs, one of `log_bodies`, `log_severity_texts`, `log_severity_number`, `attributes`, `resources`\nor `libraries` must be specified with a non-empty value for a valid configuration. The `span_names`, \n`span_kinds`, `metric_names` and `services` fields are invalid.\n- For metrics, one of `metric_names` or `resources` must be specified with a valid non-empty value for\na valid configuration. The `span_names`, `span_kinds`, `log_bodies`, `log_severity_texts`, \n`log_severity_number`, `services`, `attributes` and `libraries` fields are invalid.\n\n\nNote: If both `include` and `exclude` are specified, the `include` properties\nare checked before the `exclude` properties.\n\n```yaml\nattributes:\n    # include and/or exclude can be specified. However, the include properties\n    # are always checked before the exclude properties.\n    {include, exclude}:\n      # At least one of services, span_names or attributes must be specified.\n      # It is supported to have more than one specified, but all of the specified\n      # conditions must evaluate to true for a match to occur.\n\n      # match_type controls how items in \"services\" and \"span_names\" arrays are\n      # interpreted. Possible values are \"regexp\" or \"strict\".\n      # This is a required field.\n      match_type: {strict, regexp}\n\n      # regexp is an optional configuration section for match_type regexp.\n      regexp:\n        # \u003c see \"Match Configuration\" below \u003e\n\n      # services specify an array of items to match the service name against.\n      # A match occurs if the span service name matches at least one of the items.\n      # This is an optional field.\n      services: [\u003citem1\u003e, ..., \u003citemN\u003e]\n\n      # resources specifies a list of resources to match against.\n      # A match occurs if the input data resources matches at least one of the items.\n      # This is an optional field.\n      resources:\n          # Key specifies the resource to match against.\n        - key: \u003ckey\u003e\n          # Value specifies the exact value to match against.\n          # If not specified, a match occurs if the key is present in the resources.\n          value: {value}\n\n      # libraries specify a list of items to match the implementation library against.\n      # A match occurs if the input data implementation library matches at least one of the items.\n      # This is an optional field.\n      libraries: [\u003citem1\u003e, ..., \u003citemN\u003e]\n          # Name specifies the library to match against.\n        - name: \u003cname\u003e\n          # Version specifies the exact version to match against.\n          # This is an optional field.\n          # If the field is not set, any version will match.\n          # If the field is set to an empty string, only an\n          # empty string version will match.\n          version: {version}\n\n      # The span name must match at least one of the items.\n      # This is an optional field.\n      span_names: [\u003citem1\u003e, ..., \u003citemN\u003e]\n\n      # The span kind must match at least one of the items.\n      # This is an optional field.\n      span_kinds: [\u003citem1\u003e, ..., \u003citemN\u003e]\n\n      # The log body must match at least one of the items.\n      # Currently only string body types are supported.\n      # This is an optional field.\n      log_bodies: [\u003citem1\u003e, ..., \u003citemN\u003e]\n\n      # The log severity text must match at least one of the items.\n      # This is an optional field.\n      log_severity_texts: [\u003citem1\u003e, ..., \u003citemN\u003e]\n\n      # The log severity number defines how to match against a log record's\n      # SeverityNumber, if defined.\n      # This is an optional field.\n      log_severity_number:\n        # Min is the lowest severity that may be matched.\n        # e.g. if this is plog.SeverityNumberInfo, \n        # INFO, WARN, ERROR, and FATAL logs will match.\n        min: \u003cint\u003e\n        # MatchUndefined controls whether logs with \"undefined\" severity matches.\n        # If this is true, entries with undefined severity will match.\n        match_undefined: \u003cbool\u003e\n\n      # The metric name must match at least one of the items.\n      # This is an optional field.\n      metric_names: [\u003citem1\u003e, ..., \u003citemN\u003e]\n\n      # Attributes specifies the list of attributes to match against.\n      # All of these attributes must match exactly for a match to occur.\n      # This is an optional field.\n      attributes:\n          # Key specifies the attribute to match against.\n        - key: \u003ckey\u003e\n          # Value specifies the exact value to match against.\n          # If not specified, a match occurs if the key is present in the attributes.\n          value: {value}\n```\n\n### Match Configuration\n\nSome `match_type` values have additional configuration options that can be\nspecified. The `match_type` value is the name of the configuration section.\nThese sections are optional.\n\n```yaml\n# regexp is an optional configuration section for match_type regexp.\nregexp:\n  # cacheenabled determines whether match results are LRU cached to make subsequent matches faster.\n  # Cache size is unlimited unless cachemaxnumentries is also specified.\n  cacheenabled: \u003cbool\u003e\n  # cachemaxnumentries is the max number of entries of the LRU cache; ignored if cacheenabled is false.\n  cachemaxnumentries: \u003cint\u003e\n```\n\n## Warnings\n\nIn general, the Attributes processor is a very safe processor to use.  Care only needs to be taken when modifying data point attributes:\n- [Identity Conflict](https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/standard-warnings.md#identity-conflict): Reducing/changing existing data point attributes has the potential to create an identity conflict since the Attributes processor does not perform any re-aggregation of the data points. Adding new attributes to data points is safe.","properties":{"actions":{"description":"Actions specifies the list of attributes to act on.\nThe set of actions are {INSERT, UPDATE, UPSERT, DELETE, HASH, EXTRACT, CONVERT}.\nThis is a required field.","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.coreinternal.attraction.ActionKeyValue"},"title":"actions","type":"array"},"exclude":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterconfig.MatchProperties","description":"Exclude specifies when this processor will not be applied to the input data\nwhich match the specified properties.\nNote: The `exclude` properties are checked after the `include` properties,\nif they exist, are checked.\nIf `include` isn't specified, the `exclude` properties are checked against\nall input data.\nThis is an optional field. If neither `include` and `exclude` are set, all input data\nis processed. If `exclude` is set and `include` isn't set, then all the\ninput data that does not match the properties in this structure are processed.","title":"exclude"},"include":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterconfig.MatchProperties","description":"Include specifies the set of input data properties that must be present in order\nfor this processor to apply to it.\nNote: If `exclude` is specified, the input data is compared against those\nproperties after the `include` properties.\nThis is an optional field. If neither `include` and `exclude` are set, all input data\nare processed. If `include` is set and `exclude` isn't set, then all\ninput data matching the properties in this structure are processed.","title":"include"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.cumulativetodeltaprocessor.Config":{"additionalProperties":false,"description":"Config defines the configuration for the processor.","markdownDescription":"# Cumulative to Delta Processor\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [contrib], [aws], [observiq], [sumo] |\n| Warnings      | [Statefulness](#warnings) |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\n## Description\n\nThe cumulative to delta processor (`cumulativetodeltaprocessor`) converts monotonic, cumulative sum and histogram metrics to monotonic, delta metrics. Non-monotonic sums and exponential histograms are excluded.\n\n## Configuration\n\nConfiguration is specified through a list of metrics. The processor uses metric names to identify a set of cumulative metrics and converts them from cumulative to delta.\n\nThe following settings can be optionally configured:\n\n- `include`: List of metrics names or patterns to convert to delta.\n- `exclude`: List of metrics names or patterns to not convert to delta.  **If a metric name matches both include and exclude, exclude takes precedence.**\n- `max_staleness`: The total time a state entry will live past the time it was last seen. Set to 0 to retain state indefinitely. Default: 0\n- `initial_value`: Handling of the first observed point for a given metric identity.\n  When the collector (re)starts, there's no record of how much of a given cumulative counter has already been converted to delta values.\n  - `auto` (default): Send if and only if the startime is set AND the starttime happens after the component started AND the starttime is different from the timestamp.\n    Suitable for gateway deployments, this heuristic is like `drop`, but keeps values for newly started counters (which could not have had previous observed values).\n  - `keep`: Send the observed value as the delta value.\n    Suitable for when the incoming metrics have not been observed before,\n    e.g. running the collector as a sidecar, the collector lifecycle is tied to the metric source.\n  - `drop`: Keep the observed value but don't send.\n    Suitable for gateway deployments, guarantees that all delta counts it produces haven't been observed before, but loses the values between thir first 2 observations.\n\nIf neither include nor exclude are supplied, no filtering is applied.\n\n#### Examples\n\n```yaml\nprocessors:\n    # processor name: cumulativetodelta\n    cumulativetodelta:\n\n        # list the exact cumulative sum or histogram metrics to convert to delta\n        include:\n            metrics:\n                - \u003cmetric_1_name\u003e\n                - \u003cmetric_2_name\u003e\n                .\n                .\n                - \u003cmetric_n_name\u003e\n            match_type: strict\n```\n\n```yaml\nprocessors:\n    # processor name: cumulativetodelta\n    cumulativetodelta:\n\n        # Convert cumulative sum or histogram metrics to delta\n        # if and only if 'metric' is in the name\n        include:\n            metrics:\n                - \"*metric*\"\n            match_type: regexp\n```\n\n```yaml\nprocessors:\n    # processor name: cumulativetodelta\n    cumulativetodelta:\n\n        # Convert cumulative sum or histogram metrics to delta\n        # if and only if 'metric' is not in the name\n        exclude:\n            metrics:\n                - \"*metric*\"\n            match_type: regexp\n```\n\n```yaml\nprocessors:\n    # processor name: cumulativetodelta\n    cumulativetodelta:\n        # If include/exclude are not specified\n        # convert all cumulative sum or histogram metrics to delta\n```\n\n## Warnings\n\n- [Statefulness](https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/standard-warnings.md#statefulness): The cumulativetodelta processor's calculates delta by remembering the previous value of a metric.  For this reason, the calculation is only accurate if the metric is continuously sent to the same instance of the collector.  As a result, the cumulativetodelta processor may not work as expected if used in a deployment of multiple collectors.  When using this processor it is best for the data source to being sending data to a single collector.\n\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib","properties":{"exclude":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.cumulativetodeltaprocessor.MatchMetrics","title":"exclude"},"include":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.cumulativetodeltaprocessor.MatchMetrics","description":"Include specifies a filter on the metrics that should be converted.\nExclude specifies a filter on the metrics that should not be converted.\nIf neither `include` nor `exclude` are set, all metrics will be converted.\nCannot be used with deprecated Metrics config option.","title":"include"},"initial_value":{"description":"InitialValue determines how to handle the first datapoint for a given metric. Valid values:\n\n  - auto: (default) send the first point iff the startime is set AND the starttime happens after the component started AND the starttime is different from the timestamp\n  - keep: always send the first point\n  - drop: don't send the first point, but store it for subsequent delta calculations","title":"initial_value","type":"integer"},"max_staleness":{"description":"MaxStaleness is the total time a state entry will live past the time it was last seen. Set to 0 to retain state indefinitely.","title":"max_staleness","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.cumulativetodeltaprocessor.MatchMetrics":{"additionalProperties":false,"properties":{"match_type":{"title":"match_type","type":"string"},"metrics":{"items":{"type":"string"},"title":"metrics","type":"array"},"regexp":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterset.regexp.Config","title":"regexp"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.deltatorateprocessor.Config":{"additionalProperties":false,"description":"Config defines the configuration for the processor.","markdownDescription":"# Delta to Rate Processor\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [development]: metrics   |\n| Distributions | [contrib], [aws], [observiq], [sumo] |\n\n[development]: https://github.com/open-telemetry/opentelemetry-collector#development\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\n**Status: under development; Not recommended for production usage.**\n\n## Description\n\nThe delta to rate processor (`deltatorateprocessor`) converts delta sum metrics to rate metrics. This rate is a gauge. \n\n## Configuration\n\nConfiguration is specified through a list of metrics. The processor uses metric names to identify a set of delta sum metrics and calculates the rates which are gauges.\n\n```yaml\nprocessors:\n    # processor name: deltatorate\n    deltatorate:\n\n        # list the delta sum metrics to calculate the rate. This is a required field.\n        metrics:\n            - \u003cmetric_1_name\u003e\n            - \u003cmetric_2_name\u003e\n            .\n            .\n            - \u003cmetric_n_name\u003e\n```\n\n[development]: https://github.com/open-telemetry/opentelemetry-collector#development\n[contrib]:https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib","properties":{"metrics":{"description":"List of delta sum metrics to convert to rates","items":{"type":"string"},"title":"metrics","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.filterprocessor.Config":{"additionalProperties":false,"description":"Config defines configuration for Resource processor.","markdownDescription":"# Filter Processor\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [alpha]: traces, metrics, logs   |\n| Distributions | [core], [contrib], [aws], [observiq], [splunk], [sumo] |\n| Warnings      | [Orphaned Telemetry, Other](#warnings) |\n\n[alpha]: https://github.com/open-telemetry/opentelemetry-collector#alpha\n[core]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe filterprocessor allows dropping spans, span events, metrics, datapoints, and logs from the collector.\n\n## Configuration\n\nThe filterprocessor utilizes the [OpenTelemetry Transformation Language](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/pkg/ottl/README.md)\nto create conditions that determine when telemetry should be dropped.\nIf **any** condition is met, the telemetry is dropped (each condition is ORed together).\nEach configuration option corresponds with a different type of telemetry and OTTL Context.\nSee the table below for details on each context and the fields it exposes.\n\n| Config              | OTTL Context                                                                                                                       |\n|---------------------|------------------------------------------------------------------------------------------------------------------------------------|\n| `traces.span`       | [Span](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/pkg/ottl/contexts/ottlspan/README.md)           |\n| `traces.spanevent`  | [SpanEvent](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/pkg/ottl/contexts/ottlspanevent/README.md) |\n| `metrics.metric`    | [Metric](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/pkg/ottl/contexts/ottlmetric/README.md)       |\n| `metrics.datapoint` | [DataPoint](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/pkg/ottl/contexts/ottldatapoint/README.md) |\n| `logs.log_record`   | [Log](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/pkg/ottl/contexts/ottllog/README.md)             |\n\nThe OTTL allows the use of `and`, `or`, and `()` in conditions.\nSee [OTTL Boolean Expressions](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/pkg/ottl/README.md#boolean-expressions) for more details.\n\nFor conditions that apply to the same signal, such as spans and span events, if the \"higher\" level telemetry matches a condition and is dropped, the \"lower\" level condition will not be checked.\nThis means that if a span is dropped but a span event condition was defined, the span event condition will not be checked for that span.\nThe same relationship applies to metrics and datapoints.\n\nIf all span events for a span are dropped, the span will be left intact.\nIf all datapoints for a metric are dropped, the metric will also be dropped.\n\nThe filter processor also allows configuring an optional field, `error_mode`, which will determine how the processor reacts to errors that occur while processing an OTTL condition.\n\n| error_mode            | description                                                                                                                |\n|-----------------------|----------------------------------------------------------------------------------------------------------------------------|\n| ignore                | The processor ignores errors returned by conditions and continues on to the next condition.  This is the recommended mode. |\n| propagate             | The processor returns the error up the pipeline.  This will result in the payload being dropped from the collector.        |\n\nIf not specified, `propagate` will be used.\n\n### Examples\n\n```yaml\nprocessors:\n  filter/ottl:\n    error_mode: ignore\n    traces:\n      span:\n        - 'attributes[\"container.name\"] == \"app_container_1\"'\n        - 'resource.attributes[\"host.name\"] == \"localhost\"'\n        - 'name == \"app_3\"'\n      spanevent:\n        - 'attributes[\"grpc\"] == true'\n        - 'IsMatch(name, \".*grpc.*\")'\n    metrics:\n      metric:\n          - 'name == \"my.metric\" and resource.attributes[\"my_label\"] == \"abc123\"'\n          - 'type == METRIC_DATA_TYPE_HISTOGRAM'\n      datapoint:\n          - 'metric.type == METRIC_DATA_TYPE_SUMMARY'\n          - 'resource.attributes[\"service.name\"] == \"my_service_name\"'\n    logs:\n      log_record:\n        - 'IsMatch(body, \".*password.*\")'\n        - 'severity_number \u003c SEVERITY_NUMBER_WARN'\n```\n\n### OTTL Functions\n\nThe filter processor has access to all [OTTL Converter functions](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/pkg/ottl/ottlfuncs#converters)\n\nIn addition, the processor defines a few of its own functions:\n\n**Metrics only functions**\n- [HasAttrKeyOnDatapoint](#HasAttrKeyOnDatapoint)\n- [HasAttrOnDatapoint](#HasAttrOnDatapoint)\n\n#### HasAttrKeyOnDatapoint\n\n`HasAttrKeyOnDatapoint(key)`\n\nReturns `true` if the given key appears in the attribute map of any datapoint on a metric.\n`key` must be a string.\n\nExamples:\n\n- `HasAttrKeyOnDatapoint(\"http.method\")`\n\n#### HasAttrOnDatapoint\n\n`HasAttrOnDatapoint(key, value)`\n\nReturns `true` if the given key and value appears in the attribute map of any datapoint on a metric.\n`key` and `value` must both be strings.\n\nExamples:\n\n- `HasAttrOnDatapoint(\"http.method\", \"GET\")`\n\n## Alternative Config Options\n\nAll the following configurations can be expressed using OTTL configuration\nand may eventually be deprecated as part of [#18642](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/18642).\n\nThe filter processor can be configured to include or exclude:\n\n- Logs, based on resource attributes using the `strict` or `regexp` match types\n- Metrics based on metric name in the case of the `strict` or `regexp` match types,\n  or based on other metric attributes in the case of the `expr` match type.\n  Please refer to [config.go](./config.go) for the config spec.\n- Spans based on span names and resource attributes, all with full regex support\n\nIt takes a pipeline type, of which `logs` `metrics`, and `traces` are supported, followed\nby an action:\n\n- `include`: Any names NOT matching filters are excluded from remainder of pipeline\n- `exclude`: Any names matching filters are excluded from remainder of pipeline\n\nFor the actions the following parameters are required:\n\nFor logs:\n\n- `match_type`: `strict`|`regexp`\n- `resource_attributes`: ResourceAttributes defines a list of possible resource\n  attributes to match logs against.\n  A match occurs if any resource attribute matches all expressions in this given list.\n- `record_attributes`: RecordAttributes defines a list of possible record\n  attributes to match logs against.\n  A match occurs if any record attribute matches all expressions in this given list.\n- `severity_texts`: SeverityTexts defines a list of possible severity texts to match the logs against.\n  A match occurs if the record matches any expression in this given list.\n- `bodies`: Bodies defines a list of possible log bodies to match the logs against.\n  A match occurs if the record matches any expression in this given list.\n- `severity_number`: SeverityNumber defines how to match a record based on its SeverityNumber.\n  The following can be configured for matching a log record's SeverityNumber:\n  - `min`: Min defines the minimum severity with which a log record should match.\n    e.g. if this is \"WARN\", all log records with \"WARN\" severity and above (WARN[2-4], ERROR[2-4], FATAL[2-4]) are matched.\n    The list of valid severities that may be used for this option can be found [here](https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/logs/data-model.md#displaying-severity). You may use either the numerical \"SeverityNumber\" or the \"Short Name\"\n  - `match_undefined`: MatchUndefinedSeverity defines whether to match logs with undefined severity or not when using the `min_severity` matching option.\n    By default, this is `false`.\n\nFor metrics:\n\n- `match_type`: `strict`|`regexp`|`expr`\n- `metric_names`: (only for a `match_type` of `strict` or `regexp`) list of strings\n  or re2 regex patterns\n- `expressions`: (only for a `match_type` of `expr`) list of `expr` expressions\n  (see \"Using an `expr` match_type\" below)\n- `resource_attributes`: ResourceAttributes defines a list of possible resource\n  attributes to match metrics against.\n  A match occurs if any resource attribute matches all expressions in this given list.\n\nThis processor uses [re2 regex][re2_regex] for regex syntax.\n\n[re2_regex]: https://github.com/google/re2/wiki/Syntax\n\nMore details can be found at [include/exclude metrics](../attributesprocessor/README.md#includeexclude-filtering).\n\nExamples:\n\n```yaml\nprocessors:\n  filter/1:\n    metrics:\n      include:\n        match_type: regexp\n        metric_names:\n          - prefix/.*\n          - prefix_.*\n        resource_attributes:\n          - key: container.name\n            value: app_container_1\n      exclude:\n        match_type: strict\n        metric_names:\n          - hello_world\n          - hello/world\n  filter/2:\n    logs:\n      include:\n        match_type: strict\n        resource_attributes:\n          - key: host.name\n            value: just_this_one_hostname\n  filter/regexp:\n    logs:\n      include:\n        match_type: regexp\n        resource_attributes:\n          - key: host.name\n            value: prefix.*\n  filter/regexp_record:\n    logs:\n      include:\n        match_type: regexp\n        record_attributes:\n          - key: record_attr\n            value: prefix_.*\n  # Filter on severity text field\n  filter/severity_text:\n    logs:\n      include:\n        match_type: regexp\n        severity_texts:\n        - INFO[2-4]?\n        - WARN[2-4]?\n        - ERROR[2-4]?\n  # Filter out logs below INFO (no DEBUG or TRACE level logs),\n  # retaining logs with undefined severity\n  filter/severity_number:\n    logs:\n      include:\n        severity_number:\n          min: \"INFO\"\n          match_undefined: true\n  filter/bodies:\n    logs:\n      include:\n        match_type: regexp\n        bodies:\n        - ^IMPORTANT RECORD\n```\n\nRefer to the config files in [testdata](./testdata) for detailed\nexamples on using the processor.\n\n### Using an \"expr\" match_type\n\nIn addition to matching metric names with the `strict` or `regexp` match types, the filter processor\nsupports matching entire `Metric`s using the [expr](https://github.com/antonmedv/expr) expression engine.\n\nThe `expr` filter evaluates the supplied boolean expressions _per datapoint_ on a metric, and returns a result\nfor the entire metric. If any datapoint evaluates to true then the entire metric evaluates to true, otherwise\nfalse.\n\nMade available to the expression environment are the following:\n\n* `MetricName`\n    a variable containing the current Metric's name\n* `MetricType`\n    a variable containing the current Metric's type: \"Gauge\", \"Sum\", \"Histogram\", \"ExponentialHistogram\" or \"Summary\".\n* `Label(name)`\n    a function that takes a label name string as an argument and returns a string: the value of a label with that\n    name if one exists, or \"\"\n* `HasLabel(name)`\n    a function that takes a label name string as an argument and returns a boolean: true if the datapoint has a label\n    with that name, false otherwise\n\nExample:\n\n```yaml\nprocessors:\n  filter/1:\n    metrics:\n      exclude:\n        match_type: expr\n        expressions:\n        - MetricName == \"my.metric\" \u0026\u0026 Label(\"my_label\") == \"abc123\"\n        - MetricType == \"Histogram\"\n```\n\nThe above config will filter out any Metric that both has the name \"my.metric\" and has at least one datapoint\nwith a label of 'my_label=\"abc123\"'.\n\n### Support for multiple expressions\n\nAs with `strict` and `regexp`, multiple `expr` expressions are allowed.\n\nFor example, the following two filters have the same effect: they filter out metrics named \"system.cpu.time\" and\n\"system.disk.io\". \n\n```yaml\nprocessors:\n  filter/expr:\n    metrics:\n      exclude:\n        match_type: expr\n        expressions:\n          - MetricName == \"system.cpu.time\"\n          - MetricName == \"system.disk.io\"\n  filter/strict:\n    metrics:\n      exclude:\n        match_type: strict\n        metric_names:\n          - system.cpu.time\n          - system.disk.io\n```\n\nThe expressions are effectively ORed per datapoint. So for the above `expr` configuration, given a datapoint, if its\nparent Metric's name is \"system.cpu.time\" or \"system.disk.io\" then there's a match. The conditions are tested against\nall the datapoints in a Metric until there's a match, in which case the entire Metric is considered a match, and in\nthe above example the Metric will be excluded. If after testing all the datapoints in a Metric against all the\nexpressions there isn't a match, the entire Metric is considered to be not matching.\n\n\n### Filter metrics using resource attributes\nIn addition to the names, metrics can be filtered using resource attributes. `resource_attributes` takes a list of resource attributes to filter metrics against. \n\nFollowing example will include only the metrics coming from `app_container_1` (the value for `container.name` resource attribute is `app_container_1`). \n\n```yaml\nprocessors:\n  filter/resource_attributes_include:\n    metrics:\n      include:\n        match_type: strict\n        metric_names:\n          - hello_world\n          - hello/world\n        resource_attributes:\n          - key: container.name\n            value: app_container_1\n```\n\nFollowing example will exclude all the metrics coming from `app_container_1` (the value for `container.name` resource attribute is `app_container_1`). \n\n```yaml\nprocessors:\n  filter/resource_attributes_exclude:\n    metrics:\n      exclude:\n        match_type: strict\n        metric_names:\n          - hello_world\n          - hello/world\n        resource_attributes:\n          - key: container.name\n            value: app_container_1\n```\n\nWe can also use `regexp` to filter metrics using resource attributes. Following example will include only the metrics coming from `app_container_1` or `app_container_2` (the value for `container.name` resource attribute is either `app_container_1` or `app_container_2`). \n\n```yaml\nprocessors:\n  filter/resource_attributes_regexp:\n    metrics:\n      exclude:\n        match_type: regexp\n        metric_names:\n          - hello_world\n          - hello/world\n        resource_attributes:\n          - key: container.name\n            value: (app_container_1|app_container_1)\n```\n\nIn case the no metric names are provided, `matric_names` being empty, the filtering is only done at resource level.\n\n### Filter Spans from Traces\n\n* This pipeline is able to drop spans and whole traces \n* Note: If this drops a parent span, it does not search out it's children leading to a missing Span in your trace visualization\n\nSee the documentation in the [attribute processor](../attributesprocessor/README.md) for syntax\n\nFor spans, one of Services, SpanNames, Attributes, Resources or Libraries must be specified with a\nnon-empty value for a valid configuration.\n\n```yaml\nprocessors:\n  filter/spans:\n    spans:\n      include:\n        match_type: strict\n        services:\n          - app_3\n      exclude:\n        match_type: regexp\n        services:\n          - app_1\n          - app_2\n        span_names:\n          - hello_world\n          - hello/world\n        attributes:\n          - key: container.name\n            value: (app_container_1|app_container_2)\n        libraries:\n          - name: opentelemetry\n            version: 0.0-beta\n        resources:\n          - key: container.host\n            value: (localhost|127.0.0.1)\n```\n\n## Warnings\n\nIn general, understand your data before using the filter processor.\n\n- When using the filterprocessor make sure you understand the look of your incoming data and test the configuration thoroughly. In general, use as specific a configuration as possible to lower the risk of the wrong data being dropped.\n- [Orphaned Telemetry](https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/standard-warnings.md#orphaned-telemetry): The processor allows dropping spans. Dropping a span may lead to orphaned spans if the dropped span is a parent. Dropping a span may lead to orphaned logs if the log references the dropped span.","properties":{"error_mode":{"description":"ErrorMode determines how the processor reacts to errors that occur while processing an OTTL condition.\nValid values are `ignore` and `propagate`.\n`ignore` means the processor ignores errors returned by conditions and continues on to the next condition. This is the recommended mode.\n`propagate` means the processor returns the error up the pipeline.  This will result in the payload being dropped from the collector.\nThe default value is `propagate`.","title":"error_mode","type":"string"},"logs":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.filterprocessor.LogFilters","title":"logs"},"metrics":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.filterprocessor.MetricFilters","title":"metrics"},"spans":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterconfig.MatchConfig","title":"spans"},"traces":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.filterprocessor.TraceFilters","title":"traces"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.filterprocessor.LogFilters":{"additionalProperties":false,"description":"LogFilters filters by Log properties.","properties":{"exclude":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.filterprocessor.LogMatchProperties","description":"Exclude match properties describe logs that should be excluded from the Collector Service pipeline,\nall other logs should be included.\nIf both Include and Exclude are specified, Include filtering occurs first.","title":"exclude"},"include":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.filterprocessor.LogMatchProperties","description":"Include match properties describe logs that should be included in the Collector Service pipeline,\nall other logs should be dropped from further processing.\nIf both Include and Exclude are specified, Include filtering occurs first.","title":"include"},"log_record":{"description":"LogConditions is a list of OTTL conditions for an ottllog context.\nIf any condition resolves to true, the log event will be dropped.\nSupports `and`, `or`, and `()`","items":{"type":"string"},"title":"log_record","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.filterprocessor.LogMatchProperties":{"additionalProperties":false,"description":"LogMatchProperties specifies the set of properties in a log to match against and the type of string pattern matching to use.","properties":{"bodies":{"description":"LogBodies is a list of strings that the LogRecord's body field must match\nagainst.","items":{"type":"string"},"title":"bodies","type":"array"},"match_type":{"description":"LogMatchType specifies the type of matching desired","title":"match_type","type":"string"},"record_attributes":{"description":"RecordAttributes defines a list of possible record attributes to match logs against.\nA match occurs if any record attribute matches at least one expression in this given list.","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterconfig.Attribute"},"title":"record_attributes","type":"array"},"resource_attributes":{"description":"ResourceAttributes defines a list of possible resource attributes to match logs against.\nA match occurs if any resource attribute matches all expressions in this given list.","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterconfig.Attribute"},"title":"resource_attributes","type":"array"},"severity_number":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.filterprocessor.LogSeverityNumberMatchProperties","description":"SeverityNumberProperties defines how to match against a log record's SeverityNumber, if defined.","title":"severity_number"},"severity_texts":{"description":"SeverityTexts is a list of strings that the LogRecord's severity text field must match\nagainst.","items":{"type":"string"},"title":"severity_texts","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.filterprocessor.LogSeverityNumberMatchProperties":{"additionalProperties":false,"properties":{"match_undefined":{"description":"MatchUndefined lets logs records with \"unknown\" severity match.\nIf MinSeverity is not set, this field is ignored, as fields are not matched based on severity.","title":"match_undefined","type":"boolean"},"min":{"description":"Min is the minimum severity needed for the log record to match.\nThis corresponds to the short names specified here:\nhttps://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/logs/data-model.md#displaying-severity\nthis field is case-insensitive (\"INFO\" == \"info\")","title":"min","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.filterprocessor.MetricFilters":{"additionalProperties":false,"description":"MetricFilters filters by Metric properties.","properties":{"datapoint":{"description":"DataPointConditions is a list of OTTL conditions for an ottldatapoint context.\nIf any condition resolves to true, the datapoint will be dropped.\nSupports `and`, `or`, and `()`","items":{"type":"string"},"title":"datapoint","type":"array"},"exclude":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterconfig.MetricMatchProperties","description":"Exclude match properties describe metrics that should be excluded from the Collector Service pipeline,\nall other metrics should be included.\nIf both Include and Exclude are specified, Include filtering occurs first.","title":"exclude"},"include":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterconfig.MetricMatchProperties","description":"Include match properties describe metrics that should be included in the Collector Service pipeline,\nall other metrics should be dropped from further processing.\nIf both Include and Exclude are specified, Include filtering occurs first.","title":"include"},"metric":{"description":"MetricConditions is a list of OTTL conditions for an ottlmetric context.\nIf any condition resolves to true, the metric will be dropped.\nSupports `and`, `or`, and `()`","items":{"type":"string"},"title":"metric","type":"array"},"regexp":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterset.regexp.Config","description":"RegexpConfig specifies options for the Regexp match type","title":"regexp"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.filterprocessor.TraceFilters":{"additionalProperties":false,"description":"TraceFilters filters by OTTL conditions","properties":{"span":{"description":"SpanConditions is a list of OTTL conditions for an ottlspan context.\nIf any condition resolves to true, the span will be dropped.\nSupports `and`, `or`, and `()`","items":{"type":"string"},"title":"span","type":"array"},"spanevent":{"description":"SpanEventConditions is a list of OTTL conditions for an ottlspanevent context.\nIf any condition resolves to true, the span event will be dropped.\nSupports `and`, `or`, and `()`","items":{"type":"string"},"title":"spanevent","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.groupbyattrsprocessor.Config":{"additionalProperties":false,"description":"Config is the configuration for the processor.","markdownDescription":"# Group by Attributes processor\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: traces, metrics, logs   |\n| Distributions | [contrib], [observiq], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\n## Description\n\nThis processor re-associates spans, log records and metric datapoints to a *Resource* that matches with the specified attributes. As a result, all spans, log records or metric datapoints with the same values for the specified attributes are \"grouped\" under the same *Resource*.\n\nTypical use cases:\n\n* extract resources from \"flat\" data formats, such as Fluentbit logs or Prometheus metrics\n* associate Prometheus metrics to a *Resource* that describes the relevant host, based on label present on all metrics\n* optimize data packaging by extracting common attributes\n* [compacting](#compaction) multiple records that share the same Resource and InstrumentationLibrary attributes but are under multiple ResourceSpans/ResourceMetrics/ResourceLogs, into a single ResourceSpans/ResourceMetrics/ResourceLogs (when empty list of keys is being provided). This might happen e.g. when [groupbytrace](../groupbytraceprocessor) processor is being used or data comes in multiple requests. By compacting data, it takes less memory, is more efficiently processed, serialized and the number of export requests is reduced (e.g. in case of [jaeger](../../exporter/jaegerexporter) exporter).\n\nIt is recommended to use the `groupbyattrs` processor together with [batch](https://github.com/open-telemetry/opentelemetry-collector/tree/main/processor/batchprocessor) processor, as a consecutive step, as this will reduce the fragmentation of data (by grouping records together under matching Resource/Instrumentation Library)\n\n## Examples\n\n### Grouping metrics\n\nConsider the below metrics, all originally associated to the same *Resource*:\n\n```go\nResource {host.name=\"localhost\",source=\"prom\"}\n  Metric \"gauge-1\" (GAUGE)\n    DataPoint {host.name=\"host-A\",id=\"eth0\"}\n    DataPoint {host.name=\"host-A\",id=\"eth0\"}\n    DataPoint {host.name=\"host-B\",id=\"eth0\"}\n  Metric \"gauge-1\" (GAUGE) // Identical to previous Metric\n    DataPoint {host.name=\"host-A\",id=\"eth0\"}\n    DataPoint {host.name=\"host-A\",id=\"eth0\"}\n    DataPoint {host.name=\"host-B\",id=\"eth0\"}\n  Metric \"mixed-type\" (GAUGE)\n    DataPoint {host.name=\"host-A\",id=\"eth0\"}\n    DataPoint {host.name=\"host-A\",id=\"eth0\"}\n    DataPoint {host.name=\"host-B\",id=\"eth0\"}\n  Metric \"mixed-type\" (SUM)\n    DataPoint {host.name=\"host-A\",id=\"eth0\"}\n    DataPoint {host.name=\"host-A\",id=\"eth0\"}\n  Metric \"dont-move\" (Gauge)\n    DataPoint {id=\"eth0\"}\n```\n\nWith the below configuration, the **groupbyattrs** will re-associate the metrics with either `host-A` or `host-B`, based on the value of the `host.name` attribute.\n\n```yaml\nprocessors:\n  groupbyattrs:\n    keys:\n      - host.name\n```\n\nThe output of the processor will therefore be:\n\n```go\nResource {host.name=\"localhost\",source=\"prom\"}\n  Metric \"dont-move\" (Gauge)\n    DataPoint {id=\"eth0\"}\n\nResource {host.name=\"host-A\",source=\"prom\"}\n  Metric \"gauge-1\"\n    DataPoint {id=\"eth0\"}\n    DataPoint {id=\"eth0\"}\n    DataPoint {id=\"eth0\"}\n    DataPoint {id=\"eth0\"}\n  Metric \"mixed-type\" (GAUGE)\n    DataPoint {id=\"eth0\"}\n    DataPoint {id=\"eth0\"}\n  Metric \"mixed-type\" (SUM)\n    DataPoint {id=\"eth0\"}\n    DataPoint {id=\"eth0\"}\n\nResource {host.name=\"host-B\",source=\"prom\"}\n  Metric \"gauge-1\"\n    DataPoint {id=\"eth0\"}\n    DataPoint {id=\"eth0\"}\n  Metric \"mixed-type\" (GAUGE)\n    DataPoint {id=\"eth0\"}\n```\n\nNotes:\n\n* The *DataPoints* for the `gauge-1` (GAUGE) metric were originally split under 2 *Metric* instances and have been merged in the output\n* The *DataPoints* of the `mixed-type` (GAUGE) and `mixed-type` (SUM) metrics have not been merged under the same *Metric*, because their *DataType* is different\n* The `dont-move` metric *DataPoints* don't have a `host.name` attribute and therefore remained under the original *Resource*\n* The new *Resources* inherited the attributes from the original *Resource* (`source=\"prom\"`), **plus** the specified attributes from the processed metrics (`host.name=\"host-A\"` or `host.name=\"host-B\"`)\n* The specified \"grouping\" attributes that are set on the new *Resources* are also **removed** from the metric *DataPoints*\n* While not shown in the above example, the processor also merges collections of records under matching InstrumentationLibrary\n\n### Compaction\n\nIn some cases, the data might come in single requests to the collector or become fragmented due to use of [groupbytrace](../groupbytraceprocessor) processor. Even after batching there might be multiple duplicated ResourceSpans/ResourceLogs/ResourceMetrics objects, which leads to additional memory consumption, increased processing costs, inefficient serialization and increase of the export requests. As a remedy, `groupbyattrs` processor might be used to compact the data with matching Resource and InstrumentationLibrary properties.\n\nFor example, consider the following input:\n\n```go\nResource {host.name=\"localhost\"}\n  InstumentationLibrary {name=\"MyLibrary\"}\n  Spans\n    Span {span_id=1, ...}\n  InstumentationLibrary {name=\"OtherLibrary\"}\n  Spans\n    Span {span_id=2, ...}\n    \nResource {host.name=\"localhost\"}\n  InstumentationLibrary {name=\"MyLibrary\"}\n  Spans\n    Span {span_id=3, ...}\n    \nResource {host.name=\"localhost\"}\n  InstumentationLibrary {name=\"MyLibrary\"}\n  Spans\n    Span {span_id=4, ...}\n    \nResource {host.name=\"otherhost\"}\n  InstumentationLibrary {name=\"MyLibrary\"}\n  Spans\n    Span {span_id=5, ...}\n```\n\nWith the below configuration, the **groupbyattrs** will re-associate the spans with matching Resource and InstrumentationLibrary. \n\n```yaml\nprocessors:\n  batch:\n  groupbyattrs:\n\npipelines:\n  traces:\n    processors: [batch, groupbyattrs/grouping]\n    ...\n```\n\nThe output of the processor will therefore be:\n\n```go\nResource {host.name=\"localhost\"}\n  InstumentationLibrary {name=\"MyLibrary\"}\n  Spans\n    Span {span_id=1, ...}\n    Span {span_id=3, ...}\n    Span {span_id=4, ...}\n  InstumentationLibrary {name=\"OtherLibrary\"}\n  Spans\n    Span {span_id=2, ...}\n\nResource {host.name=\"otherhost\"}\n  InstumentationLibrary {name=\"MyLibrary\"}\n  Spans\n    Span {span_id=5, ...}\n```\n\n## Configuration\n\nThe configuration is very simple, as you only need to specify an array of attribute keys that will be used to \"group\" spans, log records or metric data points together, as in the below example:\n\n```yaml\nprocessors:\n  groupbyattrs:\n    keys:\n      - foo\n      - bar\n```\n\nThe `keys` property describes which attribute keys will be considered for grouping:\n\n* If the processed span, log record and metric data point has at least one of the specified attributes key, it will be moved to a *Resource* with the same value for these attributes. The *Resource* will be created if none exists with the same attributes.\n* If none of the specified attributes key is present in the processed span, log record or metric data point, it remains associated to the same *Resource* (no change).\n\nPlease refer to:\n\n* [config.go](./config.go) for the config spec\n* [config.yaml](./testdata/config.yaml) for detailed examples on using the processor\n\n## Internal Metrics\n\nThe following internal metrics are recorded by this processor:\n\n| Metric                    | Description                                              |\n| ------------------------- | -------------------------------------------------------- |\n| `num_grouped_spans`       | the number of spans that had attributes grouped          |\n| `num_non_grouped_spans`   | the number of spans that did not have attributes grouped |\n| `span_groups`             | distribution of groups extracted for spans               |\n| `num_grouped_logs`        | number of logs that had attributes grouped               |\n| `num_non_grouped_logs`    | number of logs that did not have attributes grouped      |\n| `log_groups`              | distribution of groups extracted for logs                |\n| `num_grouped_metrics`     | number of metrics that had attributes grouped            |\n| `num_non_grouped_metrics` | number of metrics that did not have attributes grouped   |\n| `metric_groups`           | distribution of groups extracted for metrics             |","properties":{"keys":{"description":"GroupByKeys describes the attribute names that are going to be used for grouping.\nEmpty value is allowed, since processor in such case can compact data","items":{"type":"string"},"title":"keys","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.groupbytraceprocessor.Config":{"additionalProperties":false,"description":"Config is the configuration for the processor.","markdownDescription":"# Group by Trace processor\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: traces   |\n| Distributions | [contrib], [aws], [observiq], [sumo] |\n| Warnings      | [Statefulness](#warnings) |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThis processor collects all the spans from the same trace, waiting a \npre-determined amount of time before releasing the trace to the next processor.\nThe expectation is that, generally, traces will be complete after the given time.\n\nThis processor should be used whenever a processor requires grouped traces to make decisions,\nsuch as a tail-based sampler or a per-trace metrics processor.\n\nThe batch processor shouldn't be used before this processor, as this one will \nprobably undo part (or much) of the work that the batch processor performs. It's\nfine to have the batch processor to run right after this one, and every entry in the\nbatch will be a complete trace.\n\nPlease refer to [config.go](./config.go) for the config spec.\n\nExamples:\n\n```yaml\nprocessors:\n  groupbytrace:\n  groupbytrace/2:\n    wait_duration: 10s\n    num_traces: 1000\n    num_workers: 2\n```\n\n## Configuration\n\nRefer to [config.yaml](./testdata/config.yaml) for detailed examples on using the processor.\n\nThe `num_traces` (default=1,000,000) property tells the processor what's the maximum number of traces to keep in the internal storage. A higher `num_traces` might incur in a higher memory usage.\n\nThe `wait_duration` (default=1s) property tells the processor for how long it should keep traces in the internal storage. Once a trace is kept for this duration, it's then released to the next consumer and removed from the internal storage. Spans from a trace that has been released will be kept for the entire duration again.\n\nThe `num_workers` (default=1) property controls how many concurrent workers the processor will use to process traces. If you are looking to optimize this value\nthen using GOMAXPROCS could be considered as a starting point. \n\n## Metrics\n\nThe following metrics are recorded by this processor:\n\n* `otelcol_processor_groupbytrace_conf_num_traces` represents the maximum number of traces that can be kept by the internal storage. This value comes from the processor's configuration and will never change over the lifecycle of the processor.\n* `otelcol_processor_groupbytrace_event_latency_bucket`, with the following `event` tag values:\n  * `onTraceReceived` represents the number of traces' parts the processor has received from the previous components\n  * `onTraceExpired` represents the number of traces that finished waiting in memory for spans to arrive\n  * `onTraceReleased` represents the number of traces that have been marked as released to the next component\n  * `onTraceRemoved` represents the number of traces that have been marked for removal from the internal storage\n* `otelcol_processor_groupbytrace_num_events_in_queue` representing the state of the internal queue. Ideally, this number would be close to zero, but might have temporary spikes if the storage is slow.\n* `otelcol_processor_groupbytrace_num_traces_in_memory` representing the state of the internal trace storage, waiting for spans to arrive. It's common to have items in memory all the time if the processor has a continuous flow of data. The longer the `wait_duration`, the higher the amount of traces in memory should be, given enough traffic.\n* `otelcol_processor_groupbytrace_spans_released` and `otelcol_processor_groupbytrace_traces_released` represent the number of spans and traces effectively released to the next component.\n* `otelcol_processor_groupbytrace_traces_evicted` represents the number of traces that have been evicted from the internal storage due to capacity problems. Ideally, this should be zero, or very close to zero at all times. If you keep getting items evicted, increase the `num_traces`.\n* `otelcol_processor_groupbytrace_incomplete_releases` represents the traces that have been marked as expired, but had been previously been removed. This might be the case when a span from a trace has been received in a batch while the trace existed in the in-memory storage, but has since been released/removed before the span could be added to the trace. This should always be very close to 0, and a high value might indicate a software bug.\n\nA healthy system would have the same value for the metric `otelcol_processor_groupbytrace_spans_released` and for three events under `otelcol_processor_groupbytrace_event_latency_bucket`: `onTraceExpired`, `onTraceRemoved` and `onTraceReleased`.\n\nThe metric `otelcol_processor_groupbytrace_event_latency_bucket` is a bucket and shows how long each event took to be processed in miliseconds. In most cases, it should take less than 5ms for an event to be processed, but it might be the case where an event could take 10ms. Higher latencies are possible, but it should never really reach the last item, representing 1s. Events taking more than 1s are killed automatically, and if you have multiple items in this bucket, it might indicate a bug in the software.\n\nMost metrics are updated when the events occur, except for the following ones, which are updated periodically:\n* `otelcol_processor_groupbytrace_num_events_in_queue`\n* `otelcol_processor_groupbytrace_num_traces_in_memory`\n\n## Warnings\n\n- [Statefulness](https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/standard-warnings.md#statefulness): The groupbytrace processor's works best when all spans for a trace are sent to the same collector instance.","properties":{"discard_orphans":{"description":"DiscardOrphans instructs the processor to discard traces without the root span.\nThis typically indicates that the trace is incomplete.\nDefault: false.\nNot yet implemented, and an error will be returned when this option is used.","title":"discard_orphans","type":"boolean"},"num_traces":{"description":"NumTraces is the max number of traces to keep in memory waiting for the duration.\nDefault: 1_000_000.","title":"num_traces","type":"integer"},"num_workers":{"description":"NumWorkers is a number of workers processing event queue.\nDefault: 1.","title":"num_workers","type":"integer"},"store_on_disk":{"description":"StoreOnDisk tells the processor to keep only the trace ID in memory, serializing the trace spans to disk.\nUseful when the duration to wait for traces to complete is high.\nDefault: false.\nNot yet implemented, and an error will be returned when this option is used.","title":"store_on_disk","type":"boolean"},"wait_duration":{"description":"WaitDuration tells the processor to wait for the specified duration for the trace to be complete.\nDefault: 1s.","title":"wait_duration","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.k8sattributesprocessor.Config":{"additionalProperties":false,"description":"Config defines configuration for k8s attributes processor.","markdownDescription":"# Kubernetes Attributes Processor\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: logs, metrics, traces   |\n| Distributions | [contrib], [observiq], [redhat], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[redhat]: https://github.com/os-observability/redhat-opentelemetry-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nKubernetes attributes processor allow automatic setting of spans, metrics and logs resource attributes with k8s metadata.\n\nThe processor automatically discovers k8s resources (pods), extracts metadata from them and adds the extracted metadata\nto the relevant spans, metrics and logs as resource attributes. The processor uses the kubernetes API to discover all pods\nrunning in a cluster, keeps a record of their IP addresses, pod UIDs and interesting metadata.\nThe rules for associating the data passing through the processor (spans, metrics and logs) with specific Pod Metadata are configured via \"pod_association\" key.\nIt represents a list of associations that are executed in the specified order until the first one is able to do the match.\n\n\n## Configuration\n\nThe processor stores the list of running pods and the associated metadata. When it sees a datapoint (log, trace or metric), it will try to associate the datapoint\nto the pod from where the datapoint originated, so we can add the relevant pod metadata to the datapoint. By default, it associates the incoming connection IP\nto the Pod IP. But for cases where this approach doesn't work (sending through a proxy, etc.), a custom association rule can be specified.\n\nEach association is specified as a list of sources of associations. A source is a rule that matches metadata from the datapoint to pod metadata.\nIn order to get an association applied, all the sources specified need to match.\n\nEach sources rule is specified as a pair of `from` (representing the rule type) and `name` (representing the attribute name if `from` is set to `resource_attribute`).\nFollowing rule types are available:\n\n**from: \"connection\"** - takes the IP attribute from connection context (if available)\n**from: \"resource_attribute\"** - allows to specify the attribute name to lookup up in the list of attributes of the received Resource.\n                                 Semantic convention should be used for naming.\n\nPod association configuration.\n\n```yaml\npod_association:\n  # below association takes a look at the datapoint's k8s.pod.ip resource attribute and tries to match it with\n  # the pod having the same attribute.\n  - sources:\n      - from: resource_attribute\n        name: k8s.pod.ip\n  # below association matches for pair `k8s.pod.name` and `k8s.namespace.name`\n  - sources:\n      - from: resource_attribute\n        name: k8s.pod.name\n      - from: resource_attribute\n        name: k8s.namespace.name\n```\n\nIf Pod association rules are not configured, resources are associated with metadata only by connection's IP Address.\n\nWhich metadata to collect is determined by `metadata` configuration that defines list of resource attributes\nto be added. Items in the list called exactly the same as the resource attributes that will be added.\nThe following attributes are added by default: \n  - k8s.namespace.name\n  - k8s.pod.name\n  - k8s.pod.uid\n  - k8s.pod.start_time\n  - k8s.deployment.name\n  - k8s.node.name\n\nYou can change this list with `metadata` configuration.\n\nNot all the attributes are guaranteed to be added. Only attribute names from `metadata` should be used for \npod_association's `resource_attribute`, because empty or non-existing values will be ignored.\n\nAdditional container level attributes can be extracted provided that certain resource attributes are provided:\n\n1. If the `container.id` resource attribute is provided, the following additional attributes will be available:\n   - k8s.container.name\n   - container.image.name\n   - container.image.tag\n2. If the `k8s.container.name` resource attribute is provided, the following additional attributes will be available:\n   - container.image.name\n   - container.image.tag\n3. If the `k8s.container.restart_count` resource attribute is provided, it can be used to associate with a particular container\n   instance. If it's not set, the latest container instance will be used:\n   - container.id (not added by default, has to be specified in `metadata`)\n\nThe k8sattributesprocessor can also set resource attributes from k8s labels and annotations of pods and namespaces.\nThe config for associating the data passing through the processor (spans, metrics and logs) with specific Pod/Namespace annotations/labels is configured via \"annotations\"  and \"labels\" keys.\nThis config represents a list of annotations/labels that are extracted from pods/namespaces and added to spans, metrics and logs.\nEach item is specified as a config of tag_name (representing the tag name to tag the spans with),\nkey (representing the key used to extract value) and from (representing the kubernetes object used to extract the value).\nThe \"from\" field has only two possible values \"pod\" and \"namespace\" and defaults to \"pod\" if none is specified.\n\nA few examples to use this config are as follows:\n\n```yaml\nannotations:\n  - tag_name: a1 # extracts value of annotation from pods with key `annotation-one` and inserts it as a tag with key `a1`\n    key: annotation-one\n    from: pod\n  - tag_name: a2 # extracts value of annotation from namespaces with key `annotation-two` with regexp and inserts it as a tag with key `a2`\n    key: annotation-two\n    regex: field=(?P\u003cvalue\u003e.+)\n    from: namespace\n\nlabels:\n  - tag_name: l1 # extracts value of label from namespaces with key `label1` and inserts it as a tag with key `l1`\n    key: label1\n    from: namespace\n  - tag_name: l2 # extracts value of label from pods with key `label2` with regexp and inserts it as a tag with key `l2`\n    key: label2\n    regex: field=(?P\u003cvalue\u003e.+)\n    from: pod\n```\n\n### Config example\n\n```yaml\nk8sattributes:\nk8sattributes/2:\n auth_type: \"serviceAccount\"\n passthrough: false\n filter:\n   node_from_env_var: KUBE_NODE_NAME\n extract:\n   metadata:\n     - k8s.pod.name\n     - k8s.pod.uid\n     - k8s.deployment.name\n     - k8s.namespace.name\n     - k8s.node.name\n     - k8s.pod.start_time\n pod_association:\n   - sources:\n       - from: resource_attribute\n         name: k8s.pod.ip\n   - sources:\n       - from: resource_attribute\n         name: k8s.pod.uid\n   - sources:\n       - from: connection\n```\n\n## Role-based access control\n\nThe k8sattributesprocessor needs `get`, `watch` and `list` permissions on both `pods` and `namespaces` resources, for all namespaces and pods included in the configured filters. Additionally, when using `k8s.deployment.uid` or `k8s.deployment.name` the processor also needs `get`, `watch` and `list` permissions for `replicaset` resources.\n\nHere is an example of a `ClusterRole` to give a `ServiceAccount` the necessary permissions for all pods and namespaces in the cluster (replace `\u003cOTEL_COL_NAMESPACE\u003e` with a namespace where collector is deployed):\n\n```yaml\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: collector\n  namespace: \u003cOTEL_COL_NAMESPACE\u003e\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: otel-collector\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"namespaces\"]\n  verbs: [\"get\", \"watch\", \"list\"]\n- apiGroups: [\"apps\"]\n  resources: [\"replicasets\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"extensions\"]\n  resources: [\"replicasets\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: otel-collector\nsubjects:\n- kind: ServiceAccount\n  name: collector\n  namespace: \u003cOTEL_COL_NAMESPACE\u003e\nroleRef:\n  kind: ClusterRole\n  name: otel-collector\n  apiGroup: rbac.authorization.k8s.io\n```\n\n## Deployment scenarios\n\nThe processor can be used in collectors deployed both as an agent (Kubernetes DaemonSet) or as a gateway (Kubernetes Deployment).\n\n### As an agent\n\nWhen running as an agent, the processor detects IP addresses of pods sending spans, metrics or logs to the agent\nand uses this information to extract metadata from pods. When running as an agent, it is important to apply\na discovery filter so that the processor only discovers pods from the same host that it is running on. Not using\nsuch a filter can result in unnecessary resource usage especially on very large clusters. Once the filter is applied,\neach processor will only query the k8s API for pods running on it's own node.\n\nNode filter can be applied by setting the `filter.node` config option to the name of a k8s node. While this works\nas expected, it cannot be used to automatically filter pods by the same node that the processor is running on in\nmost cases as it is not know before hand which node a pod will be scheduled on. Luckily, kubernetes has a solution\nfor this called the downward API. To automatically filter pods by the node the processor is running on, you'll need\nto complete the following steps:\n\n1. Use the downward API to inject the node name as an environment variable.\nAdd the following snippet under the pod env section of the OpenTelemetry container.\n\n```yaml\n2. spec:\n  containers:\n  - env:\n    - name: KUBE_NODE_NAME\n      valueFrom:\n        fieldRef:\n          apiVersion: v1\n          fieldPath: spec.nodeName\n```\n\nThis will inject a new environment variable to the OpenTelemetry container with the value as the\nname of the node the pod was scheduled to run on.\n\n2. Set \"filter.node_from_env_var\" to the name of the environment variable holding the node name.\n\n```yaml\nk8sattributes:\n  filter:\n    node_from_env_var: KUBE_NODE_NAME # this should be same as the var name used in previous step\n```\n\nThis will restrict each OpenTelemetry agent to query pods running on the same node only dramatically reducing\nresource requirements for very large clusters.\n\n### As a gateway\n\nWhen running as a gateway, the processor cannot correctly detect the IP address of the pods generating\nthe telemetry data without any of the well-known IP attributes, when it receives them\nfrom an agent instead of receiving them directly from the pods. To\nworkaround this issue, agents deployed with the k8sattributes processor can be configured to detect\nthe IP addresses and forward them along with the telemetry data resources. Collector can then match this IP address\nwith k8s pods and enrich the records with the metadata. In order to set this up, you'll need to complete the\nfollowing steps:\n\n1. Setup agents in passthrough mode\nConfigure the agents' k8sattributes processors to run in passthrough mode.\n\n```yaml\n# k8sattributes config for agent\nk8sattributes:\n  passthrough: true\n```\n\nThis will ensure that the agents detect the IP address as add it as an attribute to all telemetry resources.\nAgents will not make any k8s API calls, do any discovery of pods or extract any metadata.\n\n2. Configure the collector as usual\nNo special configuration changes are needed to be made on the collector. It'll automatically detect\nthe IP address of spans, logs and metrics sent by the agents as well as directly by other services/pods.\n\n## Caveats\n\nThere are some edge-cases and scenarios where k8sattributes will not work properly.\n\n### Host networking mode\n\nThe processor cannot correct identify pods running in the host network mode and\nenriching telemetry data generated by such pods is not supported at the moment, unless the association\nrule is not based on IP attribute.\n\n### As a sidecar\n\nThe processor does not support detecting containers from the same pods when running\nas a sidecar. While this can be done, we think it is simpler to just use the kubernetes\ndownward API to inject environment variables into the pods and directly use their values\nas tags.","properties":{"auth_type":{"description":"How to authenticate to the K8s API server.  This can be one of `none`\n(for no auth), `serviceAccount` (to use the standard service account\ntoken provided to the agent pod), or `kubeConfig` to use credentials\nfrom `~/.kube/config`.","title":"auth_type","type":"string"},"exclude":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.k8sattributesprocessor.ExcludeConfig","description":"Exclude section allows to define names of pod that should be\nignored while tagging.","title":"exclude"},"extract":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.k8sattributesprocessor.ExtractConfig","description":"Extract section allows specifying extraction rules to extract\ndata from k8s pod specs","title":"extract"},"filter":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.k8sattributesprocessor.FilterConfig","description":"Filter section allows specifying filters to filter\npods by labels, fields, namespaces, nodes, etc.","title":"filter"},"passthrough":{"description":"Passthrough mode only annotates resources with the pod IP and\ndoes not try to extract any other metadata. It does not need\naccess to the K8S cluster API. Agent/Collector must receive spans\ndirectly from services to be able to correctly detect the pod IPs.","title":"passthrough","type":"boolean"},"pod_association":{"description":"Association section allows to define rules for tagging spans, metrics,\nand logs with Pod metadata.","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.k8sattributesprocessor.PodAssociationConfig"},"title":"pod_association","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.k8sattributesprocessor.ExcludeConfig":{"additionalProperties":false,"description":"ExcludeConfig represent a list of Pods to exclude","properties":{"pods":{"items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.k8sattributesprocessor.ExcludePodConfig"},"title":"pods","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.k8sattributesprocessor.ExcludePodConfig":{"additionalProperties":false,"description":"ExcludePodConfig represent a Pod name to ignore","properties":{"name":{"title":"name","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.k8sattributesprocessor.ExtractConfig":{"additionalProperties":false,"description":"ExtractConfig section allows specifying extraction rules to extract data from k8s pod specs.","properties":{"annotations":{"description":"Annotations allows extracting data from pod annotations and record it\nas resource attributes.\nIt is a list of FieldExtractConfig type. See FieldExtractConfig\ndocumentation for more details.","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.k8sattributesprocessor.FieldExtractConfig"},"title":"annotations","type":"array"},"labels":{"description":"Labels allows extracting data from pod labels and record it\nas resource attributes.\nIt is a list of FieldExtractConfig type. See FieldExtractConfig\ndocumentation for more details.","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.k8sattributesprocessor.FieldExtractConfig"},"title":"labels","type":"array"},"metadata":{"description":"Metadata allows to extract pod/namespace metadata from a list of metadata fields.\nThe field accepts a list of strings.\n\nMetadata fields supported right now are,\n  k8s.pod.name, k8s.pod.uid, k8s.deployment.name,\n  k8s.node.name, k8s.namespace.name, k8s.pod.start_time,\n  k8s.replicaset.name, k8s.replicaset.uid,\n  k8s.daemonset.name, k8s.daemonset.uid,\n  k8s.job.name, k8s.job.uid, k8s.cronjob.name,\n  k8s.statefulset.name, k8s.statefulset.uid,\n  k8s.container.name, container.image.name,\n  container.image.tag, container.id\n\nSpecifying anything other than these values will result in an error.\nBy default, the following fields are extracted and added to spans, metrics and logs as attributes:\n - k8s.pod.name\n - k8s.pod.uid\n - k8s.pod.start_time\n - k8s.namespace.name\n - k8s.node.name\n - k8s.deployment.name (if the pod is controlled by a deployment)\n - k8s.container.name (requires an additional attribute to be set: container.id)\n - container.image.name (requires one of the following additional attributes to be set: container.id or k8s.container.name)\n - container.image.tag (requires one of the following additional attributes to be set: container.id or k8s.container.name)","items":{"type":"string"},"title":"metadata","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.k8sattributesprocessor.FieldExtractConfig":{"additionalProperties":false,"description":"FieldExtractConfig allows specifying an extraction rule to extract a resource attribute from pod (or namespace) annotations (or labels).","properties":{"from":{"description":"From represents the source of the labels/annotations.\nAllowed values are \"pod\" and \"namespace\". The default is pod.","title":"from","type":"string"},"key":{"description":"Key represents the annotation (or label) name. This must exactly match an annotation (or label) name.","title":"key","type":"string"},"key_regex":{"description":"KeyRegex is a regular expression used to extract a Key that matches the regex.\nOut of Key or KeyRegex, only one option is expected to be configured at a time.","title":"key_regex","type":"string"},"regex":{"description":"Regex is an optional field used to extract a sub-string from a complex field value.\nThe supplied regular expression must contain one named parameter with the string \"value\"\nas the name. For example, if your pod spec contains the following annotation,\n\nkubernetes.io/change-cause: 2019-08-28T18:34:33Z APP_NAME=my-app GIT_SHA=58a1e39 CI_BUILD=4120\n\nand you'd like to extract the GIT_SHA and the CI_BUILD values as tags, then you must\nspecify the following two extraction rules:\n\nextract:\n  annotations:\n    - tag_name: git.sha\n      key: kubernetes.io/change-cause\n      regex: GIT_SHA=(?P\u003cvalue\u003e\\w+)\n    - tag_name: ci.build\n      key: kubernetes.io/change-cause\n      regex: JENKINS=(?P\u003cvalue\u003e[\\w]+)\n\nthis will add the `git.sha` and `ci.build` resource attributes.","title":"regex","type":"string"},"tag_name":{"description":"TagName represents the name of the resource attribute that will be added to logs, metrics or spans.\nWhen not specified, a default tag name will be used of the format:\n  - k8s.pod.annotations.\u003cannotation key\u003e\n  - k8s.pod.labels.\u003clabel key\u003e\nFor example, if tag_name is not specified and the key is git_sha,\nthen the attribute name will be `k8s.pod.annotations.git_sha`.\nWhen key_regex is present, tag_name supports back reference to both named capturing and positioned capturing.\nFor example, if your pod spec contains the following labels,\n\napp.kubernetes.io/component: mysql\napp.kubernetes.io/version: 5.7.21\n\nand you'd like to add tags for all labels with prefix app.kubernetes.io/ and also trim the prefix,\nthen you can specify the following extraction rules:\n\nextract:\n  labels:\n    - tag_name: $$1\n      key_regex: kubernetes.io/(.*)\n\nthis will add the `component` and `version` tags to the spans or metrics.","title":"tag_name","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.k8sattributesprocessor.FieldFilterConfig":{"additionalProperties":false,"description":"FieldFilterConfig allows specifying exactly one filter by a field.","properties":{"key":{"description":"Key represents the key or name of the field or labels that a filter\ncan apply on.","title":"key","type":"string"},"op":{"description":"Op represents the filter operation to apply on the given\nKey: Value pair. The following operations are supported\n  equals, not-equals, exists, does-not-exist.","title":"op","type":"string"},"value":{"description":"Value represents the value associated with the key that a filter\noperation specified by the `Op` field applies on.","title":"value","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.k8sattributesprocessor.FilterConfig":{"additionalProperties":false,"description":"FilterConfig section allows specifying filters to filter pods by labels, fields, namespaces, nodes, etc.","properties":{"fields":{"description":"Fields allows to filter pods by generic k8s fields.\nOnly the following operations are supported:\n   - equals\n   - not-equals\n\nCheck FieldFilterConfig for more details.","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.k8sattributesprocessor.FieldFilterConfig"},"title":"fields","type":"array"},"labels":{"description":"Labels allows to filter pods by generic k8s pod labels.\nOnly the following operations are supported:\n   - equals\n   - not-equals\n   - exists\n   - not-exists\n\nCheck FieldFilterConfig for more details.","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.k8sattributesprocessor.FieldFilterConfig"},"title":"labels","type":"array"},"namespace":{"description":"Namespace filters all pods by the provided namespace. All other pods are ignored.","title":"namespace","type":"string"},"node":{"description":"Node represents a k8s node or host. If specified, any pods not running\non the specified node will be ignored by the tagger.","title":"node","type":"string"},"node_from_env_var":{"description":"NodeFromEnv can be used to extract the node name from an environment\nvariable. The value must be the name of the environment variable.\nThis is useful when the node a Otel agent will run on cannot be\npredicted. In such cases, the Kubernetes downward API can be used to\nadd the node name to each pod as an environment variable. K8s tagger\ncan then read this value and filter pods by it.\n\nFor example, node name can be passed to each agent with the downward API as follows\n\nenv:\n  - name: K8S_NODE_NAME\n    valueFrom:\n      fieldRef:\n        fieldPath: spec.nodeName\n\nThen the NodeFromEnv field can be set to `K8S_NODE_NAME` to filter all pods by the node that\nthe agent is running on.\n\nMore on downward API here: https://kubernetes.io/docs/tasks/inject-data-application/environment-variable-expose-pod-information/","title":"node_from_env_var","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.k8sattributesprocessor.PodAssociationConfig":{"additionalProperties":false,"description":"PodAssociationConfig contain single rule how to associate Pod metadata with logs, spans and metrics","properties":{"sources":{"description":"List of pod association sources which should be taken\nto identify pod","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.k8sattributesprocessor.PodAssociationSourceConfig"},"title":"sources","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.k8sattributesprocessor.PodAssociationSourceConfig":{"additionalProperties":false,"properties":{"from":{"description":"From represents the source of the association.\nAllowed values are \"connection\" and \"resource_attribute\".","title":"from","type":"string"},"name":{"description":"Name represents extracted key name.\ne.g. ip, pod_uid, k8s.pod.ip","title":"name","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.metricsgenerationprocessor.Config":{"additionalProperties":false,"description":"Config defines the configuration for the processor.","markdownDescription":"# Metrics Generation Processor\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [development]: metrics   |\n| Distributions | [contrib], [aws], [sumo] |\n\n[development]: https://github.com/open-telemetry/opentelemetry-collector#development\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\n**Status: under development; Not recommended for production usage.**\n\n## Description\n\nThe metrics generation processor (`experimental_metricsgenerationprocessor`) can be used to create new metrics using existing metrics following a given rule. Currently it supports following two approaches for creating a new metric.\n\n1. It can create a new metric from two existing metrics by applying one of the folliwing arithmetic operations: add, subtract, multiply, divide and percent. One use case is to calculate the `pod.memory.utilization` metric like the following equation-\n`pod.memory.utilization` = (`pod.memory.usage.bytes` / `node.memory.limit`)\n1. It can create a new metric by scaling the value of an existing metric with a given constant number. One use case is to convert `pod.memory.usage` metric values from Megabytes to Bytes (multiply the existing metric's value by 1,048,576)\n\n## Configuration\n\nConfiguration is specified through a list of generation rules. Generation rules find the metrics which \nmatch the given metric names and apply the specified operation to those metrics.\n\n```yaml\nprocessors:\n    # processor name: experimental_metricsgeneration\n    experimental_metricsgeneration:\n\n        # specify the metric generation rules\n        rules:\n              # Name of the new metric. This is a required field.\n            - name: \u003cnew_metric_name\u003e\n\n              # Unit for the new metric being generated.\n              unit: \u003cnew_metric_unit\u003e\n\n              # type describes how the new metric will be generated. It can be one of `calculate` or `scale`.  calculate generates a metric applying the given operation on two operand metrics. scale operates only on operand1 metric to generate the new metric.\n              type: {calculate, scale}\n\n              # This is a required field.\n              metric1: \u003cfirst_operand_metric\u003e\n\n              # This field is required only if the type is \"calculate\".\n              metric2: \u003csecond_operand_metric\u003e\n\n              # Operation specifies which arithmetic operation to apply. It must be one of the five supported operations.\n              operation: {add, subtract, multiply, divide, percent}\n```\n\n## Example Configurations\n\n### Create a new metric using two existing metrics\n```yaml\n# create pod.cpu.utilized following (pod.cpu.usage / node.cpu.limit)\nrules:\n    - name: pod.cpu.utilized\n      type: calculate\n      metric1: pod.cpu.usage\n      metric2: node.cpu.limit\n      operation: divide\n```\n\n### Create a new metric scaling the value of an existing metric\n```yaml\n# create pod.memory.usage.bytes from pod.memory.usage.megabytes\nrules:\n    - name: pod.memory.usage.bytes\n      unit: Bytes\n      type: scale\n      metric1: pod.memory.usage.megabytes\n      operation: multiply\n      scale_by: 1048576\n```","properties":{"rules":{"description":"Set of rules for generating new metrics","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.metricsgenerationprocessor.Rule"},"title":"rules","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.metricsgenerationprocessor.Rule":{"additionalProperties":false,"properties":{"metric1":{"description":"First operand metric to use in the calculation. This is a required field.","title":"metric1","type":"string"},"metric2":{"description":"Second operand metric to use in the calculation. A required field if the type is calculate.","title":"metric2","type":"string"},"name":{"description":"Name of the new metric being generated. This is a required field.","title":"name","type":"string"},"operation":{"description":"The arithmetic operation to apply for the calculation. This is a required field.","title":"operation","type":"string"},"scale_by":{"description":"A constant number by which the first operand will be scaled. A required field if the type is scale.","title":"scale_by","type":"number"},"type":{"description":"The rule type following which the new metric will be generated. This is a required field.","title":"type","type":"string"},"unit":{"description":"Unit for the new metric being generated.","title":"unit","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.metricstransformprocessor.Config":{"additionalProperties":false,"description":"Config defines configuration for Resource processor.","markdownDescription":"# Metrics Transform Processor\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [contrib], [aws], [observiq], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\n## Description\n\nThe metrics transform processor can be used to rename metrics, and add, rename\nor delete label keys and values. It can also be used to perform scaling and\naggregations on metrics across labels or label values. The complete list of\nsupported operations that can be applied to one or more metrics is provided in\nthe below table.\n\n:information_source: This processor only supports renames/aggregations **within\na batch of metrics**. It does not do any aggregation across batches, so it is\nnot suitable for aggregating metrics from multiple sources (e.g. multiple nodes\nor clients).\n\n| Operation                     | Example (based on metric `system.cpu.usage`)                                                    |\n|-------------------------------|-------------------------------------------------------------------------------------------------|\n| Rename metrics                | Rename to `system.cpu.usage_time`                                                               |\n| Add labels                    | Add new label `identifier` with value `1` to all points                                         |\n| Rename label keys             | Rename label `state` to `cpu_state`                                                             |\n| Rename label values           | For label `state`, rename value `idle` to `-`                                                   |\n| Delete data points            | Delete all points where label `state` has value `idle`                                          |\n| Toggle data type              | Change from `int` data points to `double` data points                                           |\n| Scale value                   | Multiply values by 1000 to convert from seconds to milliseconds                                 |\n| Aggregate across label sets   | Retain only the label `state`, average all points with the same value for this label            |\n| Aggregate across label values | For label `state`, sum points where the value is `user` or `system` into `used = user + system` |\n\nIn addition to the above:\n\n- Operations can be applied to one or more metrics using a `strict` or `regexp`\n  filter\n- The `action` property allows metrics to be:\n  - Updated in-place (`update`)\n  - Copied and updates applied to the copy (`insert`)\n  - Combined into a newly inserted metric that is generated by combining all data\n    points from the set of matching metrics into a single metric (`combine`); the\n    original matching metrics are also removed\n- When renaming metrics, capturing groups from the `regexp` filter will be\n  expanded\n- When adding or updating a label value, `{{version}}` will be replaced with\n  this collector's version number\n\n## Configuration\n\nConfiguration is specified through a list of transformations and operations.\nTransformations and operations will be applied to all metrics in order so that\nlater transformations or operations may reference the result of previous\ntransformations or operations.\n\n```yaml\nprocessors:\n  metricstransform:\n  # transforms is a list of transformations with each element transforming a metric selected by metric name\n    transforms:\n    \n        # SPECIFY WHICH METRIC(S) TO MATCH\n        \n        # include specifies the metric name used to determine which metric(s) to operate on\n      - include: \u003cmetric_name\u003e\n        # match_type specifies whether the include name should be used as a strict match or regexp match, default = strict\n        match_type: {strict, regexp}\n    \n        # experimental_match_labels specifies the label set against which the metric filter will work. If experimental_match_labels is specified, transforms will only be applied to those metrics which \n        # have the provided metric label values. This works for both strict and regexp match_type. This is an experimental feature.\n        experimental_match_labels: {\u003clabel1\u003e: \u003clabel_value1\u003e, \u003clabel2\u003e: \u003clabel_value2\u003e}\n        \n        # SPECIFY THE ACTION TO TAKE ON THE MATCHED METRIC(S)\n        \n        # action specifies if the operations (specified below) are performed on metrics in place (update), on an inserted clone (insert), or on a new combined metric (combine)\n        action: {update, insert, combine}\n        \n        # SPECIFY HOW TO TRANSFORM THE METRIC GENERATED AS A RESULT OF APPLYING THE ABOVE ACTION\n        \n        # new_name specifies the updated name of the metric; if action is insert or combine, new_name is required\n        new_name: \u003cnew_metric_name_inserted\u003e\n        # aggregation_type defines how combined data points will be aggregated; if action is combine, aggregation_type is required\n        aggregation_type: {sum, mean, min, max}\n        # submatch_case specifies the case that should be used when adding label values based on regexp submatches when performing a combine action; leave blank to use the submatch value as is\n        submatch_case: {lower, upper}\n        # operations contain a list of operations that will be performed on the resulting metric(s)\n        operations:\n            # action defines the type of operation that will be performed, see examples below for more details\n          - action: {add_label, update_label, delete_label_value, toggle_scalar_data_type, experimental_scale_value, aggregate_labels, aggregate_label_values}\n            # label specifies the label to operate on\n            label: \u003clabel\u003e\n            # new_label specifies the updated name of the label; if action is add_label, new_label is required\n            new_label: \u003cnew_label\u003e\n            # aggregated_values contains a list of label values that will be aggregated; if action is aggregate_label_values, aggregated_values is required\n            aggregated_values: [values...]\n            # new_value specifies the updated name of the label value; if action is add_label or aggregate_label_values, new_value is required\n            new_value: \u003cnew_value\u003e\n            # label_value specifies the label value for which points should be deleted; if action is delete_label_value, label_value is required\n            label_value: \u003clabel_value\u003e\n            # label_set contains a list of labels that will remain after aggregation; if action is aggregate_labels, label_set is required\n            label_set: [labels...]\n            # aggregation_type defines how data points will be aggregated; if action is aggregate_labels or aggregate_label_values, aggregation_type is required\n            aggregation_type: {sum, mean, min, max}\n            # experimental_scale specifies the scalar to apply to values\n            experimental_scale: \u003cscalar\u003e\n            # value_actions contain a list of operations that will be performed on the selected label\n            value_actions:\n                # value specifies the value to operate on\n              - value: \u003ccurrent_label_value\u003e\n                # new_value specifies the updated value\n                new_value: \u003cnew_label_value\u003e\n```\n\n## Examples\n\n### Create a new metric from an existing metric\n```yaml\n# create host.cpu.utilization from host.cpu.usage\ninclude: host.cpu.usage\naction: insert\nnew_name: host.cpu.utilization\noperations:\n  ...\n```\n\n### Create a new metric from an existing metric with matching label values\n```yaml\n# create host.cpu.utilization from host.cpu.usage where we have metric label \"container=my_container\"\ninclude: host.cpu.usage\naction: insert\nnew_name: host.cpu.utilization\nmatch_type: strict\nexperimental_match_labels: {\"container\": \"my_container\"}\noperations:\n  ...\n```\n\n### Create a new metric from an existing metric with matching label values with regexp\n```yaml\n# create host.cpu.utilization from host.cpu.usage where we have metric label pod with non-empty values\ninclude: host.cpu.usage\naction: insert\nnew_name: host.cpu.utilization\nmatch_type: regexp\nexperimental_match_labels: {\"pod\": \"(.|\\\\s)*\\\\S(.|\\\\s)*\"}\noperations:\n  ...\n```\n\n### Rename metric\n```yaml\n# rename system.cpu.usage to system.cpu.usage_time\ninclude: system.cpu.usage\naction: update\nnew_name: system.cpu.usage_time\n```\n\n### Rename multiple metrics using Substitution\n```yaml\n# rename all system.cpu metrics to system.processor.*.stat\n# instead of regular $ use double dollar $$. Because $ is treated as a special character.\n# wrap the group name/number with braces\ninclude: ^system\\.cpu\\.(.*)$$\nmatch_type: regexp\naction: update\nnew_name: system.processor.$${1}.stat\n```\n\n### Add a label\n```yaml\n# for system.cpu.usage_time, add label `version` with value `opentelemetry collector vX.Y.Z` to all points\ninclude: system.cpu.usage\naction: update\noperations:\n  - action: add_label\n    new_label: version\n    new_value: opentelemetry collector {{version}}\n```\n\n### Add a label to multiple metrics\n```yaml\n# for all system metrics, add label `version` with value `opentelemetry collector vX.Y.Z` to all points\ninclude: ^system\\.\nmatch_type: regexp\naction: update\noperations:\n  - action: add_label\n    new_label: version\n    new_value: opentelemetry collector {{version}}\n```\n\n### Rename labels\n```yaml\n# for system.cpu.usage_time, rename the label state to cpu_state\ninclude: system.cpu.usage\naction: update\noperations:\n  - action: update_label\n    label: state\n    new_label: cpu_state\n```\n\n### Rename labels for multiple metrics\n```yaml\n# for all system.cpu metrics, rename the label state to cpu_state\ninclude: ^system\\.cpu\\.\naction: update\noperations:\n  - action: update_label\n    label: state\n    new_label: cpu_state\n```\n\n### Rename label values\n```yaml\n# rename the label value slab_reclaimable to sreclaimable, slab_unreclaimable to sunreclaimable\ninclude: system.memory.usage\naction: update\noperations:\n  - action: update_label\n    label: state\n    value_actions:\n      - value: slab_reclaimable\n        new_value: sreclaimable\n      - value: slab_unreclaimable\n        new_value: sunreclaimable\n```\n\n### Delete by label value\n```yaml\n# deletes all data points with the label value 'idle' of the label 'state'\ninclude: system.cpu.usage\naction: update\noperations:\n  - action: delete_label_value\n    label: state\n    label_value: idle\n```\n\n### Toggle datatype\n```yaml\n# toggle the datatype of cpu usage from int (the default) to double\ninclude: system.cpu.usage\naction: update\noperations:\n  - action: toggle_scalar_data_type\n```\n\n### Scale value\n```yaml\n# experimental_scale CPU usage from seconds to milliseconds\ninclude: system.cpu.usage\naction: update\noperations:\n  - action: experimental_scale_value\n    experimental_scale: 1000\n```\n\n### Aggregate labels\n```yaml\n# aggregate away all labels except `state` using summation\ninclude: system.cpu.usage\naction: update\noperations:\n  - action: aggregate_labels\n    label_set: [ state ]\n    aggregation_type: sum\n```\n\n### Aggregate label values\n```yaml\n# aggregate data points with state label value slab_reclaimable \u0026 slab_unreclaimable using summation into slab\ninclude: system.memory.usage\naction: update\noperations:\n  - action: aggregate_label_values\n    label: state\n    aggregated_values: [ slab_reclaimable, slab_unreclaimable ]\n    new_value: slab \n    aggregation_type: sum\n```\n\n### Combine metrics\n```yaml\n# convert a set of metrics for each http_method into a single metric with an http_method label, i.e.\n#\n# Web Service (*)/Total Delete Requests     iis.requests{http_method=delete}\n# Web Service (*)/Total Get Requests     \u003e  iis.requests{http_method=get}\n# Web Service (*)/Total Post Requests       iis.requests{http_method=post}\ninclude: ^Web Service \\(\\*\\)/Total (?P\u003chttp_method\u003e.*) Requests$\nmatch_type: regexp\naction: combine\nnew_name: iis.requests\nsubmatch_case: lower\noperations:\n  ...\n```\n\n### Group Metrics \n```yaml\n# Group metrics from one single ResourceMetrics and report them as multiple ResourceMetrics.\n# \n# ex: Consider pod and container metrics collected from Kubernetes. Both the metrics are recorded under under one ResourceMetric\n# applying this transformation will result in two separate ResourceMetric packets with corresponding resource labels in the resource headers\n#\n# instead of regular $ use double dollar $$. Because $ is treated as a special character.\n\n\n- include: ^k8s\\.pod\\.(.*)$$\n  match_type: regexp\n  action: group\n  group_resource_labels: {\"resouce.type\": \"k8s.pod\", \"source\": \"kubelet\"}\n- include: ^container\\.(.*)$$\n  match_type: regexp\n  action: group\n  group_resource_labels: {\"resouce.type\": \"container\", \"source\": \"kubelet\"}\n```\n\n### Metric Transform Processor vs. [Attributes Processor for Metrics](../attributesprocessor)\n\nRegarding metric support, these two processors have overlapping functionality. They can both do simple modifications\nof metric attribute key-value pairs. As a general rule the attributes processor has more attribute related\nfunctionality, while the metrics transform processor can do much more data manipulation. The attributes processor\nis preferred when the only needed functionality is overlapping, as it natively uses the official OpenTelemetry\ndata model. However, if the metric transform processor is already in use or its extra functionality is necessary,\nthere's no need to migrate away from it.\n\nShared functionality\n* Add attributes\n* Update values of attributes\n\nAttribute processor specific functionality\n* delete\n* hash\n* extract\n\nMetric transform processor specific functionality\n* Rename metrics\n* Delete data points\n* Toggle data type\n* Scale value\n* Aggregate across label sets\n* Aggregate across label values","properties":{"transforms":{"description":"Transform specifies a list of transforms on metrics with each transform focusing on one metric.","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.metricstransformprocessor.Transform"},"title":"transforms","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.metricstransformprocessor.Operation":{"additionalProperties":false,"description":"Operation defines the specific operation performed on the selected metrics.","properties":{"action":{"description":"Action specifies the action performed for this operation.\nREQUIRED","title":"action","type":"string"},"aggregated_values":{"description":"AggregatedValues is a list of label values to aggregate away.","items":{"type":"string"},"title":"aggregated_values","type":"array"},"aggregation_type":{"description":"AggregationType specifies how to aggregate.","title":"aggregation_type","type":"string"},"experimental_scale":{"description":"Scale is a scalar to multiply the values with.","title":"experimental_scale","type":"number"},"label":{"description":"Label identifies the exact label to operate on.","title":"label","type":"string"},"label_set":{"description":"LabelSet is a list of labels to keep. All other labels are aggregated based on the AggregationType.","items":{"type":"string"},"title":"label_set","type":"array"},"label_value":{"description":"LabelValue identifies the exact label value to operate on","title":"label_value","type":"string"},"new_label":{"description":"NewLabel determines the name to rename the identified label to.","title":"new_label","type":"string"},"new_value":{"description":"NewValue is used to set a new label value either when the operation is `AggregatedValues` or `AddLabel`.","title":"new_value","type":"string"},"value_actions":{"description":"ValueActions is a list of renaming actions for label values.","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.metricstransformprocessor.ValueAction"},"title":"value_actions","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.metricstransformprocessor.Transform":{"additionalProperties":false,"description":"Transform defines the transformation applied to the specific metric","properties":{"action":{"description":"Action specifies the action performed on the matched metric. Action specifies\nif the operations (specified below) are performed on metrics in place (update),\non an inserted clone (insert), or on a new combined metric that includes all\ndata points from the set of matching metrics (combine).\nREQUIRED","title":"action","type":"string"},"aggregation_type":{"description":"AggregationType specifies how to aggregate.\nREQUIRED only if Action is COMBINE.","title":"aggregation_type","type":"string"},"experimental_match_labels":{"description":"MatchLabels specifies the label set against which the metric filter will work.\nThis field is optional.","patternProperties":{".*":{"type":"string"}},"title":"experimental_match_labels","type":"object"},"group_resource_labels":{"description":"GroupResourceLabels specifes resource labels that will be appended to this group's new ResourceMetrics message\nREQUIRED only if Action is GROUP","patternProperties":{".*":{"type":"string"}},"title":"group_resource_labels","type":"object"},"include":{"description":"Include specifies the metric(s) to operate on.","title":"include","type":"string"},"match_type":{"description":"MatchType determines how the Include string is matched: \u003cstrict|regexp\u003e.","title":"match_type","type":"string"},"new_name":{"description":"NewName specifies the name of the new metric when inserting or updating.\nREQUIRED only if Action is INSERT.","title":"new_name","type":"string"},"operations":{"description":"Operations contains a list of operations that will be performed on the resulting metric(s).","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.metricstransformprocessor.Operation"},"title":"operations","type":"array"},"submatch_case":{"description":"SubmatchCase specifies what case to use for label values created from regexp submatches.","title":"submatch_case","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.metricstransformprocessor.ValueAction":{"additionalProperties":false,"description":"ValueAction renames label values.","properties":{"new_value":{"description":"NewValue specifies the label value to rename to.","title":"new_value","type":"string"},"value":{"description":"Value specifies the current label value.","title":"value","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.probabilisticsamplerprocessor.Config":{"additionalProperties":false,"description":"Config has the configuration guiding the sampler processor.","properties":{"attribute_source":{"title":"attribute_source","type":"string"},"from_attribute":{"description":"FromAttribute (logs only) The optional name of a log record attribute used for sampling purposes, such as a\nunique log record ID. The value of the attribute is only used if the trace ID is absent or if `attribute_source` is set to `record`.","title":"from_attribute","type":"string"},"hash_seed":{"description":"HashSeed allows one to configure the hashing seed. This is important in scenarios where multiple layers of collectors\nhave different sampling rates: if they use the same seed all passing one layer may pass the other even if they have\ndifferent sampling rates, configuring different seeds avoids that.","title":"hash_seed","type":"integer"},"sampling_percentage":{"description":"SamplingPercentage is the percentage rate at which traces or logs are going to be sampled. Defaults to zero, i.e.: no sample.\nValues greater or equal 100 are treated as \"sample all traces/logs\".","title":"sampling_percentage","type":"number"},"sampling_priority":{"description":"SamplingPriority (logs only) allows to use a log record attribute designed by the `sampling_priority` key\nto be used as the sampling priority of the log record.","title":"sampling_priority","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.redactionprocessor.Config":{"additionalProperties":false,"markdownDescription":"# Redaction processor\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: traces   |\n| Distributions | [contrib], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThis processor deletes span attributes that don't match a list of allowed span\nattributes. It also masks span attribute values that match a blocked value\nlist. Span attributes that aren't on the allowed list are removed before any\nvalue checks are done.\n\n## Use Cases\n\nTypical use-cases:\n\n* Prevent sensitive fields from accidentally leaking into traces\n* Ensure compliance with legal, privacy, or security requirements\n\nFor example:\n\n* EU General Data Protection Regulation (GDPR) prohibits the transfer of any\n  personal data like birthdates, addresses, or ip addresses across borders\n  without explicit consent from the data subject. Popular trace aggregation\n  services are located in US, not in EU. You can use the redaction processor\n  to scrub personal data from your data.\n* PRC legislation prohibits the transfer of geographic coordinates outside of\n  the PRC. Popular trace aggregation services are located in US, not in the\n  PRC. You can use the redaction processor to scrub geographic coordinates\n  from your data.\n* Payment Card Industry (PCI) Data Security Standards prohibit logging certain\n  things or storing them unencrypted. You can use the redaction processor to\n  scrub them from your traces.\n\nThe above is written by an engineer, not a lawyer. The redaction processor is\nintended as one line of defence rather than the only compliance measure in\nplace.\n\n## Processor Configuration\n\nPlease refer to [config.go](./config.go) for the config spec.\n\nExamples:\n\n```yaml\nprocessors:\n  redaction:\n    # allow_all_keys is a flag which when set to true, which can disables the\n    # allowed_keys list. The list of blocked_values is applied regardless. If\n    # you just want to block values, set this to true.\n    allow_all_keys: false\n    # allowed_keys is a list of span attribute keys that are kept on the span and\n    # processed. The list is designed to fail closed. If allowed_keys is empty,\n    # no span attributes are allowed and all span attributes are removed. To\n    # allow all keys, set allow_all_keys to true.\n    allowed_keys:\n      - description\n      - group\n      - id\n      - name\n    # Ignore the following attributes, allow them to pass without redaction.\n    # Any keys in this list are allowed so they don't need to be in both lists.\n    ignored_keys:\n      - safe_attribute\n    # blocked_values is a list of regular expressions for blocking values of\n    # allowed span attributes. Values that match are masked\n    blocked_values:\n      - \"4[0-9]{12}(?:[0-9]{3})?\" ## Visa credit card number\n      - \"(5[1-5][0-9]{14})\"       ## MasterCard number\n    # summary controls the verbosity level of the diagnostic attributes that\n    # the processor adds to the spans when it redacts or masks other\n    # attributes. In some contexts a list of redacted attributes leaks\n    # information, while it is valuable when integrating and testing a new\n    # configuration. Possible values:\n    # - `debug` includes both redacted key counts and names in the summary\n    # - `info` includes just the redacted key counts in the summary\n    # - `silent` omits the summary attributes\n    summary: debug\n```\n\nRefer to [config.yaml](./testdata/config.yaml) for how to fit the configuration\ninto an OpenTelemetry Collector pipeline definition.\n\nIgnored attributes are processed first so they're always allowed and never\nblocked. This field should only be used where you know the data is always\nsafe to send to the telemetry system.\n\nOnly span attributes included on the list of allowed keys list are retained.\nIf `allowed_keys` is empty, then no span attributes are allowed. All span\nattributes are removed in that case. To keep all span attributes, you should\nexplicitly set `allow_all_keys` to true.\n\n`blocked_values` applies to the values of the allowed keys. If the value of an\nallowed key matches the regular expression for a blocked value, the matching\npart of the value is then masked with a fixed length of asterisks.\n\nFor example, if `notes` is on the list of allowed keys, then the `notes` span\nattribute is retained. However, if there is a value such as a credit card\nnumber in the `notes` field that matched a regular expression on the list of\nblocked values, then that value is masked.","properties":{"allow_all_keys":{"description":"AllowAllKeys is a flag to allow all span attribute keys. Setting this\nto true disables the AllowedKeys list. The list of BlockedValues is\napplied regardless. If you just want to block values, set this to true.","title":"allow_all_keys","type":"boolean"},"allowed_keys":{"description":"AllowedKeys is a list of allowed span attribute keys. Span attributes\nnot on the list are removed. The list fails closed if it's empty. To\nallow all keys, you should explicitly set AllowAllKeys","items":{"type":"string"},"title":"allowed_keys","type":"array"},"blocked_values":{"description":"BlockedValues is a list of regular expressions for blocking values of\nallowed span attributes. Values that match are masked","items":{"type":"string"},"title":"blocked_values","type":"array"},"ignored_keys":{"description":"IgnoredKeys is a list of span attribute keys that are not redacted.\nSpan attributes in this list are allowed to pass through the filter\nwithout being changed or removed.","items":{"type":"string"},"title":"ignored_keys","type":"array"},"summary":{"description":"Summary controls the verbosity level of the diagnostic attributes that\nthe processor adds to the spans when it redacts or masks other\nattributes. In some contexts a list of redacted attributes leaks\ninformation, while it is valuable when integrating and testing a new\nconfiguration. Possible values are `debug`, `info`, and `silent`.","title":"summary","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.Config":{"additionalProperties":false,"description":"Config defines configuration for Resource processor.","markdownDescription":"# Resource Detection Processor\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: traces, metrics, logs   |\n| Distributions | [contrib], [aws], [observiq], [redhat], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[redhat]: https://github.com/os-observability/redhat-opentelemetry-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe resource detection processor can be used to detect resource information from the host,\nin a format that conforms to the [OpenTelemetry resource semantic conventions](https://github.com/open-telemetry/opentelemetry-specification/tree/main/specification/resource/semantic_conventions/), and append or\noverride the resource value in telemetry data with this information.\n\n## Supported detectors\n\n### Environment Variable\n\nReads resource information from the `OTEL_RESOURCE_ATTRIBUTES` environment\nvariable. This is expected to be in the format `\u003ckey1\u003e=\u003cvalue1\u003e,\u003ckey2\u003e=\u003cvalue2\u003e,...`, the\ndetails of which are currently pending confirmation in the OpenTelemetry specification.\n\nExample:\n\n```yaml\nprocessors:\n  resourcedetection/env:\n    detectors: [env]\n    timeout: 2s\n    override: false\n```\n\n### System metadata\n\nNote: use the Docker detector (see below) if running the Collector as a Docker container.\n\nQueries the host machine to retrieve the following resource attributes:\n\n    * host.name\n    * host.id\n    * os.type\n\nBy default `host.name` is being set to FQDN if possible, and a hostname provided by OS used as fallback.\nThis logic can be changed with `hostname_sources` configuration which is set to `[\"dns\", \"os\"]` by default.\n\nUse the following config to avoid getting FQDN and apply hostname provided by OS only:\n\n```yaml\nprocessors:\n  resourcedetection/system:\n    detectors: [\"system\"]\n    system:\n      hostname_sources: [\"os\"]\n```\n\n* all valid options for `hostname_sources`:\n    * \"dns\"\n    * \"os\"\n    * \"cname\"\n    * \"lookup\"\n\n#### Hostname Sources\n\n##### dns\n\nThe \"dns\" hostname source uses multiple sources to get the fully qualified domain name. First, it looks up the\nhost name in the local machine's `hosts` file. If that fails, it looks up the CNAME. Lastly, if that fails,\nit does a reverse DNS query. Note: this hostname source may produce unreliable results on Windows. To produce\na FQDN, Windows hosts might have better results using the \"lookup\" hostname source, which is mentioned below.\n\n##### os\n\nThe \"os\" hostname source provides the hostname provided by the local machine's kernel.\n\n##### cname\n\nThe \"cname\" hostname source provides the canonical name, as provided by net.LookupCNAME in the Go standard library.\nNote: this hostname source may produce unreliable results on Windows.\n\n##### lookup\n\nThe \"lookup\" hostname source does a reverse DNS lookup of the current host's IP address.\n\n### Docker metadata\n\nQueries the Docker daemon to retrieve the following resource attributes from the host machine:\n\n    * host.name\n    * os.type\n\nYou need to mount the Docker socket (`/var/run/docker.sock` on Linux) to contact the Docker daemon.\nDocker detection does not work on macOS.\n\nExample:\n\n```yaml\nprocessors:\n  resourcedetection/docker:\n    detectors: [env, docker]\n    timeout: 2s\n    override: false\n```\n\n### Heroku metadata\n\nWhen [Heroku dyno metadata is active](https://devcenter.heroku.com/articles/dyno-metadata), Heroku applications publish information through environment variables.\n\nWe map these environment variables to resource attributes as follows:\n\n| Dyno metadata environment variable | Resource attribute                  |\n|------------------------------------|-------------------------------------|\n| `HEROKU_APP_ID`                    | `heroku.app.id`                     |\n| `HEROKU_APP_NAME`                  | `service.name`                      |\n| `HEROKU_DYNO_ID`                   | `service.instance.id`               |\n| `HEROKU_RELEASE_CREATED_AT`        | `heroku.release.creation_timestamp` |\n| `HEROKU_RELEASE_VERSION`           | `service.version`                   |\n| `HEROKU_SLUG_COMMIT`               | `heroku.release.commit`             |\n\nFor more information, see the [Heroku cloud provider documentation](https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/resource/semantic_conventions/cloud_provider/heroku.md) under the [OpenTelemetry specification semantic conventions](https://github.com/open-telemetry/opentelemetry-specification).\n\n```yaml\nprocessors:\n  resourcedetection/heroku:\n    detectors: [env, heroku]\n    timeout: 2s\n    override: false\n```\n\n### GCP Metadata\n\nUses the [Google Cloud Client Libraries for Go](https://github.com/googleapis/google-cloud-go)\nto read resource information from the [metadata server](https://cloud.google.com/compute/docs/storing-retrieving-metadata) and environment variables to detect which GCP platform the\napplication is running on, and detect the appropriate attributes for that platform. Regardless\nof the GCP platform the application is running on, use the gcp detector:\n\nExample:\n\n```yaml\nprocessors:\n  resourcedetection/gcp:\n    detectors: [env, gcp]\n    timeout: 2s\n    override: false\n```\n\n#### GCE Metadata\n\n    * cloud.provider (\"gcp\")\n    * cloud.platform (\"gcp_compute_engine\")\n    * cloud.account.id (project id)\n    * cloud.region  (e.g. us-central1)\n    * cloud.availability_zone (e.g. us-central1-c)\n    * host.id (instance id)\n    * host.name (instance name)\n    * host.type (machine type)\n\n#### GKE Metadata\n\n    * cloud.provider (\"gcp\")\n    * cloud.platform (\"gcp_kubernetes_engine\")\n    * cloud.account.id (project id)\n    * cloud.region (only for regional GKE clusters; e.g. \"us-central1\")\n    * cloud.availability_zone (only for zonal GKE clusters; e.g. \"us-central1-c\")\n    * k8s.cluster.name\n    * host.id (instance id)\n    * host.name (instance name; only when workload identity is disabled)\n\nOne known issue is when GKE workload identity is enabled, the GCE metadata endpoints won't be available, thus the GKE resource detector won't be\nable to determine `host.name`. In that case, users are encouraged to set `host.name` from either:\n- `node.name` through the downward API with the `env` detector\n- obtaining the Kubernetes node name from the Kubernetes API (with `k8s.io/client-go`)\n\n#### Google Cloud Run Metadata\n\n    * cloud.provider (\"gcp\")\n    * cloud.platform (\"gcp_cloud_run\")\n    * cloud.account.id (project id)\n    * cloud.region (e.g. \"us-central1\")\n    * faas.id (instance id)\n    * faas.name (service name)\n    * faas.version (service revision)\n\n#### Google Cloud Functions Metadata\n\n    * cloud.provider (\"gcp\")\n    * cloud.platform (\"gcp_cloud_functions\")\n    * cloud.account.id (project id)\n    * cloud.region (e.g. \"us-central1\")\n    * faas.id (instance id)\n    * faas.name (function name)\n    * faas.version (function version)\n\n#### Google App Engine Metadata\n\n    * cloud.provider (\"gcp\")\n    * cloud.platform (\"gcp_app_engine\")\n    * cloud.account.id (project id)\n    * cloud.region (e.g. \"us-central1\")\n    * cloud.availability_zone (e.g. \"us-central1-c\")\n    * faas.id (instance id)\n    * faas.name (service name)\n    * faas.version (service version)\n\n### AWS EC2\n\nUses [AWS SDK for Go](https://docs.aws.amazon.com/sdk-for-go/api/aws/ec2metadata/) to read resource information from the [EC2 instance metadata API](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html) to retrieve the following resource attributes:\n\n    * cloud.provider (\"aws\")\n    * cloud.platform (\"aws_ec2\")\n    * cloud.account.id\n    * cloud.region\n    * cloud.availability_zone\n    * host.id\n    * host.image.id\n    * host.name\n    * host.type\n\nIt also can optionally gather tags for the EC2 instance that the collector is running on.\nNote that in order to fetch EC2 tags, the IAM role assigned to the EC2 instance must have a policy that includes the `ec2:DescribeTags` permission.\n\nEC2 custom configuration example:\n```yaml\nprocessors:\n  resourcedetection/ec2:\n    detectors: [\"ec2\"]\n    ec2:\n      # A list of regex's to match tag keys to add as resource attributes can be specified\n      tags:\n        - ^tag1$\n        - ^tag2$\n        - ^label.*$\n```\n\nIf you are using a proxy server on your EC2 instance, it's important that you exempt requests for instance metadata as [described in the AWS cli user guide](https://github.com/awsdocs/aws-cli-user-guide/blob/a2393582590b64bd2a1d9978af15b350e1f9eb8e/doc_source/cli-configure-proxy.md#using-a-proxy-on-amazon-ec2-instances). Failing to do so can result in proxied or missing instance data.\n\nIf the instance is part of AWS ParallelCluster and the detector is failing to connect to the metadata server, check the iptable and make sure the chain `PARALLELCLUSTER_IMDS` contains a rule that allows OTEL user to access `169.254.169.254/32`\n\n### Amazon ECS\n\nQueries the [Task Metadata Endpoint](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-metadata-endpoint.html) (TMDE) to record information about the current ECS Task. Only TMDE V4 and V3 are supported.\n\n    * cloud.provider (\"aws\")\n    * cloud.platform (\"aws_ecs\")\n    * cloud.account.id\n    * cloud.region\n    * cloud.availability_zone\n    * aws.ecs.cluster.arn\n    * aws.ecs.task.arn\n    * aws.ecs.task.family\n    * aws.ecs.task.revision\n    * aws.ecs.launchtype (V4 only)\n    * aws.log.group.names (V4 only)\n    * aws.log.group.arns (V4 only)\n    * aws.log.stream.names (V4 only)\n    * aws.log.stream.arns (V4 only)\n\nExample:\n\n```yaml\nprocessors:\n  resourcedetection/ecs:\n    detectors: [env, ecs]\n    timeout: 2s\n    override: false\n```\n\n### Amazon Elastic Beanstalk\n\nReads the AWS X-Ray configuration file available on all Beanstalk instances with [X-Ray Enabled](https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/environment-configuration-debugging.html).\n\n    * cloud.provider (\"aws\")\n    * cloud.platform (\"aws_elastic_beanstalk\")\n    * deployment.environment\n    * service.instance.id\n    * service.version\n\nExample:\n\n```yaml\nprocessors:\n  resourcedetection/elastic_beanstalk:\n    detectors: [env, elastic_beanstalk]\n    timeout: 2s\n    override: false\n```\n\n### Amazon EKS\n\n    * cloud.provider (\"aws\")\n    * cloud.platform (\"aws_eks\")\n\nExample:\n\n```yaml\nprocessors:\n  resourcedetection/eks:\n    detectors: [env, eks]\n    timeout: 2s\n    override: false\n```\n\n### AWS Lambda\n\nUses the AWS Lambda [runtime environment variables](https://docs.aws.amazon.com/lambda/latest/dg/configuration-envvars.html#configuration-envvars-runtime)\nto retrieve the following resource attributes:\n\n[Cloud semantic conventions](https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/resource/semantic_conventions/cloud.md)\n\n* `cloud.provider` (`\"aws\"`)\n* `cloud.platform` (`\"aws_lambda\"`)\n* `cloud.region` (`$AWS_REGION`)\n\n[Function as a Service semantic conventions](https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/resource/semantic_conventions/faas.md)\nand [AWS Lambda semantic conventions](https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/trace/semantic_conventions/instrumentation/aws-lambda.md#resource-detector)\n\n* `faas.name` (`$AWS_LAMBDA_FUNCTION_NAME`)\n* `faas.version` (`$AWS_LAMBDA_FUNCTION_VERSION`)\n* `faas.instance` (`$AWS_LAMBDA_LOG_STREAM_NAME`)\n* `faas.max_memory` (`$AWS_LAMBDA_FUNCTION_MEMORY_SIZE`)\n\n[AWS Logs semantic conventions](https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/resource/semantic_conventions/cloud_provider/aws/logs.md)\n\n* `aws.log.group.names` (`$AWS_LAMBDA_LOG_GROUP_NAME`)\n* `aws.log.stream.names` (`$AWS_LAMBDA_LOG_STREAM_NAME`)\n\nExample:\n\n```yaml\nprocessors:\n  resourcedetection/lambda:\n    detectors: [env, lambda]\n    timeout: 0.2s\n    override: false\n```\n\n### Azure\n\nQueries the [Azure Instance Metadata Service](https://aka.ms/azureimds) to retrieve the following resource attributes:\n\n    * cloud.provider (\"azure\")\n    * cloud.platform (\"azure_vm\")\n    * cloud.region\n    * cloud.account.id (subscription ID)\n    * host.id (virtual machine ID)\n    * host.name\n    * azure.vm.name (same as host.name)\n    * azure.vm.size (virtual machine size)\n    * azure.vm.scaleset.name (name of the scale set if any)\n    * azure.resourcegroup.name (resource group name)\n\nExample:\n\n```yaml\nprocessors:\n  resourcedetection/azure:\n    detectors: [env, azure]\n    timeout: 2s\n    override: false\n```\n\n### Azure AKS\n\n  * cloud.provider (\"azure\")\n  * cloud.platform (\"azure_aks\")\n\n```yaml\nprocessors:\n  resourcedetection/aks:\n    detectors: [env, aks]\n    timeout: 2s\n    override: false\n```\n\n### Consul\n\nQueries a [consul agent](https://www.consul.io/docs/agent) and reads its' [configuration endpoint](https://www.consul.io/api-docs/agent#read-configuration) to retrieve the following resource attributes:\n\n  * cloud.region (consul datacenter)\n  * host.id (consul node id)\n  * host.name (consul node name)\n  * *exploded consul metadata* - reads all key:value pairs in [consul metadata](https://www.consul.io/docs/agent/options#_node_meta) into label:labelvalue pairs.\n\n```yaml\nprocessors:\n  resourcedetection/consul:\n    detectors: [env, consul]\n    timeout: 2s\n    override: false\n```\n\n### Heroku\n\n** You must first enable the [Heroku metadata feature](https://devcenter.heroku.com/articles/dyno-metadata) on the application **\n\nQueries [Heroku metadata](https://devcenter.heroku.com/articles/dyno-metadata) to retrieve the following resource attributes:\n\n* heroku.release.version (identifier for the current release)\n* heroku.release.creation_timestamp (time and date the release was created)\n* heroku.release.commit (commit hash for the current release)\n* heroku.app.name (application name)\n* heroku.app.id (unique identifier for the application)\n* heroku.dyno.id (dyno identifier. Used as host name)\n\n```yaml\nprocessors:\n  resourcedetection/heroku:\n    detectors: [env, heroku]\n    timeout: 2s\n    override: false\n```\n\n### Openshift\n\nQueries the OpenShift and Kubernetes API to retrieve the following resource attributes:\n\n    * cloud.provider\n    * cloud.platform\n    * cloud.region\n    * k8s.cluster.name\n\nBy default, the API address is determined from the environment variables `KUBERNETES_SERVICE_HOST`, `KUBERNETES_SERVICE_PORT` and the service token is read from `/var/run/secrets/kubernetes.io/serviceaccount/token`.\nIf TLS is not explicit disabled and no `ca_file` is configured `/var/run/secrets/kubernetes.io/serviceaccount/ca.crt` is used.\nThe determination of the API address, ca_file and the service token is skipped if they are set in the configuration.\n\nExample:\n\n```yaml\nprocessors:\n  resourcedetection/openshift:\n    detectors: [openshift]\n    timeout: 2s\n    override: false\n    openshift: # optional\n      address: \"https://api.example.com\"\n      token: \"token\"\n      tls:\n        insecure: false\n        ca_file: \"/var/run/secrets/kubernetes.io/serviceaccount/ca.crt\"\n```\n\nSee: [TLS Configuration Settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/configtls/README.md) for the full set of available options.\n\n## Configuration\n\n```yaml\n# a list of resource detectors to run, valid options are: \"env\", \"system\", \"gce\", \"gke\", \"ec2\", \"ecs\", \"elastic_beanstalk\", \"eks\", \"lambda\", \"azure\", \"heroku\", \"openshift\"\ndetectors: [ \u003cstring\u003e ]\n# determines if existing resource attributes should be overridden or preserved, defaults to true\noverride: \u003cbool\u003e\n# [DEPRECATED] When included, only attributes in the list will be appended.  Applies to all detectors.\nattributes: [ \u003cstring\u003e ]\n```\n\nMoreover, you have the ability to specify which detector should collect each attribute with `resource_attributes` option. An example of such a configuration is:\n\n```yaml\nresourcedetection:\n  detectors: [system, ec2]\n  system:\n    resource_attributes:\n      host.name:\n        enabled: true\n      host.id:\n        enabled: false\n  ec2:\n    resource_attributes:\n      host.name:\n        enabled: false\n      host.id:\n        enabled: true\n```\n\n### Migration from attributes to resource_attributes\n\nThe `attributes` option is deprecated and will be removed soon, from now on you should enable/disable attributes through `resource_attributes`.\nFor example, this config:\n\n```yaml\nresourcedetection:\n  detectors: [system]\n  attributes: ['host.name', 'host.id']\n```\n\ncan be replaced with:\n\n```yaml\nresourcedetection:\n  detectors: [system]\n  system:\n    resource_attributes:\n      host.name:\n        enabled: true\n      host.id:\n        enabled: true\n      os.type:\n        enabled: false\n```\n\nNOTE: Currently all attributes are enabled by default for backwards compatibility purposes, but it will change in the future.\n\n## Ordering\n\nNote that if multiple detectors are inserting the same attribute name, the first detector to insert wins. For example if you had `detectors: [eks, ec2]` then `cloud.platform` will be `aws_eks` instead of `ec2`. The below ordering is recommended.\n\n### GCP\n\n* gke\n* gce\n\n### AWS\n\n* lambda\n* elastic_beanstalk\n* eks\n* ecs\n* ec2\n\nThe full list of settings exposed for this extension are documented [here](./config.go)\nwith detailed sample configurations [here](./testdata/config.yaml).","properties":{"CustomRoundTripper":{"description":"Custom Round Tripper to allow for individual components to intercept HTTP requests","title":"CustomRoundTripper"},"aks":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.azure.aks.Config","description":"Aks contains user-specified configurations for the aks detector","title":"aks"},"attributes":{"description":"Attributes is an allowlist of attributes to add.\nIf a supplied attribute is not a valid atrtibute of a supplied detector it will be ignored.","items":{"type":"string"},"title":"attributes","type":"array"},"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth configuration for outgoing HTTP calls.","title":"auth"},"azure":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.azure.Config","description":"Azure contains user-specified configurations for the azure detector","title":"azure"},"compression":{"description":"The compression key for supported compression types within collector.","title":"compression","type":"string"},"consul":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.consul.Config","description":"ConsulConfig contains user-specified configurations for the Consul detector","title":"consul"},"detectors":{"description":"Detectors is an ordered list of named detectors that should be\nrun to attempt to detect resource information.","items":{"type":"string"},"title":"detectors","type":"array"},"docker":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.docker.Config","description":"DockerConfig contains user-specified configurations for the docker detector","title":"docker"},"ec2":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ec2.Config","description":"EC2Config contains user-specified configurations for the EC2 detector","title":"ec2"},"ecs":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ecs.Config","description":"ECSConfig contains user-specified configurations for the ECS detector","title":"ecs"},"eks":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.eks.Config","description":"EKSConfig contains user-specified configurations for the EKS detector","title":"eks"},"elasticbeanstalk":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.elasticbeanstalk.Config","description":"Elasticbeanstalk contains user-specified configurations for the elasticbeanstalk detector","title":"elasticbeanstalk"},"endpoint":{"description":"The target URL to send data to (e.g.: http://some.url:9411/v1/traces).","title":"endpoint","type":"string"},"gcp":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.gcp.Config","description":"GcpConfig contains user-specified configurations for the gcp detector","title":"gcp"},"headers":{"description":"Additional headers attached to each HTTP request sent by the client.\nExisting header values are overwritten if collision happens.\nHeader values are opaque since they may be sensitive.","patternProperties":{".*":{"type":"string"}},"title":"headers","type":"object"},"heroku":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.heroku.Config","description":"HerokuConfig contains user-specified configurations for the heroku detector","title":"heroku"},"idle_conn_timeout":{"description":"IdleConnTimeout is the maximum amount of time a connection will remain open before closing itself.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"idle_conn_timeout","type":"string"},"lambda":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.lambda.Config","description":"Lambda contains user-specified configurations for the lambda detector","title":"lambda"},"max_conns_per_host":{"description":"MaxConnsPerHost limits the total number of connections per host, including connections in the dialing,\nactive, and idle states.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_conns_per_host","type":"integer"},"max_idle_conns":{"description":"MaxIdleConns is used to set a limit to the maximum idle HTTP connections the client can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns","type":"integer"},"max_idle_conns_per_host":{"description":"MaxIdleConnsPerHost is used to set a limit to the maximum idle HTTP connections the host can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns_per_host","type":"integer"},"openshift":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.openshift.Config","description":"OpenShift contains user-specified configurations for the Openshift detector","title":"openshift"},"override":{"description":"Override indicates whether any existing resource attributes\nshould be overridden or preserved. Defaults to true.","title":"override","type":"boolean"},"read_buffer_size":{"description":"ReadBufferSize for HTTP client. See http.Transport.ReadBufferSize.","title":"read_buffer_size","type":"integer"},"system":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.system.Config","description":"SystemConfig contains user-specified configurations for the System detector","title":"system"},"timeout":{"description":"Timeout parameter configures `http.Client.Timeout`.","title":"timeout","type":"string"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","description":"TLSSetting struct exposes TLS client configuration.","title":"tls"},"write_buffer_size":{"description":"WriteBufferSize for HTTP client. See http.Transport.WriteBufferSize.","title":"write_buffer_size","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ec2.Config":{"additionalProperties":false,"description":"Config defines user-specified configurations unique to the EC2 detector","properties":{"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ec2.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"},"tags":{"description":"Tags is a list of regex's to match ec2 instance tag keys that users want\nto add as resource attributes to processed data","items":{"type":"string"},"title":"tags","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ec2.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ec2.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for resourcedetectionprocessor/ec2 resource attributes.","properties":{"cloud.account.id":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ec2.internal.metadata.ResourceAttributeConfig","title":"cloud.account.id"},"cloud.availability_zone":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ec2.internal.metadata.ResourceAttributeConfig","title":"cloud.availability_zone"},"cloud.platform":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ec2.internal.metadata.ResourceAttributeConfig","title":"cloud.platform"},"cloud.provider":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ec2.internal.metadata.ResourceAttributeConfig","title":"cloud.provider"},"cloud.region":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ec2.internal.metadata.ResourceAttributeConfig","title":"cloud.region"},"host.id":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ec2.internal.metadata.ResourceAttributeConfig","title":"host.id"},"host.image.id":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ec2.internal.metadata.ResourceAttributeConfig","title":"host.image.id"},"host.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ec2.internal.metadata.ResourceAttributeConfig","title":"host.name"},"host.type":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ec2.internal.metadata.ResourceAttributeConfig","title":"host.type"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ecs.Config":{"additionalProperties":false,"properties":{"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ecs.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ecs.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ecs.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for resourcedetectionprocessor/ecs resource attributes.","properties":{"aws.ecs.cluster.arn":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ecs.internal.metadata.ResourceAttributeConfig","title":"aws.ecs.cluster.arn"},"aws.ecs.launchtype":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ecs.internal.metadata.ResourceAttributeConfig","title":"aws.ecs.launchtype"},"aws.ecs.task.arn":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ecs.internal.metadata.ResourceAttributeConfig","title":"aws.ecs.task.arn"},"aws.ecs.task.family":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ecs.internal.metadata.ResourceAttributeConfig","title":"aws.ecs.task.family"},"aws.ecs.task.revision":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ecs.internal.metadata.ResourceAttributeConfig","title":"aws.ecs.task.revision"},"aws.log.group.arns":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ecs.internal.metadata.ResourceAttributeConfig","title":"aws.log.group.arns"},"aws.log.group.names":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ecs.internal.metadata.ResourceAttributeConfig","title":"aws.log.group.names"},"aws.log.stream.arns":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ecs.internal.metadata.ResourceAttributeConfig","title":"aws.log.stream.arns"},"aws.log.stream.names":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ecs.internal.metadata.ResourceAttributeConfig","title":"aws.log.stream.names"},"cloud.account.id":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ecs.internal.metadata.ResourceAttributeConfig","title":"cloud.account.id"},"cloud.availability_zone":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ecs.internal.metadata.ResourceAttributeConfig","title":"cloud.availability_zone"},"cloud.platform":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ecs.internal.metadata.ResourceAttributeConfig","title":"cloud.platform"},"cloud.provider":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ecs.internal.metadata.ResourceAttributeConfig","title":"cloud.provider"},"cloud.region":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.ecs.internal.metadata.ResourceAttributeConfig","title":"cloud.region"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.eks.Config":{"additionalProperties":false,"properties":{"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.eks.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.eks.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.eks.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for resourcedetectionprocessor/eks resource attributes.","properties":{"cloud.platform":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.eks.internal.metadata.ResourceAttributeConfig","title":"cloud.platform"},"cloud.provider":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.eks.internal.metadata.ResourceAttributeConfig","title":"cloud.provider"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.elasticbeanstalk.Config":{"additionalProperties":false,"properties":{"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.elasticbeanstalk.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.elasticbeanstalk.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.elasticbeanstalk.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for resourcedetectionprocessor/elastic_beanstalk resource attributes.","properties":{"cloud.platform":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.elasticbeanstalk.internal.metadata.ResourceAttributeConfig","title":"cloud.platform"},"cloud.provider":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.elasticbeanstalk.internal.metadata.ResourceAttributeConfig","title":"cloud.provider"},"deployment.environment":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.elasticbeanstalk.internal.metadata.ResourceAttributeConfig","title":"deployment.environment"},"service.instance.id":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.elasticbeanstalk.internal.metadata.ResourceAttributeConfig","title":"service.instance.id"},"service.version":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.elasticbeanstalk.internal.metadata.ResourceAttributeConfig","title":"service.version"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.lambda.Config":{"additionalProperties":false,"properties":{"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.lambda.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.lambda.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.lambda.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for resourcedetectionprocessor/lambda resource attributes.","properties":{"aws.log.group.names":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.lambda.internal.metadata.ResourceAttributeConfig","title":"aws.log.group.names"},"aws.log.stream.names":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.lambda.internal.metadata.ResourceAttributeConfig","title":"aws.log.stream.names"},"cloud.platform":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.lambda.internal.metadata.ResourceAttributeConfig","title":"cloud.platform"},"cloud.provider":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.lambda.internal.metadata.ResourceAttributeConfig","title":"cloud.provider"},"cloud.region":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.lambda.internal.metadata.ResourceAttributeConfig","title":"cloud.region"},"faas.instance":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.lambda.internal.metadata.ResourceAttributeConfig","title":"faas.instance"},"faas.max_memory":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.lambda.internal.metadata.ResourceAttributeConfig","title":"faas.max_memory"},"faas.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.lambda.internal.metadata.ResourceAttributeConfig","title":"faas.name"},"faas.version":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.aws.lambda.internal.metadata.ResourceAttributeConfig","title":"faas.version"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.azure.Config":{"additionalProperties":false,"properties":{"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.azure.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.azure.aks.Config":{"additionalProperties":false,"properties":{"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.azure.aks.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.azure.aks.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.azure.aks.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for resourcedetectionprocessor/aks resource attributes.","properties":{"cloud.platform":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.azure.aks.internal.metadata.ResourceAttributeConfig","title":"cloud.platform"},"cloud.provider":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.azure.aks.internal.metadata.ResourceAttributeConfig","title":"cloud.provider"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.azure.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.azure.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for resourcedetectionprocessor/azure resource attributes.","properties":{"azure.resourcegroup.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.azure.internal.metadata.ResourceAttributeConfig","title":"azure.resourcegroup.name"},"azure.vm.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.azure.internal.metadata.ResourceAttributeConfig","title":"azure.vm.name"},"azure.vm.scaleset.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.azure.internal.metadata.ResourceAttributeConfig","title":"azure.vm.scaleset.name"},"azure.vm.size":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.azure.internal.metadata.ResourceAttributeConfig","title":"azure.vm.size"},"cloud.account.id":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.azure.internal.metadata.ResourceAttributeConfig","title":"cloud.account.id"},"cloud.platform":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.azure.internal.metadata.ResourceAttributeConfig","title":"cloud.platform"},"cloud.provider":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.azure.internal.metadata.ResourceAttributeConfig","title":"cloud.provider"},"cloud.region":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.azure.internal.metadata.ResourceAttributeConfig","title":"cloud.region"},"host.id":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.azure.internal.metadata.ResourceAttributeConfig","title":"host.id"},"host.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.azure.internal.metadata.ResourceAttributeConfig","title":"host.name"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.consul.Config":{"additionalProperties":false,"description":"The struct requires no user-specified fields by default as consul agent's default configuration will be provided to the API client.","properties":{"address":{"description":"Address is the address of the Consul server","title":"address","type":"string"},"datacenter":{"description":"Datacenter to use. If not provided, the default agent datacenter is used.","title":"datacenter","type":"string"},"meta":{"description":"Allowlist of [Consul\nMetadata](https://www.consul.io/docs/agent/options#node_meta) keys to use as\nresource attributes.","patternProperties":{".*":true},"title":"meta","type":"object"},"namespace":{"description":"Namespace is the name of the namespace to send along for the request\nwhen no other Namespace is present in the QueryOptions","title":"namespace","type":"string"},"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.consul.internal.metadata.ResourceAttributesConfig","description":"ResourceAttributes configuration for Consul detector","title":"resource_attributes"},"token":{"description":"Token is used to provide a per-request ACL token\nwhich overrides the agent's default (empty) token.\nToken or Tokenfile are only required if [Consul's ACL\nSystem](https://www.consul.io/docs/security/acl/acl-system) is enabled.","title":"token","type":"string"},"token_file":{"description":"TokenFile is a file containing the current token to use for this client.\nIf provided it is read once at startup and never again.\nToken or Tokenfile are only required if [Consul's ACL\nSystem](https://www.consul.io/docs/security/acl/acl-system) is enabled.","title":"token_file","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.consul.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.consul.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for resourcedetectionprocessor/consul resource attributes.","properties":{"azure.resourcegroup.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.consul.internal.metadata.ResourceAttributeConfig","title":"azure.resourcegroup.name"},"azure.vm.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.consul.internal.metadata.ResourceAttributeConfig","title":"azure.vm.name"},"azure.vm.scaleset.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.consul.internal.metadata.ResourceAttributeConfig","title":"azure.vm.scaleset.name"},"azure.vm.size":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.consul.internal.metadata.ResourceAttributeConfig","title":"azure.vm.size"},"cloud.account.id":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.consul.internal.metadata.ResourceAttributeConfig","title":"cloud.account.id"},"cloud.platform":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.consul.internal.metadata.ResourceAttributeConfig","title":"cloud.platform"},"cloud.provider":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.consul.internal.metadata.ResourceAttributeConfig","title":"cloud.provider"},"cloud.region":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.consul.internal.metadata.ResourceAttributeConfig","title":"cloud.region"},"host.id":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.consul.internal.metadata.ResourceAttributeConfig","title":"host.id"},"host.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.consul.internal.metadata.ResourceAttributeConfig","title":"host.name"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.docker.Config":{"additionalProperties":false,"properties":{"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.docker.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.docker.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.docker.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for resourcedetectionprocessor/docker resource attributes.","properties":{"host.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.docker.internal.metadata.ResourceAttributeConfig","title":"host.name"},"os.type":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.docker.internal.metadata.ResourceAttributeConfig","title":"os.type"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.gcp.Config":{"additionalProperties":false,"properties":{"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.gcp.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.gcp.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.gcp.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for resourcedetectionprocessor/gcp resource attributes.","properties":{"cloud.account.id":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.gcp.internal.metadata.ResourceAttributeConfig","title":"cloud.account.id"},"cloud.availability_zone":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.gcp.internal.metadata.ResourceAttributeConfig","title":"cloud.availability_zone"},"cloud.platform":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.gcp.internal.metadata.ResourceAttributeConfig","title":"cloud.platform"},"cloud.provider":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.gcp.internal.metadata.ResourceAttributeConfig","title":"cloud.provider"},"cloud.region":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.gcp.internal.metadata.ResourceAttributeConfig","title":"cloud.region"},"faas.id":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.gcp.internal.metadata.ResourceAttributeConfig","title":"faas.id"},"faas.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.gcp.internal.metadata.ResourceAttributeConfig","title":"faas.name"},"faas.version":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.gcp.internal.metadata.ResourceAttributeConfig","title":"faas.version"},"host.id":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.gcp.internal.metadata.ResourceAttributeConfig","title":"host.id"},"host.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.gcp.internal.metadata.ResourceAttributeConfig","title":"host.name"},"host.type":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.gcp.internal.metadata.ResourceAttributeConfig","title":"host.type"},"k8s.cluster.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.gcp.internal.metadata.ResourceAttributeConfig","title":"k8s.cluster.name"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.heroku.Config":{"additionalProperties":false,"properties":{"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.heroku.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.heroku.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.heroku.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for resourcedetectionprocessor/heroku resource attributes.","properties":{"cloud.provider":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.heroku.internal.metadata.ResourceAttributeConfig","title":"cloud.provider"},"heroku.app.id":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.heroku.internal.metadata.ResourceAttributeConfig","title":"heroku.app.id"},"heroku.app.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.heroku.internal.metadata.ResourceAttributeConfig","title":"heroku.app.name"},"heroku.dyno.id":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.heroku.internal.metadata.ResourceAttributeConfig","title":"heroku.dyno.id"},"heroku.release.commit":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.heroku.internal.metadata.ResourceAttributeConfig","title":"heroku.release.commit"},"heroku.release.creation_timestamp":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.heroku.internal.metadata.ResourceAttributeConfig","title":"heroku.release.creation_timestamp"},"heroku.release.version":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.heroku.internal.metadata.ResourceAttributeConfig","title":"heroku.release.version"},"service.instance.id":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.heroku.internal.metadata.ResourceAttributeConfig","title":"service.instance.id"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.openshift.Config":{"additionalProperties":false,"description":"Config can contain user-specified inputs to overwrite default values.","properties":{"address":{"description":"Address is the address of the openshift api server","title":"address","type":"string"},"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.openshift.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","description":"TLSSettings contains TLS configurations that are specific to client\nconnection used to communicate with the Openshift API.","title":"tls"},"token":{"description":"Token is used to identify against the openshift api server","title":"token","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.openshift.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.openshift.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for resourcedetectionprocessor/openshift resource attributes.","properties":{"cloud.platform":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.openshift.internal.metadata.ResourceAttributeConfig","title":"cloud.platform"},"cloud.provider":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.openshift.internal.metadata.ResourceAttributeConfig","title":"cloud.provider"},"cloud.region":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.openshift.internal.metadata.ResourceAttributeConfig","title":"cloud.region"},"k8s.cluster.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.openshift.internal.metadata.ResourceAttributeConfig","title":"k8s.cluster.name"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.system.Config":{"additionalProperties":false,"description":"Config defines user-specified configurations unique to the system detector","properties":{"hostname_sources":{"description":"The HostnameSources is a priority list of sources from which hostname will be fetched.\nIn case of the error in fetching hostname from source,\nthe next source from the list will be considered.(**default**: `[\"dns\", \"os\"]`)","items":{"type":"string"},"title":"hostname_sources","type":"array"},"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.system.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.system.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.system.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for resourcedetectionprocessor/system resource attributes.","properties":{"host.id":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.system.internal.metadata.ResourceAttributeConfig","title":"host.id"},"host.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.system.internal.metadata.ResourceAttributeConfig","title":"host.name"},"os.type":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.internal.system.internal.metadata.ResourceAttributeConfig","title":"os.type"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourceprocessor.Config":{"additionalProperties":false,"description":"Config defines configuration for Resource processor.","markdownDescription":"# Resource Processor\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: traces, metrics, logs   |\n| Distributions | [core], [contrib], [aws], [observiq], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[core]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe resource processor can be used to apply changes on resource attributes.\nPlease refer to [config.go](./config.go) for the config spec.\n\n`attributes` represents actions that can be applied on resource attributes.\nSee [Attributes Processor](../attributesprocessor/README.md) for more details on supported attributes actions.\n\nExamples:\n\n```yaml\nprocessors:\n  resource:\n    attributes:\n    - key: cloud.availability_zone\n      value: \"zone-1\"\n      action: upsert\n    - key: k8s.cluster.name\n      from_attribute: k8s-cluster\n      action: insert\n    - key: redundant-attribute\n      action: delete\n```\n\nRefer to [config.yaml](./testdata/config.yaml) for detailed\nexamples on using the processor.","properties":{"attributes":{"description":"AttributesActions specifies the list of actions to be applied on resource attributes.\nThe set of actions are {INSERT, UPDATE, UPSERT, DELETE, HASH, EXTRACT}.","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.coreinternal.attraction.ActionKeyValue"},"title":"attributes","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.routingprocessor.Config":{"additionalProperties":false,"description":"Config defines configuration for the Routing processor.","markdownDescription":"# Routing processor\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: traces, metrics, logs   |\n| Distributions | [contrib], [observiq], [redhat], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[redhat]: https://github.com/os-observability/redhat-opentelemetry-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nRoutes logs, metrics or traces to specific exporters.\n\nThis processor will either read a header from the incoming HTTP request (gRPC or plain HTTP), or it will read a resource attribute, and direct the trace information to specific exporters based on the value read.\n\nThis processor *does not* let traces/metrics/logs to continue through the pipeline and will emit a warning in case other processor(s) are defined after this one.\nSimilarly, exporters defined as part of the pipeline are not authoritative: if you add an exporter to the pipeline, make sure you add it to this processor *as well*, otherwise it won't be used at all.\nAll exporters defined as part of this processor *must also* be defined as part of the pipeline's exporters.\n\nGiven that this processor depends on information provided by the client via HTTP headers or resource attributes, caution must be taken when processors that aggregate data like `batch` or `groupbytrace` are used as part of the pipeline.\n\n## Configuration\n\nThe following settings are required:\n\n- `from_attribute`: contains the HTTP header name or the resource attribute name to look up the route's value. Only the OTLP exporter has been tested in connection with the OTLP gRPC Receiver, but any other gRPC receiver should work fine, as long as the client sends the specified HTTP header.\n- `table`: the routing table for this processor.\n- `table.value`: a possible value for the attribute specified under FromAttribute.\n- `table.exporters`: the list of exporters to use when the value from the FromAttribute field matches this table item.\n\nThe following settings can be optionally configured:\n\n- `attribute_source` defines where to look for the attribute in `from_attribute`. The allowed values are:\n  - `context` (the default) - to search the [context][context_docs], which includes HTTP headers\n  - `resource` - to search the resource attributes.\n- `drop_resource_routing_attribute` - controls whether to remove the resource attribute used for routing. This is only relevant if AttributeSource is set to resource.\n- `default_exporters` contains the list of exporters to use when a more specific record can't be found in the routing table.\n\nExample:\n\n```yaml\nprocessors:\n  routing:\n    from_attribute: X-Tenant\n    default_exporters:\n    - jaeger\n    table:\n    - value: acme\n      exporters: [jaeger/acme]\nexporters:\n  jaeger:\n    endpoint: localhost:14250\n  jaeger/acme:\n    endpoint: localhost:24250\n```\n\n### Tech Preview: OpenTelemetry Transformation Language statements as routing conditions\n\nAlternatively, it is possible to use subset of the [OpenTelemetry Transformation Language (OTTL)](../../pkg/ottl/README.md) statements as routing conditions.\n\nTo configure the routing processor with [OTTL] routing conditions use the following options:\n\n- `table (required)`: the routing table for this processor.\n- `table.statement (required)`: the routing condition provided as the [OTTL] statement.\n- `table.exporters (required)`: the list of exporters to use when the routing condition is met.\n- `default_exporters (optional)`: contains the list of exporters to use when a record does not meet any of specified conditions.\n- `error_mode (optional)`: determines how errors returned from OTTL statements are handled. Valid values are `ignore` and `propagate`. If `ignored` is used and a statement's condition has an error then the payload will be routed to the default exporter.  If not supplied, `propagate` is used.\n\n\n```yaml\n\nprocessors:\n  routing:\n    default_exporters:\n    - jaeger\n    error_mode: ignore\n    table:\n      - statement: route() where resource.attributes[\"X-Tenant\"] == \"acme\"\n        exporters: [jaeger/acme]\n      - statement: delete_key(resource.attributes, \"X-Tenant\") where IsMatch(resource.attributes[\"X-Tenant\"], \".*corp\")\n        exporters: [jaeger/ecorp]\n\nexporters:\n  jaeger:\n    endpoint: localhost:14250\n  jaeger/acme:\n    endpoint: localhost:24250\n  jaeger/ecorp:\n    endpoint: localhost:34250\n```\n\nA signal may get matched by routing conditions of more than one routing table entry. In this case, the signal will be routed to all exporters of matching routes.\nRespectively, if none of the routing conditions met, then a signal is routed to default exporters.\n\nIt is also possible to mix both the conventional routing configuration and the routing configuration with [OTTL] conditions.\n\n#### Limitations:\n\n- [OTTL] statements can be applied only to resource attributes.\n- Currently, it is not possible to specify the boolean statements without function invocation as the routing condition. It is required to provide the NOOP `route()` or any other supported function as part of the routing statement, see [#13545](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/13545) for more information.\n- Supported [OTTL] functions:\n  - [IsMatch](../../pkg/ottl/ottlfuncs/README.md#IsMatch)\n  - [delete_key](../../pkg/ottl/ottlfuncs/README.md#delete_key)\n  - [delete_matching_keys](../../pkg/ottl/ottlfuncs/README.md#delete_matching_keys)\n\nThe full list of settings exposed for this processor are documented [here](./config.go) with detailed sample configuration files:\n\n- [logs](./testdata/config_logs.yaml)\n- [metrics](./testdata/config_metrics.yaml)\n- [traces](./testdata/config_traces.yaml)\n\n[context_docs]: https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/context/README.md\n[OTTL]: https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/processing.md#telemetry-query-language","properties":{"attribute_source":{"description":"AttributeSource defines where the attribute defined in `from_attribute` is searched for.\nThe allowed values are:\n- \"context\" - the attribute must exist in the incoming context\n- \"resource\" - the attribute must exist in resource attributes\nThe default value is \"context\".\nOptional.","title":"attribute_source","type":"string"},"default_exporters":{"description":"DefaultExporters contains the list of exporters to use when a more specific record can't be found in the routing table.\nOptional.","items":{"type":"string"},"title":"default_exporters","type":"array"},"drop_resource_routing_attribute":{"description":"DropRoutingResourceAttribute controls whether to remove the resource attribute used for routing.\nThis is only relevant if AttributeSource is set to resource.\nOptional.","title":"drop_resource_routing_attribute","type":"boolean"},"error_mode":{"description":"ErrorMode determines how the processor reacts to errors that occur while processing an OTTL condition.\nValid values are `ignore` and `propagate`.\n`ignore` means the processor ignores errors returned by conditions and continues on to the next condition. This is the recommended mode.\nIf `ignored` is used and a statement's condition has an error then the payload will be routed to the default exporter.\n`propagate` means the processor returns the error up the pipeline.  This will result in the payload being dropped from the collector.\nThe default value is `propagate`.","title":"error_mode","type":"string"},"from_attribute":{"description":"FromAttribute contains the attribute name to look up the route value. This attribute should be part of the context propagated\ndown from the previous receivers and/or processors. If all the receivers and processors are propagating the entire context correctly,\nthis could be the HTTP/gRPC header from the original request/RPC. Typically, aggregation processors (batch, groupbytrace)\nwill create a new context, so, those should be avoided when using this processor.Although the HTTP spec allows headers to be repeated,\nthis processor will only use the first value.\nRequired.","title":"from_attribute","type":"string"},"table":{"description":"Table contains the routing table for this processor.\nRequired.","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.routingprocessor.RoutingTableItem"},"title":"table","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.routingprocessor.RoutingTableItem":{"additionalProperties":false,"description":"RoutingTableItem specifies how data should be routed to the different exporters","properties":{"exporters":{"description":"Exporters contains the list of exporters to use when the value from the FromAttribute field matches this table item.\nWhen no exporters are specified, the ones specified under DefaultExporters are used, if any.\nThe routing processor will fail upon the first failure from these exporters.\nOptional.","items":{"type":"string"},"title":"exporters","type":"array"},"statement":{"description":"Statement is a OTTL statement used for making a routing decision.\nRequired when 'Value' isn't provided.","title":"statement","type":"string"},"value":{"description":"Value represents a possible value for the field specified under FromAttribute.\nRequired when Statement isn't provided.","title":"value","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.schemaprocessor.Config":{"additionalProperties":false,"description":"Config defines the user provided values for the Schema Processor","markdownDescription":"# Schema Transformer Processor\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [development]: traces, metrics, logs   |\n| Distributions | [sumo] |\n\n[development]: https://github.com/open-telemetry/opentelemetry-collector#development\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe _Schema Processor_ is used to convert existing telemetry data or signals to a version of the semantic convention defined as part of the configuration.\nThe processor works by using a set of target schema URLs that are used to match incoming signals.\nOn a match, the processor will fetch the schema translation file (if not cached) set by the incoming signal and apply the transformations\nrequired to export as the target semantic convention version.\n\nFurthermore, it is also possible for organisations and vendors to publish their own semantic conventions and be used by this processor, \nbe sure to follow [schema overview](https://opentelemetry.io/docs/reference/specification/schemas/overview/) for all the details.\n\n## Caching Schema Translation Files\n\nIn order to improve efficiency of the processor, the `prefetch` option allows the processor to start downloading and preparing\nthe translations needed for signals that match the schema URL.\n\n## Schema Formats\n\nA schema URl is made up in two parts, _Schema Family_ and _Schema Version_, the schema URL is broken down like so:\n\n```text\n|                       Schema URL                           |\n| https://example.com/telemetry/schemas/ |  |      1.0.1     |\n|             Schema Family              |  | Schema Version |\n```\n\nThe final path in the schema URL _MUST_ be the schema version and the preceding portion of the URL is the _Schema Family_.\nTo read about schema formats, please read more [here](https://opentelemetry.io/docs/reference/specification/schemas/overview/#schema-url)\n\n## Targets Schemas\n\nTargets define a set of schema URLs with a schema identifier that will be used to translate any schema URL that matches the target URL to that version.\nIn the event that the processor matches a signal to a target, the processor will translate the signal from the published one to the defined identifier;\nfor example using the configuration below, a signal published with the `https://opentelemetry.io/schemas/1.8.0` schema will be translated \nby the collector to the `https//opentelemetry.io/schemas/1.6.1` schema.\nWithin the schema targets, no duplicate schema families are allowed and will report an error if detected.\n\n\n# Example\n\n```yaml\nprocessors:\n  schema:\n    prefetch:\n    - https://opentelemetry.io/schemas/1.9.0\n    targets:\n    - https://opentelemetry.io/schemas/1.6.1\n    - http://example.com/telemetry/schemas/1.0.1\n```\n\nFor more complete examples, please refer to [config.yml](./testdata/config.yml).","properties":{"CustomRoundTripper":{"description":"Custom Round Tripper to allow for individual components to intercept HTTP requests","title":"CustomRoundTripper"},"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth configuration for outgoing HTTP calls.","title":"auth"},"compression":{"description":"The compression key for supported compression types within collector.","title":"compression","type":"string"},"endpoint":{"description":"The target URL to send data to (e.g.: http://some.url:9411/v1/traces).","title":"endpoint","type":"string"},"headers":{"description":"Additional headers attached to each HTTP request sent by the client.\nExisting header values are overwritten if collision happens.\nHeader values are opaque since they may be sensitive.","patternProperties":{".*":{"type":"string"}},"title":"headers","type":"object"},"idle_conn_timeout":{"description":"IdleConnTimeout is the maximum amount of time a connection will remain open before closing itself.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"idle_conn_timeout","type":"string"},"max_conns_per_host":{"description":"MaxConnsPerHost limits the total number of connections per host, including connections in the dialing,\nactive, and idle states.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_conns_per_host","type":"integer"},"max_idle_conns":{"description":"MaxIdleConns is used to set a limit to the maximum idle HTTP connections the client can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns","type":"integer"},"max_idle_conns_per_host":{"description":"MaxIdleConnsPerHost is used to set a limit to the maximum idle HTTP connections the host can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns_per_host","type":"integer"},"prefetch":{"description":"PreCache is a list of schema URLs that are downloaded\nand cached at the start of the collector runtime\nin order to avoid fetching data that later on could\nblock processing of signals. (Optional field)","items":{"type":"string"},"title":"prefetch","type":"array"},"read_buffer_size":{"description":"ReadBufferSize for HTTP client. See http.Transport.ReadBufferSize.","title":"read_buffer_size","type":"integer"},"targets":{"description":"Targets define what schema families should be\ntranslated to, allowing older and newer formats\nto conform to the target schema identifier.","items":{"type":"string"},"title":"targets","type":"array"},"timeout":{"description":"Timeout parameter configures `http.Client.Timeout`.","title":"timeout","type":"string"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","description":"TLSSetting struct exposes TLS client configuration.","title":"tls"},"write_buffer_size":{"description":"WriteBufferSize for HTTP client. See http.Transport.WriteBufferSize.","title":"write_buffer_size","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.servicegraphprocessor.Config":{"additionalProperties":false,"description":"Config defines the configuration options for servicegraphprocessor.","markdownDescription":"# Service graph processor\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [alpha]: traces   |\n| Distributions | [contrib], [sumo] |\n\n[alpha]: https://github.com/open-telemetry/opentelemetry-collector#alpha\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe service graphs processor is a traces processor that builds a map representing the interrelationships between various services in a system.\nThe processor will analyse trace data and generate metrics describing the relationship between the services.\nThese metrics can be used by data visualization apps (e.g. Grafana) to draw a service graph.\n\nService graphs are useful for a number of use-cases:\n\n* Infer the topology of a distributed system. As distributed systems grow, they become more complex. Service graphs can help you understand the structure of the system.\n* Provide a high level overview of the health of your system.\nService graphs show error rates, latencies, among other relevant data.\n* Provide an historic view of a systemâ€™s topology.\nDistributed systems change very frequently,\nand service graphs offer a way of seeing how these systems have evolved over time.\n\nThis component is based on [Grafana Tempo's service graph processor](https://github.com/grafana/tempo/tree/main/modules/generator/processor/servicegraphs).\n\n## How it works\n\nService graphs work by inspecting traces and looking for spans with parent-children relationship that represent a request.\nThe processor uses the OpenTelemetry semantic conventions to detect a myriad of requests.\nIt currently supports the following requests:\n\n* A direct request between two services where the outgoing and the incoming span must have `span.kind` client and server respectively.\n* A request across a messaging system where the outgoing and the incoming span must have `span.kind` producer and consumer respectively.\n* A database request; in this case the processor looks for spans containing attributes `span.kind`=client as well as db.name.\n\nEvery span that can be paired up to form a request is kept in an in-memory store,\nuntil its corresponding pair span is received or the maximum waiting time has passed.\nWhen either of these conditions are reached, the request is recorded and removed from the local store.\n\nEach emitted metrics series have the client and server label corresponding with the service doing the request and the service receiving the request.\n\n```\ntraces_service_graph_request_total{client=\"app\", server=\"db\", connection_type=\"database\"} 20\n```\n\nTLDR: The processor will try to find spans belonging to requests as seen from the client and the server and will create a metric representing an edge in the graph.\n\n## Metrics\n\nThe following metrics are emitted by the processor:\n\n| Metric                                      | Type      | Labels                          | Description                                                  |\n|---------------------------------------------|-----------|---------------------------------|--------------------------------------------------------------|\n| traces_service_graph_request_total          | Counter   | client, server, connection_type | Total count of requests between two nodes                    |\n| traces_service_graph_request_failed_total   | Counter   | client, server, connection_type | Total count of failed requests between two nodes             |\n| traces_service_graph_request_server_seconds | Histogram | client, server, connection_type | Time for a request between two nodes as seen from the server |\n| traces_service_graph_request_client_seconds | Histogram | client, server, connection_type | Time for a request between two nodes as seen from the client |\n| traces_service_graph_unpaired_spans_total   | Counter   | client, server, connection_type | Total count of unpaired spans                                |\n| traces_service_graph_dropped_spans_total    | Counter   | client, server, connection_type | Total count of dropped spans                                 |\n\nDuration is measured both from the client and the server sides.\n\nPossible values for `connection_type`: unset, `messaging_system`, or `database`.\n\nAdditional labels can be included using the `dimensions` configuration option. Those labels will have a prefix to mark where they originate (client or server span kinds).\nThe `client_` prefix relates to the dimensions coming from spans with `SPAN_KIND_CLIENT`, and the `server_` prefix relates to the\ndimensions coming from spans with `SPAN_KIND_SERVER`.\n\nSince the service graph processor has to process both sides of an edge,\nit needs to process all spans of a trace to function properly.\nIf spans of a trace are spread out over multiple instances, spans are not paired up reliably.\nA possible solution to this problem is using the [load balancing exporter](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/exporter/loadbalancingexporter)\nin a layer on front of collector instances running this processor.\n\n## Visualization\n\nService graph metrics are natively supported by Grafana since v9.0.4.\nTo run it, configure a Tempo data source's 'Service Graphs' by linking to the Prometheus backend where metrics are being sent:\n\n```yaml\napiVersion: 1\ndatasources:\n  # Prometheus backend where metrics are sent\n  - name: Prometheus\n    type: prometheus\n    uid: prometheus\n    url: \u003cprometheus-url\u003e\n    jsonData:\n        httpMethod: GET\n    version: 1\n  - name: Tempo\n    type: tempo\n    uid: tempo\n    url: \u003ctempo-url\u003e\n    jsonData:\n      httpMethod: GET\n      serviceMap:\n        datasourceUid: 'prometheus'\n    version: 1\n```\n\n## Configuration\n\nThe following settings are required:\n\n- `metrics_exporter`: the name of the exporter that this processor will write metrics to. This exporter **must** be present in a pipeline.\n- `latency_histogram_buckets`: the list of durations defining the latency histogram buckets.\n    - Default: `[2ms, 4ms, 6ms, 8ms, 10ms, 50ms, 100ms, 200ms, 400ms, 800ms, 1s, 1400ms, 2s, 5s, 10s, 15s]`\n- `dimensions`: the list of dimensions to add together with the default dimensions defined above.\n\nThe following settings can be optionally configured:\n\n- `store` defines the config for the in-memory store used to find requests between services by pairing spans.\n    - `ttl` - TTL is the time to live for items in the store.\n      - Default: `2ms`\n    - `max_items` - MaxItems is the maximum number of items to keep in the store.\n      - Default: `1000` \n- `cache_loop` - the time to cleans the cache periodically\n- `store_expiration_loop`  the time to expire old entries from the store periodically.\n- `virtual_node_peer_attributes` the list of attributes need to match for building virtual server node, the higher the front, the higher the priority.\n  - Default: `[db.name, net.sock.peer.addr, net.peer.name, rpc.service, net.sock.peer.name, net.peer.name, http.url, http.target]`\n\n## Example configuration\n\n```yaml\nreceivers:\n  otlp:\n    protocols:\n      grpc:\n  otlp/servicegraph: # Dummy receiver for the metrics pipeline\n    protocols:\n      grpc:\n        endpoint: localhost:12345\n\nprocessors:\n  servicegraph:\n    metrics_exporter: prometheus/servicegraph # Exporter to send metrics to\n    latency_histogram_buckets: [100us, 1ms, 2ms, 6ms, 10ms, 100ms, 250ms] # Buckets for latency histogram\n    dimensions: [cluster, namespace] # Additional dimensions (labels) to be added to the metrics extracted from the resource and span attributes\n    store: # Configuration for the in-memory store\n      ttl: 2s # Value to wait for an edge to be completed\n      max_items: 200 # Amount of edges that will be stored in the storeMap      \n    cache_loop: 2m # the time to cleans the cache periodically\n    store_expiration_loop: 10s # the time to expire old entries from the store periodically.\n    virtual_node_peer_attributes:\n      - db.name\n      - rpc.service\nexporters:\n  prometheus/servicegraph:\n    endpoint: localhost:9090\n    namespace: servicegraph\n  otlp:\n    endpoint: localhost:4317\n\nservice:\n  pipelines:\n    traces:\n      receivers: [otlp]\n      processors: [servicegraph]\n      exporters: [otlp]\n    metrics/servicegraph:\n      receivers: [otlp/servicegraph]\n      processors: []\n      exporters: [prometheus/servicegraph]\n```\n\n## Features and Feature-Gates\n\nSee the [Collector feature gates](https://github.com/open-telemetry/opentelemetry-collector/blob/main/featuregate/README.md#collector-feature-gates) for an overview of feature gates in the collector.","properties":{"cache_loop":{"description":"CacheLoop is the time to cleans the cache periodically.","title":"cache_loop","type":"string"},"dimensions":{"description":"Dimensions defines the list of additional dimensions on top of the provided:\n- client\n- server\n- failed\n- connection_type\nThe dimensions will be fetched from the span's attributes. Examples of some conventionally used attributes:\nhttps://github.com/open-telemetry/opentelemetry-collector/blob/main/model/semconv/opentelemetry.go.","items":{"type":"string"},"title":"dimensions","type":"array"},"latency_histogram_buckets":{"description":"LatencyHistogramBuckets is the list of durations representing latency histogram buckets.\nSee defaultLatencyHistogramBucketsMs in processor.go for the default value.","items":{"type":"string"},"title":"latency_histogram_buckets","type":"array"},"metrics_exporter":{"description":"MetricsExporter is the name of the metrics exporter to use to ship metrics.","title":"metrics_exporter","type":"string"},"store":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.servicegraphprocessor.StoreConfig","description":"Store contains the config for the in-memory store used to find requests between services by pairing spans.","title":"store"},"store_expiration_loop":{"description":"CacheLoop is the time to expire old entries from the store periodically.","title":"store_expiration_loop","type":"string"},"virtual_node_peer_attributes":{"description":"VirtualNodePeerAttributes the list of attributes need to match, the higher the front, the higher the priority.","items":{"type":"string"},"title":"virtual_node_peer_attributes","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.servicegraphprocessor.StoreConfig":{"additionalProperties":false,"properties":{"max_items":{"description":"MaxItems is the maximum number of items to keep in the store.","title":"max_items","type":"integer"},"ttl":{"description":"TTL is the time to live for items in the store.","title":"ttl","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.spanmetricsprocessor.Config":{"additionalProperties":false,"description":"Config defines the configuration options for spanmetricsprocessor.","properties":{"aggregation_temporality":{"title":"aggregation_temporality","type":"string"},"dimensions":{"description":"Dimensions defines the list of additional dimensions on top of the provided:\n- service.name\n- operation\n- span.kind\n- status.code\nThe dimensions will be fetched from the span's attributes. Examples of some conventionally used attributes:\nhttps://github.com/open-telemetry/opentelemetry-collector/blob/main/model/semconv/opentelemetry.go.","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.spanmetricsprocessor.Dimension"},"title":"dimensions","type":"array"},"dimensions_cache_size":{"description":"DimensionsCacheSize defines the size of cache for storing Dimensions, which helps to avoid cache memory growing\nindefinitely over the lifetime of the collector.\nOptional. See defaultDimensionsCacheSize in processor.go for the default value.","title":"dimensions_cache_size","type":"integer"},"latency_histogram_buckets":{"description":"LatencyHistogramBuckets is the list of durations representing latency histogram buckets.\nSee defaultLatencyHistogramBucketsMs in processor.go for the default value.","items":{"type":"string"},"title":"latency_histogram_buckets","type":"array"},"metrics_exporter":{"description":"MetricsExporter is the name of the metrics exporter to use to ship metrics.","title":"metrics_exporter","type":"string"},"metrics_flush_interval":{"description":"MetricsEmitInterval is the time period between when metrics are flushed or emitted to the configured MetricsExporter.","title":"metrics_flush_interval","type":"string"},"namespace":{"description":"Namespace is the namespace to use for the metrics.","title":"namespace","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.spanmetricsprocessor.Dimension":{"additionalProperties":false,"description":"Dimension defines the dimension name and optional default value if the Dimension is missing from a span attribute.","markdownDescription":"# Span Metrics Processor\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [deprecated]: traces   |\n| Distributions | [contrib], [observiq], [splunk], [sumo] |\n\n[deprecated]: https://github.com/open-telemetry/opentelemetry-collector#deprecated\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\n**Note**: The `spanmetrics` processor is **deprecated** in favour of the [spanmetrics](../../connector/spanmetricsconnector/README.md) connector.\n\n**Note:** Currently experimental and subject to breaking changes (e.g. change from processor to exporter/translator component).\nSee: https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/403.\n\nAggregates Request, Error and Duration (R.E.D) metrics from span data.\n\n**Request** counts are computed as the number of spans seen per unique set of dimensions, including Errors.\nFor example, the following metric shows 142 calls:\n```\ncalls_total{http_method=\"GET\",http_status_code=\"200\",operation=\"/Address\",service_name=\"shippingservice\",span_kind=\"SPAN_KIND_SERVER\",status_code=\"STATUS_CODE_UNSET\"} 142\n```\nMultiple metrics can be aggregated if, for instance, a user wishes to view call counts just on `service_name` and `operation`.\n\n**Error** counts are computed from the Request counts which have an \"Error\" Status Code metric dimension.\nFor example, the following metric indicates 220 errors:\n```\ncalls_total{http_method=\"GET\",http_status_code=\"503\",operation=\"/checkout\",service_name=\"frontend\",span_kind=\"SPAN_KIND_CLIENT\",status_code=\"STATUS_CODE_ERROR\"} 220\n```\n\n**Duration** is computed from the difference between the span start and end times and inserted into the\nrelevant latency histogram time bucket for each unique set dimensions.\nFor example, the following latency buckets indicate the vast majority of spans (9K) have a 100ms latency:\n```\nlatency_bucket{http_method=\"GET\",http_status_code=\"200\",label1=\"value1\",operation=\"/Address\",service_name=\"shippingservice\",span_kind=\"SPAN_KIND_SERVER\",status_code=\"STATUS_CODE_UNSET\",le=\"2\"} 327\nlatency_bucket{http_method=\"GET\",http_status_code=\"200\",label1=\"value1\",operation=\"/Address\",service_name=\"shippingservice\",span_kind=\"SPAN_KIND_SERVER\",status_code=\"STATUS_CODE_UNSET\",le=\"6\"} 751\nlatency_bucket{http_method=\"GET\",http_status_code=\"200\",label1=\"value1\",operation=\"/Address\",service_name=\"shippingservice\",span_kind=\"SPAN_KIND_SERVER\",status_code=\"STATUS_CODE_UNSET\",le=\"10\"} 1195\nlatency_bucket{http_method=\"GET\",http_status_code=\"200\",label1=\"value1\",operation=\"/Address\",service_name=\"shippingservice\",span_kind=\"SPAN_KIND_SERVER\",status_code=\"STATUS_CODE_UNSET\",le=\"100\"} 10180\nlatency_bucket{http_method=\"GET\",http_status_code=\"200\",label1=\"value1\",operation=\"/Address\",service_name=\"shippingservice\",span_kind=\"SPAN_KIND_SERVER\",status_code=\"STATUS_CODE_UNSET\",le=\"250\"} 10180\n...\n```\n\nEach metric will have _at least_ the following dimensions because they are common across all spans:\n- Service name\n- Operation\n- Span kind\n- Status code\n\nThis processor lets traces to continue through the pipeline unmodified.\n\nThe following settings are required:\n\n- `metrics_exporter`: the name of the exporter that this processor will write metrics to. This exporter **must** be present in a pipeline.\n\nThe following settings can be optionally configured:\n\n- `latency_histogram_buckets`: the list of durations defining the latency histogram buckets.\n  - Default: `[2ms, 4ms, 6ms, 8ms, 10ms, 50ms, 100ms, 200ms, 400ms, 800ms, 1s, 1400ms, 2s, 5s, 10s, 15s]`\n- `dimensions`: the list of dimensions to add together with the default dimensions defined above.\n  \n  Each additional dimension is defined with a `name` which is looked up in the span's collection of attributes or\n  resource attributes (AKA process tags) such as `ip`, `host.name` or `region`.\n  \n  If the `name`d attribute is missing in the span, the optional provided `default` is used.\n  \n  If no `default` is provided, this dimension will be **omitted** from the metric.\n- `dimensions_cache_size`: the size of cache for storing Dimensions to improve collectors memory usage.\n  - Default: `1000`.\n- `aggregation_temporality`: Defines the aggregation temporality of the generated metrics. \n  One of either `AGGREGATION_TEMPORALITY_CUMULATIVE` or `AGGREGATION_TEMPORALITY_DELTA`.\n  - Default: `AGGREGATION_TEMPORALITY_CUMULATIVE`\n- `namespace`: Defines the namespace of the generated metrics. If `namespace` provided, generated metric name will be added `namespace.` prefix.\n- `metrics_flush_interval`: Defines the flush interval of the generated metrics.\n  -  Default: `15s`.\n\n## Examples\n\nThe following is a simple example usage of the spanmetrics processor.\n\nFor configuration examples on other use cases, please refer to [More Examples](#more-examples).\n\nThe full list of settings exposed for this processor are documented [here](./config.go).\n\n```yaml\nreceivers:\n  jaeger:\n    protocols:\n      thrift_http:\n        endpoint: \"0.0.0.0:14278\"\n\n  # Dummy receiver that's never used, because a pipeline is required to have one.\n  otlp/spanmetrics:\n    protocols:\n      grpc:\n        endpoint: \"localhost:12345\"\n\n  otlp:\n    protocols:\n      grpc:\n        endpoint: \"localhost:55677\"\n\nprocessors:\n  batch:\n  spanmetrics:\n    metrics_exporter: otlp/spanmetrics\n    latency_histogram_buckets: [100us, 1ms, 2ms, 6ms, 10ms, 100ms, 250ms]\n    dimensions:\n      - name: http.method\n        default: GET\n      - name: http.status_code\n    dimensions_cache_size: 1000\n    aggregation_temporality: \"AGGREGATION_TEMPORALITY_CUMULATIVE\"     \n    metrics_flush_interval: 15s\n\nexporters:\n  jaeger:\n    endpoint: localhost:14250\n\n  otlp/spanmetrics:\n    endpoint: \"localhost:55677\"\n    tls:\n      insecure: true\n\n  prometheus:\n    endpoint: \"0.0.0.0:8889\"\n\nservice:\n  pipelines:\n    traces:\n      receivers: [jaeger]\n      processors: [spanmetrics, batch]\n      exporters: [jaeger]\n\n    # The exporter name must match the metrics_exporter name.\n    # The receiver is just a dummy and never used; added to pass validation requiring at least one receiver in a pipeline.\n    metrics/spanmetrics:\n      receivers: [otlp/spanmetrics]\n      exporters: [otlp/spanmetrics]\n\n    metrics:\n      receivers: [otlp]\n      exporters: [prometheus]\n```\n\n### More Examples\n\nFor more example configuration covering various other use cases, please visit the [testdata directory](./testdata).","properties":{"default":{"title":"default","type":"string"},"name":{"title":"name","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.spanprocessor.Config":{"additionalProperties":false,"description":"Config is the configuration for the span processor.","markdownDescription":"# Span Processor\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [alpha]: traces   |\n| Distributions | [core], [contrib], [aws], [observiq], [redhat], [splunk], [sumo] |\n\n[alpha]: https://github.com/open-telemetry/opentelemetry-collector#alpha\n[core]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[redhat]: https://github.com/os-observability/redhat-opentelemetry-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe span processor modifies the span name based on its attributes or extract span attributes from the span name. It also allows\nto change span status. Please refer to [config.go](./config.go) for the config spec.\n\nIt optionally supports the ability to [include/exclude spans](../attributesprocessor/README.md#includeexclude-filtering).\n\nThe following actions are supported:\n\n- `name`: Modify the name of attributes within a span\n- `status`: Modify the status of the span\n\n### Name a span\n\nThe following settings are required:\n\n- `from_attributes`: The attribute value for the keys are used to create a\nnew name in the order specified in the configuration.\n\nThe following settings can be optionally configured:\n\n- `separator`: A string, which is specified will be used to split values\n\nNote: If renaming is dependent on attributes being modified by the `attributes`\nprocessor, ensure the `span` processor is specified after the `attributes`\nprocessor in the `pipeline` specification.\n\n```yaml\nspan:\n  name:\n    # from_attributes represents the attribute keys to pull the values from to generate the\n    # new span name.\n    from_attributes: [\u003ckey1\u003e, \u003ckey2\u003e, ...]\n    # Separator is the string used to concatenate various parts of the span name.\n    separator: \u003cvalue\u003e\n```\n\nExample:\n\n```yaml\nspan:\n  name:\n    from_attributes: [\"db.svc\", \"operation\"]\n    separator: \"::\"\n```\n\nRefer to [config.yaml](./testdata/config.yaml) for detailed\nexamples on using the processor.\n\n### Extract attributes from span name\n\nTakes a list of regular expressions to match span name against and extract\nattributes from it based on subexpressions. Must be specified under the\n`to_attributes` section.\n\nThe following settings are required:\n\n- `rules`: A list of rules to extract attribute values from span name. The values\nin the span name are replaced by extracted attribute names. Each rule in the list\nis regex pattern string. Span name is checked against the regex and if the regex\nmatches then all named subexpressions of the regex are extracted as attributes\nand are added to the span. Each subexpression name becomes an attribute name and\nsubexpression matched portion becomes the attribute value. The matched portion\nin the span name is replaced by extracted attribute name. If the attributes\nalready exist in the span then they will be overwritten. The process is repeated\nfor all rules in the order they are specified. Each subsequent rule works on the\nspan name that is the output after processing the previous rule.\n- `break_after_match` (default = false): specifies if processing of rules should stop after the first\nmatch. If it is false rule processing will continue to be performed over the\nmodified span name.\n\n```yaml\nspan/to_attributes:\n  name:\n    to_attributes:\n      rules:\n        - regexp-rule1\n        - regexp-rule2\n        - regexp-rule3\n        ...\n      break_after_match: \u003ctrue|false\u003e\n\n```\n\nExample:\n\n```yaml\n# Let's assume input span name is /api/v1/document/12345678/update\n# Applying the following results in output span name /api/v1/document/{documentId}/update\n# and will add a new attribute \"documentId\"=\"12345678\" to the span.\nspan/to_attributes:\n  name:\n    to_attributes:\n      rules:\n        - ^\\/api\\/v1\\/document\\/(?P\u003cdocumentId\u003e.*)\\/update$\n```\n\n### Set status for span\n\nThe following setting is required:\n\n- `code`: Represents span status. One of the following values \"Unset\", \"Error\", \"Ok\".\n\nThe following setting is allowed only for code \"Error\":\n- `description`\n\nExample:\n\n```yaml\n# Set status allows to set specific status for a given span. Possible values are\n# Ok, Error and Unset as per\n# https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/trace/api.md#set-status\n# The description field allows to set a human-readable message for errors.\nspan/set_status:\n  status:\n    code: Error\n    description: \"some error description\"\n```\n\nRefer to [config.yaml](./testdata/config.yaml) for detailed\nexamples on using the processor.","properties":{"exclude":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterconfig.MatchProperties","description":"Exclude specifies when this processor will not be applied to the input data\nwhich match the specified properties.\nNote: The `exclude` properties are checked after the `include` properties,\nif they exist, are checked.\nIf `include` isn't specified, the `exclude` properties are checked against\nall input data.\nThis is an optional field. If neither `include` and `exclude` are set, all input data\nis processed. If `exclude` is set and `include` isn't set, then all the\ninput data that does not match the properties in this structure are processed.","title":"exclude"},"include":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.filter.filterconfig.MatchProperties","description":"Include specifies the set of input data properties that must be present in order\nfor this processor to apply to it.\nNote: If `exclude` is specified, the input data is compared against those\nproperties after the `include` properties.\nThis is an optional field. If neither `include` and `exclude` are set, all input data\nare processed. If `include` is set and `exclude` isn't set, then all\ninput data matching the properties in this structure are processed.","title":"include"},"name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.spanprocessor.Name","description":"Rename specifies the components required to re-name a span.\nThe `from_attributes` field needs to be set for this processor to be properly\nconfigured.\nNote: The field name is `Rename` to avoid collision with the Name() method\nfrom config.NamedEntity","title":"name"},"status":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.spanprocessor.Status","description":"SetStatus specifies status which should be set for this span.","title":"status"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.spanprocessor.Name":{"additionalProperties":false,"description":"Name specifies the attributes to use to re-name a span.","properties":{"from_attributes":{"description":"FromAttributes represents the attribute keys to pull the values from to\ngenerate the new span name. All attribute keys are required in the span\nto re-name a span. If any attribute is missing from the span, no re-name\nwill occur.\nNote: The new span name is constructed in order of the `from_attributes`\nspecified in the configuration. This field is required and cannot be empty.","items":{"type":"string"},"title":"from_attributes","type":"array"},"separator":{"description":"Separator is the string used to separate attributes values in the new\nspan name. If no value is set, no separator is used between attribute\nvalues. Used with FromAttributes only.","title":"separator","type":"string"},"to_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.spanprocessor.ToAttributes","description":"ToAttributes specifies a configuration to extract attributes from span name.","title":"to_attributes"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.spanprocessor.Status":{"additionalProperties":false,"properties":{"code":{"description":"Code is one of three values \"Ok\" or \"Error\" or \"Unset\". Please check:\nhttps://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/trace/api.md#set-status","title":"code","type":"string"},"description":{"description":"Description is an optional field documenting Error statuses.","title":"description","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.spanprocessor.ToAttributes":{"additionalProperties":false,"description":"ToAttributes specifies a configuration to extract attributes from span name.","properties":{"break_after_match":{"description":"BreakAfterMatch specifies if processing of rules should stop after the first\nmatch. If it is false rule processing will continue to be performed over the\nmodified span name.","title":"break_after_match","type":"boolean"},"rules":{"description":"Rules is a list of rules to extract attribute values from span name. The values\nin the span name are replaced by extracted attribute names. Each rule in the list\nis a regex pattern string. Span name is checked against the regex. If it matches\nthen all named subexpressions of the regex are extracted as attributes\nand are added to the span. Each subexpression name becomes an attribute name and\nsubexpression matched portion becomes the attribute value. The matched portion\nin the span name is replaced by extracted attribute name. If the attributes\nalready exist in the span then they will be overwritten. The process is repeated\nfor all rules in the order they are specified. Each subsequent rule works on the\nspan name that is the output after processing the previous rule.","items":{"type":"string"},"title":"rules","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.AndCfg":{"additionalProperties":false,"properties":{"and_sub_policy":{"items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.AndSubPolicyCfg"},"title":"and_sub_policy","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.AndSubPolicyCfg":{"additionalProperties":false,"description":"AndSubPolicyCfg holds the common configuration to all policies under and policy.","properties":{"boolean_attribute":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.BooleanAttributeCfg","title":"boolean_attribute"},"latency":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.LatencyCfg","title":"latency"},"name":{"title":"name","type":"string"},"numeric_attribute":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.NumericAttributeCfg","title":"numeric_attribute"},"ottl_condition":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.OTTLConditionCfg","title":"ottl_condition"},"probabilistic":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.ProbabilisticCfg","title":"probabilistic"},"rate_limiting":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.RateLimitingCfg","title":"rate_limiting"},"span_count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.SpanCountCfg","title":"span_count"},"status_code":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.StatusCodeCfg","title":"status_code"},"string_attribute":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.StringAttributeCfg","title":"string_attribute"},"trace_state":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.TraceStateCfg","title":"trace_state"},"type":{"title":"type","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.BooleanAttributeCfg":{"additionalProperties":false,"description":"BooleanAttributeCfg holds the configurable settings to create a boolean attribute filter sampling policy evaluator.","properties":{"key":{"description":"Tag that the filter is going to be matching against.","title":"key","type":"string"},"value":{"description":"Value indicate the bool value, either true or false to use when matching against attribute values.\nBooleanAttribute Policy will apply exact value match on Value","title":"value","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.CompositeCfg":{"additionalProperties":false,"description":"CompositeCfg holds the configurable settings to create a composite sampling policy evaluator.","properties":{"composite_sub_policy":{"items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.CompositeSubPolicyCfg"},"title":"composite_sub_policy","type":"array"},"max_total_spans_per_second":{"title":"max_total_spans_per_second","type":"integer"},"policy_order":{"items":{"type":"string"},"title":"policy_order","type":"array"},"rate_allocation":{"items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.RateAllocationCfg"},"title":"rate_allocation","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.CompositeSubPolicyCfg":{"additionalProperties":false,"description":"CompositeSubPolicyCfg holds the common configuration to all policies under composite policy.","properties":{"and":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.AndCfg","description":"Configs for and policy evaluator.","title":"and"},"boolean_attribute":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.BooleanAttributeCfg","title":"boolean_attribute"},"latency":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.LatencyCfg","title":"latency"},"name":{"title":"name","type":"string"},"numeric_attribute":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.NumericAttributeCfg","title":"numeric_attribute"},"ottl_condition":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.OTTLConditionCfg","title":"ottl_condition"},"probabilistic":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.ProbabilisticCfg","title":"probabilistic"},"rate_limiting":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.RateLimitingCfg","title":"rate_limiting"},"span_count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.SpanCountCfg","title":"span_count"},"status_code":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.StatusCodeCfg","title":"status_code"},"string_attribute":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.StringAttributeCfg","title":"string_attribute"},"trace_state":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.TraceStateCfg","title":"trace_state"},"type":{"title":"type","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.Config":{"additionalProperties":false,"description":"Config holds the configuration for tail-based sampling.","properties":{"decision_wait":{"description":"DecisionWait is the desired wait time from the arrival of the first span of\ntrace until the decision about sampling it or not is evaluated.","title":"decision_wait","type":"string"},"expected_new_traces_per_sec":{"description":"ExpectedNewTracesPerSec sets the expected number of new traces sending to the tail sampling processor\nper second. This helps with allocating data structures with closer to actual usage size.","title":"expected_new_traces_per_sec","type":"integer"},"num_traces":{"description":"NumTraces is the number of traces kept on memory. Typically most of the data\nof a trace is released after a sampling decision is taken.","title":"num_traces","type":"integer"},"policies":{"description":"PolicyCfgs sets the tail-based sampling policy which makes a sampling decision\nfor a given trace when requested.","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.PolicyCfg"},"title":"policies","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.LatencyCfg":{"additionalProperties":false,"description":"LatencyCfg holds the configurable settings to create a latency filter sampling policy evaluator","properties":{"threshold_ms":{"description":"ThresholdMs in milliseconds.","title":"threshold_ms","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.NumericAttributeCfg":{"additionalProperties":false,"description":"NumericAttributeCfg holds the configurable settings to create a numeric attribute filter sampling policy evaluator.","properties":{"key":{"description":"Tag that the filter is going to be matching against.","title":"key","type":"string"},"max_value":{"description":"MaxValue is the maximum value of the attribute to be considered a match.","title":"max_value","type":"integer"},"min_value":{"description":"MinValue is the minimum value of the attribute to be considered a match.","title":"min_value","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.OTTLConditionCfg":{"additionalProperties":false,"description":"OTTLConditionCfg holds the configurable setting to create a OTTL condition filter sampling policy evaluator.","properties":{"error_mode":{"title":"error_mode","type":"string"},"span":{"items":{"type":"string"},"title":"span","type":"array"},"spanevent":{"items":{"type":"string"},"title":"spanevent","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.PolicyCfg":{"additionalProperties":false,"description":"PolicyCfg holds the common configuration to all policies.","properties":{"and":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.AndCfg","description":"Configs for defining and policy","title":"and"},"boolean_attribute":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.BooleanAttributeCfg","title":"boolean_attribute"},"composite":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.CompositeCfg","description":"Configs for defining composite policy","title":"composite"},"latency":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.LatencyCfg","title":"latency"},"name":{"title":"name","type":"string"},"numeric_attribute":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.NumericAttributeCfg","title":"numeric_attribute"},"ottl_condition":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.OTTLConditionCfg","title":"ottl_condition"},"probabilistic":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.ProbabilisticCfg","title":"probabilistic"},"rate_limiting":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.RateLimitingCfg","title":"rate_limiting"},"span_count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.SpanCountCfg","title":"span_count"},"status_code":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.StatusCodeCfg","title":"status_code"},"string_attribute":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.StringAttributeCfg","title":"string_attribute"},"trace_state":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.TraceStateCfg","title":"trace_state"},"type":{"title":"type","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.ProbabilisticCfg":{"additionalProperties":false,"description":"ProbabilisticCfg holds the configurable settings to create a probabilistic sampling policy evaluator.","properties":{"hash_salt":{"description":"HashSalt allows one to configure the hashing salts. This is important in scenarios where multiple layers of collectors\nhave different sampling rates: if they use the same salt all passing one layer may pass the other even if they have\ndifferent sampling rates, configuring different salts avoids that.","title":"hash_salt","type":"string"},"sampling_percentage":{"description":"SamplingPercentage is the percentage rate at which traces are going to be sampled. Defaults to zero, i.e.: no sample.\nValues greater or equal 100 are treated as \"sample all traces\".","title":"sampling_percentage","type":"number"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.RateAllocationCfg":{"additionalProperties":false,"description":"RateAllocationCfg used within composite policy","properties":{"percent":{"title":"percent","type":"integer"},"policy":{"title":"policy","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.RateLimitingCfg":{"additionalProperties":false,"description":"RateLimitingCfg holds the configurable settings to create a rate limiting sampling policy evaluator.","properties":{"spans_per_second":{"description":"SpansPerSecond sets the limit on the maximum nuber of spans that can be processed each second.","title":"spans_per_second","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.SpanCountCfg":{"additionalProperties":false,"description":"SpanCountCfg holds the configurable settings to create a Span Count filter sampling policy evaluator","properties":{"max_spans":{"title":"max_spans","type":"integer"},"min_spans":{"description":"Minimum number of spans in a Trace","title":"min_spans","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.StatusCodeCfg":{"additionalProperties":false,"description":"StatusCodeCfg holds the configurable settings to create a status code filter sampling policy evaluator.","properties":{"status_codes":{"items":{"type":"string"},"title":"status_codes","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.StringAttributeCfg":{"additionalProperties":false,"description":"StringAttributeCfg holds the configurable settings to create a string attribute filter sampling policy evaluator.","properties":{"cache_max_size":{"description":"CacheMaxSize is the maximum number of attribute entries of LRU Cache that stores the matched result\nfrom the regular expressions defined in Values.\nCacheMaxSize will not be used if EnabledRegexMatching is set to false.","title":"cache_max_size","type":"integer"},"enabled_regex_matching":{"description":"EnabledRegexMatching determines whether match attribute values by regexp string.","title":"enabled_regex_matching","type":"boolean"},"invert_match":{"description":"InvertMatch indicates that values or regular expressions must not match against attribute values.\nIf InvertMatch is true and Values is equal to 'acme', all other values will be sampled except 'acme'.\nAlso, if the specified Key does not match on any resource or span attributes, data will be sampled.","title":"invert_match","type":"boolean"},"key":{"description":"Tag that the filter is going to be matching against.","title":"key","type":"string"},"values":{"description":"Values indicate the set of values or regular expressions to use when matching against attribute values.\nStringAttribute Policy will apply exact value match on Values unless EnabledRegexMatching is true.","items":{"type":"string"},"title":"values","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.TraceStateCfg":{"additionalProperties":false,"properties":{"key":{"description":"Tag that the filter is going to be matching against.","title":"key","type":"string"},"values":{"description":"Values indicate the set of values to use when matching against trace_state values.","items":{"type":"string"},"title":"values","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.transformprocessor.Config":{"additionalProperties":false,"description":"Config defines the configuration for the processor.","markdownDescription":"# Transform Processor\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [alpha]: traces, metrics, logs   |\n| Distributions | [contrib], [observiq], [splunk], [sumo] |\n| Warnings      | [Unsound Transformations, Identity Conflict, Orphaned Telemetry, Other](#warnings) |\n\n[alpha]: https://github.com/open-telemetry/opentelemetry-collector#alpha\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe transform processor modifies telemetry based on configuration using the [OpenTelemetry Transformation Language](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/pkg/ottl).\n\nFor each signal type, the processor takes a list of statements associated to a [Context type](#contexts) and executes the statements against the incoming telemetry in the order specified in the config.\nEach statement can access and transform telemetry using functions and allow the use of a condition to help decide whether the function should be executed.\n\n- [Config](#config)\n- [Grammar](#grammar)\n- [Contexts](#contexts)\n- [Supported functions](#supported-functions)\n- [Examples](#examples)\n- [Contributing](#contributing)\n\n## Config\n\nThe transform processor allows configuring multiple context statements for traces, metrics, and logs.\nThe value of `context` specifies which [OTTL Context](#contexts) to use when interpreting the associated statements.\nThe statement strings, which must be OTTL compatible, will be passed to the OTTL and interpreted using the associated context. \nEach context will be processed in the order specified and each statement for a context will be executed in the order specified.\n\nThe transform processor also allows configuring an optional field, `error_mode`, which will determine how the processor reacts to errors that occur while processing a statement.\n\n| error_mode            | description                                                                                                                |\n|-----------------------|----------------------------------------------------------------------------------------------------------------------------|\n| ignore                | The processor ignores errors returned by statements and continues on to the next statement.  This is the recommended mode. |\n| propagate             | The processor returns the error up the pipeline.  This will result in the payload being dropped from the collector.        |\n\nIf not specified, `propagate` will be used.\n\n```yaml\ntransform:\n  error_mode: ignore\n  \u003ctrace|metric|log\u003e_statements:\n    - context: string\n      statements:\n        - string\n        - string\n        - string\n    - context: string\n      statements:\n        - string\n        - string\n        - string\n```\n\nProper use of contexts will provide increased performance and capabilities.  See [Contexts](#contexts) for more details.\n\nValid values for `context` are:\n\n| Signal            | Context Values                                 |\n|-------------------|------------------------------------------------|\n| trace_statements  | `resource`, `scope`, `span`, and `spanevent`   |\n| metric_statements | `resource`, `scope`, `metric`, and `datapoint` |\n| log_statements    | `resource`, `scope`, and `log`                 |\n\n### Example\n\nThe example takes advantage of context efficiency by grouping transformations with the context which it intends to transform.\nSee [Contexts](#contexts) for more details.\n\nExample configuration:\n```yaml\ntransform:\n  error_mode: ignore\n  trace_statements:\n    - context: resource\n      statements:\n        - keep_keys(attributes, [\"service.name\", \"service.namespace\", \"cloud.region\", \"process.command_line\"])\n        - replace_pattern(attributes[\"process.command_line\"], \"password\\\\=[^\\\\s]*(\\\\s?)\", \"password=***\")\n        - limit(attributes, 100, [])\n        - truncate_all(attributes, 4096)\n    - context: span\n      statements:\n        - set(status.code, 1) where attributes[\"http.path\"] == \"/health\"\n        - set(name, attributes[\"http.route\"])\n        - replace_match(attributes[\"http.target\"], \"/user/*/list/*\", \"/user/{userId}/list/{listId}\")\n        - limit(attributes, 100, [])\n        - truncate_all(attributes, 4096)\n\n  metric_statements:\n    - context: resource\n      statements:\n      - keep_keys(attributes, [\"host.name\"])\n      - truncate_all(attributes, 4096)\n    - context: metric\n      statements:\n        - set(description, \"Sum\") where type == \"Sum\"\n    - context: datapoint\n      statements:\n        - limit(attributes, 100, [\"host.name\"])\n        - truncate_all(attributes, 4096)\n        - convert_sum_to_gauge() where metric.name == \"system.processes.count\"\n        - convert_gauge_to_sum(\"cumulative\", false) where metric.name == \"prometheus_metric\"\n        \n  log_statements:\n    - context: resource\n      statements:\n        - keep_keys(resource.attributes, [\"service.name\", \"service.namespace\", \"cloud.region\"])\n    - context: log\n      statements:\n        - set(severity_text, \"FAIL\") where body == \"request failed\"\n        - replace_all_matches(attributes, \"/user/*/list/*\", \"/user/{userId}/list/{listId}\")\n        - replace_all_patterns(attributes, \"/account/\\\\d{4}\", \"/account/{accountId}\")\n        - set(body, attributes[\"http.route\"])\n```\n\n## Grammar\n\nYou can learn more in-depth details on the capabilities and limitations of the OpenTelemetry Transformation Language used by the transform processor by reading about its [grammar](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/pkg/ottl#grammar).\n\n## Contexts\n\nThe transform processor utilizes the OTTL's contexts to transform Resource, Scope, Span, SpanEvent, Metric, DataPoint, and Log telemetry.\nThe contexts allow the OTTL to interact with the underlying telemetry data in its pdata form.\n\n- [Resource Context](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/pkg/ottl/contexts/ottlresource)\n- [Scope Context](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/pkg/ottl/contexts/ottlscope)\n- [Span Context](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/pkg/ottl/contexts/ottlspan) \u003c!-- markdown-link-check-disable-line --\u003e\n- [SpanEvent Context](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/pkg/ottl/contexts/ottlspanevent)\n- [Metric Context](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/pkg/ottl/contexts/ottlmetric)\n- [DataPoint Context](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/pkg/ottl/contexts/ottldatapoint) \u003c!-- markdown-link-check-disable-line --\u003e\n- [Log Context](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/pkg/ottl/contexts/ottllog) \u003c!-- markdown-link-check-disable-line --\u003e\n\nEach context allows transformation of its type of telemetry.  \nFor example, statements associated to a `resource` context will be able to transform the resource's `attributes` and `dropped_attributes_count`.\n\nContexts __NEVER__ supply access to individual items \"lower\" in the protobuf definition.\n- This means statements associated to a `resource` __WILL NOT__ be able to access the underlying instrumentation scopes.\n- This means statements associated to a `scope` __WILL NOT__ be able to access the underlying telemetry slices (spans, metrics, or logs).\n- Similarly, statements associated to a  `metric` __WILL NOT__ be able to access individual datapoints, but can access the entire datapoints slice.\n- Similarly, statements associated to a  `span` __WILL NOT__ be able to access individual SpanEvents, but can access the entire SpanEvents slice.\n\nFor practical purposes, this means that a context cannot make decisions on its telemetry based on telemetry \"lower\" in the structure.\nFor example, __the following context statement is not possible__ because it attempts to use individual datapoint attributes in the condition of a statements that is associated to a `metric`\n\n```yaml\nmetric_statements:\n- context: metric\n  statements:\n  - set(description, \"test passed\") where datapoints.attributes[\"test\"] == \"pass\"\n```\n\nContext __ALWAYS__ supply access to the items \"higher\" in the protobuf definition that are associated to the telemetry being transformed.\n- This means that statements associated to a `datapoint` have access to a datapoint's metric, instrumentation scope, and resource.\n- This means that statements associated to a `spanevent` have access to a spanevent's span, instrumentation scope, and resource.\n- This means that statements associated to a `span`/`metric`/`log` have access to the telemetry's instrumentation scope, and resource.\n- This means that statements associated to a `scope` have access to the scope's resource.\n\nFor example, __the following context statement is possible__ because `datapoint` statements can access the datapoint's metric.\n\n```yaml\nmetric_statements:\n- context: datapoint\n  statements:\n    - set(metric.description, \"test passed\") where attributes[\"test\"] == \"pass\"\n```\n\nWhenever possible, associate your statements to the context that the statement intend to transform.\nAlthough you can modify resource attributes associated to a span using the `span` context, it is more efficient to use the `resource` context.\nThis is because contexts are nested: the efficiency comes because higher-level contexts can avoid iterating through any of the contexts at a lower level. \n\n## Supported functions:\n\nSince the transform processor utilizes the OTTL's contexts for Traces, Metrics, and Logs, it is able to utilize functions that expect pdata in addition to any common functions. These common functions can be used for any signal.\n\u003c!-- markdown-link-check-disable-next-line --\u003e\n- [OTTL Functions](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/pkg/ottl/ottlfuncs)\n\nIn addition to OTTL functions, the processor defines its own functions to help with transformations specific to this processor:\n\n**Metrics only functions**\n- [convert_sum_to_gauge](#convert_sum_to_gauge)\n- [convert_gauge_to_sum](#convert_gauge_to_sum)\n- [convert_summary_count_val_to_sum](#convert_summary_count_val_to_sum)\n- [convert_summary_sum_val_to_sum](#convert_summary_sum_val_to_sum)\n\n### convert_sum_to_gauge\n\n`convert_sum_to_gauge()`\n\nConverts incoming metrics of type \"Sum\" to type \"Gauge\", retaining the metric's datapoints. Noop for metrics that are not of type \"Sum\".\n\n**NOTE:** This function may cause a metric to break semantics for [Gauge metrics](https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/metrics/data-model.md#gauge). Use at your own risk.\n\nExamples:\n\n- `convert_sum_to_gauge()`\n\n### convert_gauge_to_sum\n\n`convert_gauge_to_sum(aggregation_temporality, is_monotonic)`\n\nConverts incoming metrics of type \"Gauge\" to type \"Sum\", retaining the metric's datapoints and setting its aggregation temporality and monotonicity accordingly. Noop for metrics that are not of type \"Gauge\".\n\n`aggregation_temporality` is a string (`\"cumulative\"` or `\"delta\"`) that specifies the resultant metric's aggregation temporality. `is_monotonic` is a boolean that specifies the resultant metric's monotonicity. \n\n**NOTE:** This function may cause a metric to break semantics for [Sum metrics](https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/metrics/data-model.md#sums). Use at your own risk.\n\nExamples:\n\n- `convert_gauge_to_sum(\"cumulative\", false)`\n\n\n- `convert_gauge_to_sum(\"delta\", true)`\n\n### convert_summary_count_val_to_sum\n\n`convert_summary_count_val_to_sum(aggregation_temporality, is_monotonic)`\n\nThe `convert_summary_count_val_to_sum` function creates a new Sum metric from a Summary's count value.\n\n`aggregation_temporality` is a string (`\"cumulative\"` or `\"delta\"`) representing the desired aggregation temporality of the new metric. `is_monotonic` is a boolean representing the monotonicity of the new metric.\n\nThe name for the new metric will be `\u003csummary metric name\u003e_count`. The fields that are copied are: `timestamp`, `starttimestamp`, `attibutes`, and `description`. The new metric that is created will be passed to all functions in the metrics statements list.  Function conditions will apply.\n\n**NOTE:** This function may cause a metric to break semantics for [Sum metrics](https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/metrics/data-model.md#sums). Use at your own risk.\n\nExamples:\n\n- `convert_summary_count_val_to_sum(\"delta\", true)`\n\n\n- `convert_summary_count_val_to_sum(\"cumulative\", false)`\n\n### convert_summary_sum_val_to_sum\n\n`convert_summary_sum_val_to_sum(aggregation_temporality, is_monotonic)`\n\nThe `convert_summary_sum_val_to_sum` function creates a new Sum metric from a Summary's sum value.\n\n`aggregation_temporality` is a string (`\"cumulative\"` or `\"delta\"`) representing the desired aggregation temporality of the new metric. `is_monotonic` is a boolean representing the monotonicity of the new metric.\n\nThe name for the new metric will be `\u003csummary metric name\u003e_sum`. The fields that are copied are: `timestamp`, `starttimestamp`, `attibutes`, and `description`. The new metric that is created will be passed to all functions in the metrics statements list.  Function conditions will apply.\n\n**NOTE:** This function may cause a metric to break semantics for [Sum metrics](https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/metrics/data-model.md#sums). Use at your own risk.\n\nExamples:\n\n- `convert_summary_sum_val_to_sum(\"delta\", true)`\n\n\n- `convert_summary_sum_val_to_sum(\"cumulative\", false)`\n\n## Examples\n\n### Perform transformation if field does not exist\nSet attribute `test` to `\"pass\"` if the attribute `test` does not exist:\n```yaml\ntransform:\n  error_mode: ignore\n  trace_statements:\n    - context: span\n      statements:\n        # accessing a map with a key that does not exist will return nil. \n        - set(attributes[\"test\"], \"pass\") where attributes[\"test\"] == nil\n``` \n\n### Rename attribute\nThere are 2 ways to rename an attribute key:\n\nYou can either set a new attribute and delete the old:\n\n```yaml\ntransform:\n  error_mode: ignore\n  trace_statements:\n    - context: resource\n      statements:\n        - set(attributes[\"namespace\"], attributes[\"k8s.namespace.name\"])\n        - delete_key(attributes, \"k8s.namespace.name\") \n``` \n\nOr you can update the key using regex:\n\n```yaml\ntransform:\n  error_mode: ignore\n  trace_statements:\n    - context: resource\n      statements:\n        - replace_all_patterns(attributes, \"key\", \"k8s\\\\.namespace\\\\.name\", \"namespace\")\n``` \n\n### Move field to attribute\nSet attribute `body` to the value of the log body:\n\n```yaml\ntransform:\n  error_mode: ignore\n  log_statements:\n    - context: log\n      statements: \n        - set(attributes[\"body\"], body)\n``` \n\n### Comnbine two attributes\nSet attribute `test` to the value of attributes `\"foo\"` and `\"bar\"` combined. \n```yaml\ntransform:\n  error_mode: ignore\n  trace_statements:\n    - context: resource\n      statements:\n        # Use Concat function to combine any number of string, separated by a delimiter.\n        - set(attributes[\"test\"], Concat([attributes[\"foo\"], attributes[\"bar\"]], \" \")\n```\n\n### Parsing JSON logs\n\nGiven the following json body\n\n```json\n{\n  \"name\": \"log\",\n  \"attr1\": \"foo\",\n  \"attr2\": \"bar\",\n  \"nested\": {\n    \"attr3\": \"example\"\n  }\n}\n```\n\nadd specific fields as attributes on the log:\n\n```yaml\ntransform:\n  error_mode: ignore\n  log_statements:\n    - context: log\n      statements:\n        # Parse body as JSON and merge the resulting map with the cache map, ignoring non-json bodies.\n        # cache is a field exposed by OTTL that is a temporary storage place for complex operations.\n        - merge_maps(cache, ParseJSON(body), \"upsert\") where IsMatch(body, \"^\\\\{\") \n          \n        # Set attributes using the values merged into cache.\n        # If the attribute doesn't exist in cache then nothing happens.\n        - set(attributes[\"attr1\"], cache[\"attr1\"])\n        - set(attributes[\"attr2\"], cache[\"attr2\"])\n        \n        # To access nested maps you can chain index ([]) operations.\n        # If nested or attr3 do no exist in cache then nothing happens.\n        - set(attributes[\"nested.attr3\"], cache[\"nested\"][\"attr3\"])\n```\n\n## Contributing\n\nSee [CONTRIBUTING.md](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/processor/transformprocessor/CONTRIBUTING.md).\n\n\n## Warnings\n\nThe transform processor's implementation of the [OpenTelemetry Transformation Language]https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/processing.md#opentelemetry-transformation-language) (OTTL) allows users to modify all aspects of their telemetry.  Some specific risks are listed below, but this is not an exhaustive list.  In general, understand your data before using the transform processor.  \n\n- [Unsound Transformations](https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/standard-warnings.md#unsound-transformations): Several Metric-only functions allow you to transform one metric data type to another or create new metrics from an existing metrics.  Transformations between metric data types are not defined in the [metrics data model](https://github.com/open-telemetry/opentelemetry-specification/blob/main//specification/metrics/data-model.md).  These functions have the expectation that you understand the incoming data and know that it can be meaningfully converted to a new metric data type or can meaningfully be used to create new metrics.\n  - Although the OTTL allows the `set` function to be used with `metric.data_type`, its implementation in the transform processor is NOOP.  To modify a data type you must use a function specific to that purpose.\n- [Identity Conflict](https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/standard-warnings.md#identity-conflict): Transformation of metrics have the potential to affect the identity of a metric leading to an Identity Crisis. Be especially cautious when transforming metric name and when reducing/changing existing attributes.  Adding new attributes is safe.\n- [Orphaned Telemetry](https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/standard-warnings.md#orphaned-telemetry): The processor allows you to modify `span_id`, `trace_id`, and `parent_span_id` for traces and `span_id`, and `trace_id` logs.  Modifying these fields could lead to orphaned spans or logs.","properties":{"error_mode":{"description":"ErrorMode determines how the processor reacts to errors that occur while processing a statement.\nValid values are `ignore` and `propagate`.\n`ignore` means the processor ignores errors returned by statements and continues on to the next statement. This is the recommended mode.\n`propagate` means the processor returns the error up the pipeline.  This will result in the payload being dropped from the collector.\nThe default value is `propagate`.","title":"error_mode","type":"string"},"log_statements":{"items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.transformprocessor.internal.common.ContextStatements"},"title":"log_statements","type":"array"},"metric_statements":{"items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.transformprocessor.internal.common.ContextStatements"},"title":"metric_statements","type":"array"},"trace_statements":{"items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.transformprocessor.internal.common.ContextStatements"},"title":"trace_statements","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.processor.transformprocessor.internal.common.ContextStatements":{"additionalProperties":false,"properties":{"context":{"title":"context","type":"string"},"statements":{"items":{"type":"string"},"title":"statements","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.apachereceiver.Config":{"additionalProperties":false,"markdownDescription":"# Apache Web Server Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [contrib], [observiq], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThis receiver fetches stats from a Apache Web Server instance using the `server-status?auto` endpoint.\n\n## Prerequisites\n\nThis receiver supports Apache Web Server version 2.4+\n\n### mod_status module\n\nIn order to receive server statistics, you must configure the server's `httpd.conf` file to [enable status support](https://httpd.apache.org/docs/2.4/mod/mod_status.html).\n\n\n### Configuration\n\nThe following settings are required:\n- `endpoint` (default: `http://localhost:8080/server-status?auto`): The URL of the httpd status endpoint\n\nThe following settings are optional:\n- `collection_interval` (default = `10s`): This receiver collects metrics on an interval. This value must be a string readable by Golang's [time.ParseDuration](https://pkg.go.dev/time#ParseDuration). Valid time units are `ns`, `us` (or `Âµs`), `ms`, `s`, `m`, `h`.\n- `initial_delay` (default = `1s`): defines how long this receiver waits before starting.\n\n### Example Configuration\n\n```yaml\nreceivers:\n  apache:\n    endpoint: \"http://localhost:8080/server-status?auto\"\n```\n\nThe full list of settings exposed for this receiver are documented [here](./config.go) with detailed sample configurations [here](./testdata/config.yaml).\n\n## Metrics\n\nDetails about the metrics produced by this receiver can be found in [metadata.yaml](./metadata.yaml)","properties":{"CustomRoundTripper":{"description":"Custom Round Tripper to allow for individual components to intercept HTTP requests","title":"CustomRoundTripper"},"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth configuration for outgoing HTTP calls.","title":"auth"},"collection_interval":{"title":"collection_interval","type":"string"},"compression":{"description":"The compression key for supported compression types within collector.","title":"compression","type":"string"},"endpoint":{"description":"The target URL to send data to (e.g.: http://some.url:9411/v1/traces).","title":"endpoint","type":"string"},"headers":{"description":"Additional headers attached to each HTTP request sent by the client.\nExisting header values are overwritten if collision happens.\nHeader values are opaque since they may be sensitive.","patternProperties":{".*":{"type":"string"}},"title":"headers","type":"object"},"idle_conn_timeout":{"description":"IdleConnTimeout is the maximum amount of time a connection will remain open before closing itself.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"idle_conn_timeout","type":"string"},"initial_delay":{"title":"initial_delay","type":"string"},"max_conns_per_host":{"description":"MaxConnsPerHost limits the total number of connections per host, including connections in the dialing,\nactive, and idle states.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_conns_per_host","type":"integer"},"max_idle_conns":{"description":"MaxIdleConns is used to set a limit to the maximum idle HTTP connections the client can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns","type":"integer"},"max_idle_conns_per_host":{"description":"MaxIdleConnsPerHost is used to set a limit to the maximum idle HTTP connections the host can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns_per_host","type":"integer"},"metrics":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.apachereceiver.internal.metadata.MetricsConfig","title":"metrics"},"read_buffer_size":{"description":"ReadBufferSize for HTTP client. See http.Transport.ReadBufferSize.","title":"read_buffer_size","type":"integer"},"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.apachereceiver.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"},"timeout":{"description":"Timeout parameter configures `http.Client.Timeout`.","title":"timeout","type":"string"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","description":"TLSSetting struct exposes TLS client configuration.","title":"tls"},"write_buffer_size":{"description":"WriteBufferSize for HTTP client. See http.Transport.WriteBufferSize.","title":"write_buffer_size","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.apachereceiver.internal.metadata.MetricConfig":{"additionalProperties":false,"description":"MetricConfig provides common config for a particular metric.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.apachereceiver.internal.metadata.MetricsConfig":{"additionalProperties":false,"description":"MetricsConfig provides config for apache metrics.","properties":{"apache.cpu.load":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.apachereceiver.internal.metadata.MetricConfig","title":"apache.cpu.load"},"apache.cpu.time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.apachereceiver.internal.metadata.MetricConfig","title":"apache.cpu.time"},"apache.current_connections":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.apachereceiver.internal.metadata.MetricConfig","title":"apache.current_connections"},"apache.load.1":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.apachereceiver.internal.metadata.MetricConfig","title":"apache.load.1"},"apache.load.15":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.apachereceiver.internal.metadata.MetricConfig","title":"apache.load.15"},"apache.load.5":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.apachereceiver.internal.metadata.MetricConfig","title":"apache.load.5"},"apache.request.time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.apachereceiver.internal.metadata.MetricConfig","title":"apache.request.time"},"apache.requests":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.apachereceiver.internal.metadata.MetricConfig","title":"apache.requests"},"apache.scoreboard":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.apachereceiver.internal.metadata.MetricConfig","title":"apache.scoreboard"},"apache.traffic":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.apachereceiver.internal.metadata.MetricConfig","title":"apache.traffic"},"apache.uptime":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.apachereceiver.internal.metadata.MetricConfig","title":"apache.uptime"},"apache.workers":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.apachereceiver.internal.metadata.MetricConfig","title":"apache.workers"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.apachereceiver.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.apachereceiver.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for apache resource attributes.","properties":{"apache.server.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.apachereceiver.internal.metadata.ResourceAttributeConfig","title":"apache.server.name"},"apache.server.port":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.apachereceiver.internal.metadata.ResourceAttributeConfig","title":"apache.server.port"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.awscloudwatchreceiver.AutodiscoverConfig":{"additionalProperties":false,"description":"AutodiscoverConfig is the configuration for the autodiscovery functionality of log groups","properties":{"limit":{"title":"limit","type":"integer"},"prefix":{"title":"prefix","type":"string"},"streams":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.awscloudwatchreceiver.StreamConfig","title":"streams"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.awscloudwatchreceiver.Config":{"additionalProperties":false,"description":"Config is the overall config structure for the awscloudwatchreceiver","markdownDescription":"# Cloudwatch Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [alpha]: logs   |\n| Distributions | [contrib], [observiq], [sumo] |\n\n[alpha]: https://github.com/open-telemetry/opentelemetry-collector#alpha\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nReceives Cloudwatch events from [AWS Cloudwatch](https://aws.amazon.com/cloudwatch/) via the [AWS SDK for Cloudwatch Logs](https://docs.aws.amazon.com/sdk-for-go/api/service/cloudwatchlogs/)\n\n## Getting Started\n\nThis receiver uses the [AWS SDK](https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html) as mode of authentication, which includes [Credentials File](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html) and [IMDS](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html) authentication for EC2 instances.\n\n## Configuration\n\n### Top Level Parameters\n\n| Parameter       | Notes      | type   | Description                                                                                                                                                                                                                                                                       |\n| --------------- | ---------- | ------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `region`        | *required* | string | The AWS recognized region string                                                                                                                                                                                                                                                  |\n| `profile`       | *optional* | string | The AWS profile used to authenticate, if none is specified the default is chosen from the list of profiles                                                                                                                                                                        |\n| `imds_endpoint` | *optional* | string | A way of specifying a custom URL to be used by the EC2 IMDS client to validate the session. If unset, and the environment variable `AWS_EC2_METADATA_SERVICE_ENDPOINT` has a value the client will use the value of the environment variable as the endpoint for operation calls. |\n| `logs`          | *optional* | `Logs` | Configuration for Logs ingestion of this receiver                                                                                                                                                                                                                                 |\n\n### Logs Parameters\n\n| Parameter                | Notes        | type                   | Description                                                                                |\n| ------------------------ | ------------ | ---------------------- | ------------------------------------------------------------------------------------------ |\n| `poll_interval`          | `default=1m` | duration               | The duration waiting in between requests.                                                  |\n| `max_events_per_request` | `default=50` | int                    | The maximum number of events to process per request to Cloudwatch                          |\n| `groups`                 | *optional*   | `See Group Parameters` | Configuration for Log Groups, by default all Log Groups and Log Streams will be collected. |\n\n### Group Parameters\n\n`autodiscover` and `named` are ways to control and filter which log groups and log streams which are collected from. They are mutually exclusive and are incompatible to be configured at the same time.\n\n- `autodiscover`\n  - `limit`: (optional; default = 50) Limits the number of discovered log groups. This does not limit how large each API call to discover the log groups will be.\n  - `prefix`: (optional) A prefix for log groups to limit the number of log groups discovered.\n    - if omitted, all log streams up to the limit are collected from\n  - `streams`: (optional) If `streams` is omitted, then all streams will be attempted to retrieve events from.\n    - `names`: A list of full log stream names to filter the discovered log groups to collect from.\n    - `prefixes`: A list of prefixes to filter the discovered log groups to collect from.\n- `named`\n  - This is a map of log group name to stream filtering options\n    - `streams`: (optional)\n      - `names`: A list of full log stream names to filter the discovered log groups to collect from.\n      - `prefixes`: A list of prefixes to filter the discovered log groups to collect from.\n\n#### Autodiscovery Example Configuration\n\n```yaml\nawscloudwatch:\n  region: us-west-1\n  logs:\n    poll_interval: 1m\n    groups:\n      autodiscover:\n        limit: 100\n        prefix: /aws/eks/\n        streams:\n          prefixes: [kube-api-controller]\n```\n\n#### Named Example\n\n```yaml\nawscloudwatch:\n  region: us-west-1\n  logs:\n    poll_interval: 5m\n    groups:\n      named:\n        /aws/eks/dev-0/cluster: \n          names: [kube-apiserver-ea9c831555adca1815ae04b87661klasdj]\n```\n\n## Sample Configs\n\nThis receiver has a number of sample configs for reference.\n\n1. [Default](./testdata/sample-configs/default.yaml)\n\n    - Minimal configuration of the receiver\n    - Performs autodiscovery\n    - Collects all log groups and log streams\n\n2. [Autodiscover Filtering Log Groups](./testdata/sample-configs/autodiscover-filter-groups.yaml)\n\n    - Performs autodiscovery\n    - Only collects log groups matching a prefix\n    - Limits the number of discovered Log Groups\n\n3. [Autodiscover Filtering Log Streams](./testdata/sample-configs/autodiscover-filter-streams.yaml)\n\n   - Performs autodiscovery for all Log Groups\n   - Filters log streams\n\n4. [Named Groups](./testdata/sample-configs/named-prefix.yaml)\n\n   - Specifies and only collects from the desired Log Groups\n   - Does not attempt autodiscovery\n\n5. [Named Groups Filter Log Streams](./testdata/sample-configs/named-prefix-streams.yaml)\n\n   - Specifies the names of the log groups to collect\n   - Does not attempt autodiscovery\n   - Only collects from log streams matching a prefix","properties":{"imds_endpoint":{"title":"imds_endpoint","type":"string"},"logs":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.awscloudwatchreceiver.LogsConfig","title":"logs"},"profile":{"title":"profile","type":"string"},"region":{"title":"region","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.awscloudwatchreceiver.GroupConfig":{"additionalProperties":false,"description":"GroupConfig is the configuration for log group collection","properties":{"autodiscover":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.awscloudwatchreceiver.AutodiscoverConfig","title":"autodiscover"},"named":{"patternProperties":{".*":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.awscloudwatchreceiver.StreamConfig"}},"title":"named","type":"object"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.awscloudwatchreceiver.LogsConfig":{"additionalProperties":false,"description":"LogsConfig is the configuration for the logs portion of this receiver","properties":{"groups":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.awscloudwatchreceiver.GroupConfig","title":"groups"},"max_events_per_request":{"title":"max_events_per_request","type":"integer"},"poll_interval":{"title":"poll_interval","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.awscloudwatchreceiver.StreamConfig":{"additionalProperties":false,"description":"StreamConfig represents the configuration for the log stream filtering","properties":{"names":{"items":{"type":"string"},"title":"names","type":"array"},"prefixes":{"items":{"type":"string"},"title":"prefixes","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.awscontainerinsightreceiver.Config":{"additionalProperties":false,"description":"Config defines configuration for aws ecs container metrics receiver.","markdownDescription":"# AWS Container Insights Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [contrib], [aws], [observiq], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\n## Overview\n\nAWS Container Insights Receiver (`awscontainerinsightreceiver`) is an AWS specific receiver that supports [CloudWatch Container Insights](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/ContainerInsights.html). CloudWatch Container Insights collect, aggregate, \nand summarize metrics and logs from your containerized applications and microservices. Data are collected as as performance log events \nusing [embedded metric format](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Embedded_Metric_Format.html). From the EMF data, Amazon CloudWatch can create the aggregated CloudWatch metrics at the cluster, node, pod, task, and service level.\n\nCloudWatch Container Insights has been supported by [ECS Agent](https://github.com/aws/amazon-ecs-agent) and [CloudWatch Agent](https://github.com/aws/amazon-cloudwatch-agent) to collect infrastructure metrics for many resources such as such as CPU, memory, disk, and network. To migrate existing customers to use OpenTelemetry, AWS Container Insights Receiver (together with CloudWatch EMF Exporter) aims to support the same CloudWatch Container Insights experience for the following platforms:  \n  * Amazon ECS \n  * Amazon EKS\n  * Kubernetes platforms on Amazon EC2\n\n## Design of AWS Container Insights Receiver\n\nSee the [design doc](./design.md)\n\n## Configuration\nExample configuration:\n```\nreceivers:\n  awscontainerinsightreceiver:\n    # all parameters are optional\n    collection_interval: 60s\n    container_orchestrator: eks\n    add_service_as_attribute: true \n    prefer_full_pod_name: false \n    add_full_pod_name_metric_label: false \n```\nThere is no need to provide any parameters since they are all optional. \n\n**collection_interval (optional)**\n\nThe interval at which metrics should be collected. The default is 60 second.\n\n**container_orchestrator (optional)**\n\nThe type of container orchestration service, e.g. eks or ecs. The default is eks.\n\n**add_service_as_attribute (optional)**\n\nWhether to add the associated service name as attribute. The default is true\n\n**prefer_full_pod_name (optional)**\n\nThe \"PodName\" attribute is set based on the name of the relevant controllers like Daemonset, Job, ReplicaSet, ReplicationController, ... If it can not be set that way and PrefFullPodName is true, the \"PodName\" attribute is set to the pod's own name. The default value is false.\n\n**add_full_pod_name_metric_label (optional)**\n\nThe \"FullPodName\" attribute is the pod name including suffix. If false FullPodName label is not added. The default value is false\n\n## Sample configuration for Container Insights \nThis is a sample configuration for AWS Container Insights using the `awscontainerinsightreceiver` and `awsemfexporter` for an EKS cluster:\n```\n# create namespace\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: aws-otel-eks\n  labels:\n    name: aws-otel-eks\n\n---\n# create cwagent service account and role binding\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: aws-otel-sa\n  namespace: aws-otel-eks\n\n---\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: aoc-agent-role\nrules:\n  - apiGroups: [\"\"]\n    resources: [\"pods\", \"nodes\", \"endpoints\"]\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"apps\"]\n    resources: [\"replicasets\"]\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"batch\"]\n    resources: [\"jobs\"]\n    verbs: [\"list\", \"watch\"]\n  - apiGroups: [\"\"]\n    resources: [\"nodes/proxy\"]\n    verbs: [\"get\"]\n  - apiGroups: [\"\"]\n    resources: [\"nodes/stats\", \"configmaps\", \"events\"]\n    verbs: [\"create\", \"get\"]\n  - apiGroups: [\"\"]\n    resources: [\"configmaps\"]\n    resourceNames: [\"otel-container-insight-clusterleader\"]\n    verbs: [\"get\",\"update\"]\n\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: aoc-agent-role-binding\nsubjects:\n  - kind: ServiceAccount\n    name: aws-otel-sa\n    namespace: aws-otel-eks\nroleRef:\n  kind: ClusterRole\n  name: aoc-agent-role\n  apiGroup: rbac.authorization.k8s.io\n\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: otel-agent-conf\n  namespace: aws-otel-eks\n  labels:\n    app: opentelemetry\n    component: otel-agent-conf\ndata:\n  otel-agent-config: |\n    extensions:\n      health_check:\n\n    receivers:\n      awscontainerinsightreceiver:\n\n    processors:\n      batch/metrics:\n        timeout: 60s\n\n    exporters:\n      awsemf:\n        namespace: ContainerInsights\n        log_group_name: '/aws/containerinsights/{ClusterName}/performance'\n        log_stream_name: '{NodeName}'\n        resource_to_telemetry_conversion:\n          enabled: true\n        dimension_rollup_option: NoDimensionRollup\n        parse_json_encoded_attr_values: [Sources, kubernetes]\n        metric_declarations:\n          # node metrics\n          - dimensions: [[NodeName, InstanceId, ClusterName]]\n            metric_name_selectors:\n              - node_cpu_utilization\n              - node_memory_utilization\n              - node_network_total_bytes\n              - node_cpu_reserved_capacity\n              - node_memory_reserved_capacity\n              - node_number_of_running_pods\n              - node_number_of_running_containers\n          - dimensions: [[ClusterName]]\n            metric_name_selectors:\n              - node_cpu_utilization\n              - node_memory_utilization\n              - node_network_total_bytes\n              - node_cpu_reserved_capacity\n              - node_memory_reserved_capacity\n              - node_number_of_running_pods\n              - node_number_of_running_containers\n              - node_cpu_usage_total\n              - node_cpu_limit\n              - node_memory_working_set\n              - node_memory_limit\n\n          # pod metrics\n          - dimensions: [[PodName, Namespace, ClusterName], [Service, Namespace, ClusterName], [Namespace, ClusterName], [ClusterName]]\n            metric_name_selectors:\n              - pod_cpu_utilization\n              - pod_memory_utilization\n              - pod_network_rx_bytes\n              - pod_network_tx_bytes\n              - pod_cpu_utilization_over_pod_limit\n              - pod_memory_utilization_over_pod_limit\n          - dimensions: [[PodName, Namespace, ClusterName], [ClusterName]]\n            metric_name_selectors:\n              - pod_cpu_reserved_capacity\n              - pod_memory_reserved_capacity\n          - dimensions: [[PodName, Namespace, ClusterName]]\n            metric_name_selectors:\n              - pod_number_of_container_restarts\n\n          # cluster metrics\n          - dimensions: [[ClusterName]]\n            metric_name_selectors:\n              - cluster_node_count\n              - cluster_failed_node_count\n\n          # service metrics\n          - dimensions: [[Service, Namespace, ClusterName], [ClusterName]]\n            metric_name_selectors:\n              - service_number_of_running_pods\n\n          # node fs metrics\n          - dimensions: [[NodeName, InstanceId, ClusterName], [ClusterName]]\n            metric_name_selectors:\n              - node_filesystem_utilization\n\n          # namespace metrics\n          - dimensions: [[Namespace, ClusterName], [ClusterName]]\n            metric_name_selectors:\n              - namespace_number_of_running_pods\n\n\n      logging:\n        loglevel: debug\n\n    service:\n      pipelines:\n        metrics:\n          receivers: [awscontainerinsightreceiver]\n          processors: [batch/metrics]\n          exporters: [awsemf]\n\n      extensions: [health_check]\n\n---\n# create Daemonset\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: aws-otel-eks-ci\n  namespace: aws-otel-eks\nspec:\n  selector:\n    matchLabels:\n      name: aws-otel-eks-ci\n  template:\n    metadata:\n      labels:\n        name: aws-otel-eks-ci\n    spec:\n      containers:\n        - name: aws-otel-collector\n          image: {collector-image-url}\n          env:\n            #- name: AWS_REGION\n            #  value: \"us-east-1\"\n            - name: K8S_NODE_NAME\n              valueFrom:\n                fieldRef:\n                  fieldPath: spec.nodeName\n            - name: HOST_IP\n              valueFrom:\n                fieldRef:\n                  fieldPath: status.hostIP\n            - name: HOST_NAME\n              valueFrom:\n                fieldRef:\n                  fieldPath: spec.nodeName\n            - name: K8S_NAMESPACE\n              valueFrom:\n                 fieldRef:\n                   fieldPath: metadata.namespace\n          imagePullPolicy: Always\n          command:\n            - \"/awscollector\"\n            - \"--config=/conf/otel-agent-config.yaml\"\n          volumeMounts:\n            - name: rootfs\n              mountPath: /rootfs\n              readOnly: true\n            - name: dockersock\n              mountPath: /var/run/docker.sock\n              readOnly: true\n            - name: varlibdocker\n              mountPath: /var/lib/docker\n              readOnly: true\n            - name: containerdsock\n              mountPath: /run/containerd/containerd.sock\n              readOnly: true\n            - name: sys\n              mountPath: /sys\n              readOnly: true\n            - name: devdisk\n              mountPath: /dev/disk\n              readOnly: true\n            - name: otel-agent-config-vol\n              mountPath: /conf\n          resources:\n            limits:\n              cpu:  200m\n              memory: 200Mi\n            requests:\n              cpu: 200m\n              memory: 200Mi\n      volumes:\n        - configMap:\n            name: otel-agent-conf\n            items:\n              - key: otel-agent-config\n                path: otel-agent-config.yaml\n          name: otel-agent-config-vol\n        - name: rootfs\n          hostPath:\n            path: /\n        - name: dockersock\n          hostPath:\n            path: /var/run/docker.sock\n        - name: varlibdocker\n          hostPath:\n            path: /var/lib/docker\n        - name: containerdsock\n          hostPath:\n            path: /run/containerd/containerd.sock\n        - name: sys\n          hostPath:\n            path: /sys\n        - name: devdisk\n          hostPath:\n            path: /dev/disk/\n      serviceAccountName: aws-otel-sa\n```\n\nTo deploy to an EKS cluster\n```\nkubectl apply -f config.yaml\n```\n\n## Available Metrics and Resource Attributes\n### Cluster\n| Metric                    | Unit  |\n|---------------------------|-------|\n| cluster_failed_node_count | Count |\n| cluster_node_count        | Count |\n\n\u003cbr/\u003e\u003cbr/\u003e \n| Resource Attribute |\n|--------------------|\n| ClusterName        |\n| NodeName           |\n| Type               |\n| Timestamp          |\n| Version            |\n| Sources            |\n\n\u003cbr/\u003e\u003cbr/\u003e \n\u003cbr/\u003e\u003cbr/\u003e \n\n### Cluster Namespace\n| Metric                           | Unit  |\n|----------------------------------|-------|\n| namespace_number_of_running_pods | Count |\n\n\u003cbr/\u003e\u003cbr/\u003e \n| Resource Attribute |\n|--------------------|\n| ClusterName        |\n| NodeName           |\n| Namespace          |\n| Type               |\n| Timestamp          |\n| Version            |\n| Sources            |\n| kubernete          |\n\n\u003cbr/\u003e\u003cbr/\u003e \n\u003cbr/\u003e\u003cbr/\u003e \n\n### Cluster Service\n| Metric                         | Unit  |\n|--------------------------------|-------|\n| service_number_of_running_pods | Count |\n\n\n\u003cbr/\u003e\u003cbr/\u003e \n| Resource Attribute |\n|--------------------|\n| ClusterName        |\n| NodeName           |\n| Namespace          |\n| Service            |\n| Type               |\n| Timestamp          |\n| Version            |\n| Sources            |\n| kubernete          |\n\n\n\u003cbr/\u003e\u003cbr/\u003e \n\u003cbr/\u003e\u003cbr/\u003e \n\n### Node\n| Metric                              | Unit          |\n|-------------------------------------|---------------|\n| node_cpu_limit                      | Millicore     |\n| node_cpu_request                    | Millicore     |\n| node_cpu_reserved_capacity          | Percent       |\n| node_cpu_usage_system               | Millicore     |\n| node_cpu_usage_total                | Millicore     |\n| node_cpu_usage_user                 | Millicore     |\n| node_cpu_utilization                | Percent       |\n| node_memory_cache                   | Bytes         |\n| node_memory_failcnt                 | Count         |\n| node_memory_hierarchical_pgfault    | Count/Second  |\n| node_memory_hierarchical_pgmajfault | Count/Second  |\n| node_memory_limit                   | Bytes         |\n| node_memory_mapped_file             | Bytes         |\n| node_memory_max_usage               | Bytes         |\n| node_memory_pgfault                 | Count/Second  |\n| node_memory_pgmajfault              | Count/Second  |\n| node_memory_request                 | Bytes         |\n| node_memory_reserved_capacity       | Percent       |\n| node_memory_rss                     | Bytes         |\n| node_memory_swap                    | Bytes         |\n| node_memory_usage                   | Bytes         |\n| node_memory_utilization             | Percent       |\n| node_memory_working_set             | Bytes         |\n| node_network_rx_bytes               | Bytes/Second  |\n| node_network_rx_dropped             | Count/Second  |\n| node_network_rx_errors              | Count/Second  |\n| node_network_rx_packets             | Count/Second  |\n| node_network_total_bytes            | Bytes/Second  |\n| node_network_tx_bytes               | Bytes/Second  |\n| node_network_tx_dropped             | Count/Second  |\n| node_network_tx_errors              | Count/Second  |\n| node_network_tx_packets             | Count/Second  |\n| node_number_of_running_containers   | Count         |\n| node_number_of_running_pods         | Count         |\n\n\u003cbr/\u003e\u003cbr/\u003e \n| Resource Attribute   |\n|----------------------|\n| ClusterName          |\n| InstanceType         |\n| NodeName             |\n| Timestamp            |\n| Type                 |\n| Version              |\n| Sources              |\n| kubernete            |\n\n\u003cbr/\u003e\u003cbr/\u003e \n\u003cbr/\u003e\u003cbr/\u003e \n\n### Node Disk IO\n| Metric                             | Unit          |\n|------------------------------------|---------------|\n| node_diskio_io_serviced_async      | Count/Second  |\n| node_diskio_io_serviced_read       | Count/Second  |\n| node_diskio_io_serviced_sync       | Count/Second  |\n| node_diskio_io_serviced_total      | Count/Second  |\n| node_diskio_io_serviced_write      | Count/Second  |\n| node_diskio_io_service_bytes_async | Bytes/Second  |\n| node_diskio_io_service_bytes_read  | Bytes/Second  |\n| node_diskio_io_service_bytes_sync  | Bytes/Second  |\n| node_diskio_io_service_bytes_total | Bytes/Second  |\n| node_diskio_io_service_bytes_write | Bytes/Second  |\n\n\u003cbr/\u003e\u003cbr/\u003e \n| Resource Attribute   |\n|----------------------|\n| AutoScalingGroupName |\n| ClusterName          |\n| InstanceId           |\n| InstanceType         |\n| NodeName             |\n| Timestamp            |\n| EBSVolumeId          |\n| device               |\n| Type                 |\n| Version              |\n| Sources              |\n| kubernete            |\n\u003cbr/\u003e\u003cbr/\u003e \n\u003cbr/\u003e\u003cbr/\u003e \n\n### Node Filesystem\n| Metric                      | Unit    |\n|-----------------------------|---------|\n| node_filesystem_available   | Bytes   |\n| node_filesystem_capacity    | Bytes   |\n| node_filesystem_inodes      | Count   |\n| node_filesystem_inodes_free | Count   |\n| node_filesystem_usage       | Bytes   |\n| node_filesystem_utilization | Percent |\n\n\u003cbr/\u003e\u003cbr/\u003e \n| Resource Attribute   |\n|----------------------|\n| AutoScalingGroupName |\n| ClusterName          |\n| InstanceId           |\n| InstanceType         |\n| NodeName             |\n| Timestamp            |\n| EBSVolumeId          |\n| device               |\n| fstype               |\n| Type                 |\n| Version              |\n| Sources              |\n| kubernete            |\n\u003cbr/\u003e\u003cbr/\u003e \n\u003cbr/\u003e\u003cbr/\u003e \n\n### Node Network\n| Metric                             | Unit         |\n|------------------------------------|--------------|\n| node_interface_network_rx_bytes    | Bytes/Second |\n| node_interface_network_rx_dropped  | Count/Second |\n| node_interface_network_rx_errors   | Count/Second |\n| node_interface_network_rx_packets  | Count/Second |\n| node_interface_network_total_bytes | Bytes/Second |\n| node_interface_network_tx_bytes    | Bytes/Second |\n| node_interface_network_tx_dropped  | Count/Second |\n| node_interface_network_tx_errors   | Count/Second |\n| node_interface_network_tx_packets  | Count/Second |\n\n\u003cbr/\u003e\u003cbr/\u003e \n| Resource Attribute   |\n|----------------------|\n| AutoScalingGroupName |\n| ClusterName          |\n| InstanceId           |\n| InstanceType         |\n| NodeName             |\n| Timestamp            |\n| Type                 |\n| Version              |\n| interface            |\n| Sources              |\n| kubernete            |\n\u003cbr/\u003e\u003cbr/\u003e \n\u003cbr/\u003e\u003cbr/\u003e \n\n### Pod\n| Metric                                | Unit          |\n|---------------------------------------|---------------|\n| pod_cpu_limit                         | Millicore     |\n| pod_cpu_request                       | Millicore     |\n| pod_cpu_reserved_capacity             | Percent       |\n| pod_cpu_usage_system                  | Millicore     |\n| pod_cpu_usage_total                   | Millicore     |\n| pod_cpu_usage_user                    | Millicore     |\n| pod_cpu_utilization                   | Percent       |\n| pod_cpu_utilization_over_pod_limit    | Percent       |\n| pod_memory_cache                      | Bytes         |\n| pod_memory_failcnt                    | Count         |\n| pod_memory_hierarchical_pgfault       | Count/Second  |\n| pod_memory_hierarchical_pgmajfault    | Count/Second  |\n| pod_memory_limit                      | Bytes         |\n| pod_memory_mapped_file                | Bytes         |\n| pod_memory_max_usage                  | Bytes         |\n| pod_memory_pgfault                    | Count/Second  |\n| pod_memory_pgmajfault                 | Count/Second  |\n| pod_memory_request                    | Bytes         |\n| pod_memory_reserved_capacity          | Percent       |\n| pod_memory_rss                        | Bytes         |\n| pod_memory_swap                       | Bytes         |\n| pod_memory_usage                      | Bytes         |\n| pod_memory_utilization                | Percent       |\n| pod_memory_utilization_over_pod_limit | Percent       |\n| pod_memory_working_set                | Bytes         |\n| pod_network_rx_bytes                  | Bytes/Second  |\n| pod_network_rx_dropped                | Count/Second  |\n| pod_network_rx_errors                 | Count/Second  |\n| pod_network_rx_packets                | Count/Second  |\n| pod_network_total_bytes               | Bytes/Second  |\n| pod_network_tx_bytes                  | Bytes/Second  |\n| pod_network_tx_dropped                | Count/Second  |\n| pod_network_tx_errors                 | Count/Second  |\n| pod_network_tx_packets                | Count/Second  |\n| pod_number_of_container_restarts      | Count         | \n| pod_number_of_containers              | Count         |   \n| pod_number_of_running_containers      | Count         |  \n\n| Resource Attribute   |\n|----------------------|\n| AutoScalingGroupName |\n| ClusterName          |\n| InstanceId           |\n| InstanceType         |\n| K8sPodName           |\n| Namespace            |\n| NodeName             |\n| PodId                |\n| Timestamp            |\n| Type                 |\n| Version              |\n| Sources              |\n| kubernete            |\n| pod_status           |\n\n\u003cbr/\u003e\u003cbr/\u003e \n\n### Pod Network\n| Metric                             | Unit         |\n|------------------------------------|--------------|\n| pod_interface_network_rx_bytes     | Bytes/Second |\n| pod_interface_network_rx_dropped   | Count/Second |\n| pod_interface_network_rx_errors    | Count/Second |\n| pod_interface_network_rx_packets   | Count/Second |\n| pod_interface_network_total_bytes  | Bytes/Second |\n| pod_interface_network_tx_bytes     | Bytes/Second |\n| pod_interface_network_tx_dropped   | Count/Second |\n| pod_interface_network_tx_errors    | Count/Second |\n| pod_interface_network_tx_packets   | Count/Second |\n\n\u003cbr/\u003e\u003cbr/\u003e \n| Resource Attribute   |\n|----------------------|\n| AutoScalingGroupName |\n| ClusterName          |\n| InstanceId           |\n| InstanceType         |\n| K8sPodName           |\n| Namespace            |\n| NodeName             |\n| PodId                |\n| Timestamp            |\n| Type                 |\n| Version              |\n| interface            |\n| Sources              |\n| kubernete            |\n| pod_status           |\n\u003cbr/\u003e\u003cbr/\u003e \n\u003cbr/\u003e\u003cbr/\u003e \n\n\n### Container\n| Metric                                  | Unit          |\n|-----------------------------------------|---------------|\n| container_cpu_limit                     | Millicore     |\n| container_cpu_request                   | Millicore     |\n| container_cpu_usage_system              | Millicore     |\n| container_cpu_usage_total               | Millicore     |\n| container_cpu_usage_user                | Millicore     |\n| container_cpu_utilization               | Percent       |\n| container_memory_cache                  | Bytes         |\n| container_memory_failcnt                | Count         |\n| container_memory_hierarchical_pgfault   | Count/Second  |\n| container_memory_hierarchical_pgmajfault| Count/Second  |\n| container_memory_limit                  | Bytes         |\n| container_memory_mapped_file            | Bytes         |\n| container_memory_max_usage              | Bytes         |\n| container_memory_pgfault                | Count/Second  |\n| container_memory_pgmajfault             | Count/Second  |\n| container_memory_request                | Bytes         |\n| container_memory_rss                    | Bytes         |\n| container_memory_swap                   | Bytes         |\n| container_memory_usage                  | Bytes         |\n| container_memory_utilization            | Percent       |\n| container_memory_working_set            | Bytes         |\n| number_of_container_restarts            | Count         |\n\n\u003cbr/\u003e\u003cbr/\u003e \n\n| Resource Attribute                |\n|-----------------------------------|\n| AutoScalingGroupName              |\n| ClusterName                       |\n| ContainerId                       |\n| ContainerName                     |\n| InstanceId                        |\n| InstanceType                      |\n| K8sPodName                        |\n| Namespace                         |\n| NodeName                          |\n| PodId                             |\n| Timestamp                         |\n| Type                              |\n| Version                           |\n| Sources                           |\n| kubernetes                        |\n| container_status                  |\n| container_status_reason           |\n| container_last_termination_reason | \n\nThe attribute `container_status_reason` is present only when `container_status` is in \"Waiting\" or \"Terminated\" State. The attribute `container_last_termination_reason` is present only when `container_status` is in \"Terminated\" State.\n\nThis is a sample configuration for AWS Container Insights using the `awscontainerinsightreceiver` and `awsemfexporter` for an ECS cluster to collect the instance level metrics:\n```\nreceivers:\n  awscontainerinsightreceiver:\n    collection_interval: 10s\n    container_orchestrator: ecs\n\nprocessors:\n  batch/metrics:\n    timeout: 60s\n\nexporters:\n  awsemf:\n    namespace: ContainerInsightsEC2Instance\n    log_group_name: '/aws/ecs/containerinsights/{ClusterName}/performance'\n    log_stream_name: 'instanceTelemetry/{ContainerInstanceId}'\n    resource_to_telemetry_conversion:\n      enabled: true\n    dimension_rollup_option: NoDimensionRollup\n    parse_json_encoded_attr_values: [Sources]\n    metric_declarations:\n      # instance metrics\n      - dimensions: [ [ ContainerInstanceId, InstanceId, ClusterName] ]\n        metric_name_selectors:\n          - instance_cpu_utilization\n          - instance_memory_utilization\n          - instance_network_total_bytes\n          - instance_cpu_reserved_capacity\n          - instance_memory_reserved_capacity\n          - instance_number_of_running_tasks\n          - instance_filesystem_utilization\n      - dimensions: [ [ClusterName] ]\n        metric_name_selectors:\n          - instance_cpu_utilization\n          - instance_memory_utilization\n          - instance_network_total_bytes\n          - instance_cpu_reserved_capacity\n          - instance_memory_reserved_capacity\n          - instance_number_of_running_tasks\n          - instance_cpu_usage_total\n          - instance_cpu_limit\n          - instance_memory_working_set\n          - instance_memory_limit\n  logging:\n    loglevel: debug\nservice:\n  pipelines:\n    metrics:\n      receivers: [awscontainerinsightreceiver]\n      processors: [batch/metrics]\n      exporters: [awsemf,logging]\n```\nTo deploy to an ECS cluster check this [doc](https://aws-otel.github.io/docs/setup/ecs#3-setup-the-aws-otel-collector-for-ecs-ec2-instance-metrics) for details\n\n## Available Metrics and Resource Attributes\n### Instance\n| Metric                                  | Unit          |\n|-----------------------------------------|---------------|\n| instance_cpu_limit                      | Millicore     |\n| instance_cpu_reserved_capacity          | Percent       |\n| instance_cpu_usage_system               | Millicore     |\n| instance_cpu_usage_total                | Millicore     |\n| instance_cpu_usage_user                 | Millicore     |\n| instance_cpu_utilization                | Percent       |\n| instance_memory_cache                   | Bytes         |\n| instance_memory_failcnt                 | Count         |\n| instance_memory_hierarchical_pgfault    | Count/Second  |\n| instance_memory_hierarchical_pgmajfault | Count/Second  |\n| instance_memory_limit                   | Bytes         |\n| instance_memory_mapped_file             | Bytes         |\n| instance_memory_max_usage               | Bytes         |\n| instance_memory_pgfault                 | Count/Second  |\n| instance_memory_pgmajfault              | Count/Second  |\n| instance_memory_reserved_capacity       | Percent       |\n| instance_memory_rss                     | Bytes         |\n| instance_memory_swap                    | Bytes         |\n| instance_memory_usage                   | Bytes         |\n| instance_memory_utilization             | Percent       |\n| instance_memory_working_set             | Bytes         |\n| instance_network_rx_bytes               | Bytes/Second  |\n| instance_network_rx_dropped             | Count/Second  |\n| instance_network_rx_errors              | Count/Second  |\n| instance_network_rx_packets             | Count/Second  |\n| instance_network_total_bytes            | Bytes/Second  |\n| instance_network_tx_bytes               | Bytes/Second  |\n| instance_network_tx_dropped             | Count/Second  |\n| instance_network_tx_errors              | Count/Second  |\n| instance_network_tx_packets             | Count/Second  |\n| instance_number_of_running_tasks        | Count         |\n\u003cbr/\u003e\u003cbr/\u003e\n\n| Resource Attribute   |\n|----------------------|\n| ClusterName          |\n| InstanceType         |\n| AutoScalingGroupName |\n| Timestamp            |\n| Type                 |\n| Version              |\n| Sources              |\n| ContainerInstanceId  |\n| InstanceId           |\n\n\u003cbr/\u003e\u003cbr/\u003e\n\u003cbr/\u003e\u003cbr/\u003e\n\n### Instance Disk IO\n| Metric                                 | Unit          |\n|----------------------------------------|---------------|\n| instance_diskio_io_serviced_async      | Count/Second  |\n| instance_diskio_io_serviced_read       | Count/Second  |\n| instance_diskio_io_serviced_sync       | Count/Second  |\n| instance_diskio_io_serviced_total      | Count/Second  |\n| instance_diskio_io_serviced_write      | Count/Second  |\n| instance_diskio_io_service_bytes_async | Bytes/Second  |\n| instance_diskio_io_service_bytes_read  | Bytes/Second  |\n| instance_diskio_io_service_bytes_sync  | Bytes/Second  |\n| instance_diskio_io_service_bytes_total | Bytes/Second  |\n| instance_diskio_io_service_bytes_write | Bytes/Second  |\n\n\u003cbr/\u003e\u003cbr/\u003e\n\n| Resource Attribute   |\n|----------------------|\n| ClusterName          |\n| InstanceType         |\n| AutoScalingGroupName |\n| Timestamp            |\n| Type                 |\n| Version              |\n| Sources              |\n| ContainerInstanceId  |\n| InstanceId           |\n| EBSVolumeId          |\n\n\u003cbr/\u003e\u003cbr/\u003e\n\u003cbr/\u003e\u003cbr/\u003e\n\n### Instance Filesystem\n| Metric                          | Unit    |\n|---------------------------------|---------|\n| instance_filesystem_available   | Bytes   |\n| instance_filesystem_capacity    | Bytes   |\n| instance_filesystem_inodes      | Count   |\n| instance_filesystem_inodes_free | Count   |\n| instance_filesystem_usage       | Bytes   |\n| instance_filesystem_utilization | Percent |\n\n\u003cbr/\u003e\u003cbr/\u003e\n| Resource Attribute   |\n|----------------------|\n| ClusterName          |\n| InstanceType         |\n| AutoScalingGroupName |\n| Timestamp            |\n| Type                 |\n| Version              |\n| Sources              |\n| ContainerInstanceId  |\n| InstanceId           |\n| EBSVolumeId          |\n\u003cbr/\u003e\u003cbr/\u003e\n\u003cbr/\u003e\u003cbr/\u003e\n\n### Instance Network\n| Metric                                 | Unit         |\n|----------------------------------------|--------------|\n| instance_interface_network_rx_bytes    | Bytes/Second |\n| instance_interface_network_rx_dropped  | Count/Second |\n| instance_interface_network_rx_errors   | Count/Second |\n| instance_interface_network_rx_packets  | Count/Second |\n| instance_interface_network_total_bytes | Bytes/Second |\n| instance_interface_network_tx_bytes    | Bytes/Second |\n| instance_interface_network_tx_dropped  | Count/Second |\n| instance_interface_network_tx_errors   | Count/Second |\n| instance_interface_network_tx_packets  | Count/Second |\n\n\u003cbr/\u003e\u003cbr/\u003e\n| Resource Attribute   |\n|----------------------|\n| ClusterName          |\n| InstanceType         |\n| AutoScalingGroupName |\n| Timestamp            |\n| Type                 |\n| Version              |\n| Sources              |\n| ContainerInstanceId  |\n| InstanceId           |\n| EBSVolumeId          |\n\u003cbr/\u003e\u003cbr/\u003e\n\u003cbr/\u003e\u003cbr/\u003e","properties":{"add_full_pod_name_metric_label":{"description":"The \"FullPodName\" attribute is the pod name including suffix\nIf false FullPodName label is not added\nThe default value is false","title":"add_full_pod_name_metric_label","type":"boolean"},"add_service_as_attribute":{"description":"Whether to add the associated service name as attribute. The default is true","title":"add_service_as_attribute","type":"boolean"},"collection_interval":{"description":"CollectionInterval is the interval at which metrics should be collected. The default is 60 second.","title":"collection_interval","type":"string"},"container_orchestrator":{"description":"ContainerOrchestrator is the type of container orchestration service, e.g. eks or ecs. The default is eks.","title":"container_orchestrator","type":"string"},"prefer_full_pod_name":{"description":"The \"PodName\" attribute is set based on the name of the relevant controllers like Daemonset, Job, ReplicaSet, ReplicationController, ...\nIf it can not be set that way and PrefFullPodName is true, the \"PodName\" attribute is set to the pod's own name.\nThe default value is false","title":"prefer_full_pod_name","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.awsecscontainermetricsreceiver.Config":{"additionalProperties":false,"description":"Config defines configuration for aws ecs container metrics receiver.","markdownDescription":"# AWS ECS Container Metrics Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [contrib], [aws], [observiq], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\n## Overview\n\nAWS ECS Container Metrics Receiver (`awsecscontainermetrics`) reads task metadata and [docker stats](https://docs.docker.com/engine/api/v1.30/#operation/ContainerStats) from [Amazon ECS Task Metadata Endpoint](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-metadata-endpoint.html), and generates resource usage metrics (such as CPU, memory, network, and disk) from them. To get the full list of metrics, see the [Available Metrics](#available-metrics) section below.\n\nThis receiver works only for [ECS Task Metadata Endpoint V4](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task-metadata-endpoint-v4.html). Amazon ECS tasks on Fargate that use platform version 1.4.0 or later and Amazon ECS tasks on Amazon EC2 that are running at least version 1.39.0 of the Amazon ECS container agent can utilize this receiver. For more information, see [Amazon ECS Container Agent Versions](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-versions.html).\n\n\n## Configuration\n\nExample:\n\n```yaml\nreceivers:\n  awsecscontainermetrics:\n    collection_interval: 20s\n```\n\n#### collection_interval:\n\nThis receiver collects task metadata and container stats at a fixed interval and emits metrics to the next consumer of OpenTelemetry pipeline. `collection_interval` will determine the frequency at which metrics are collected and emitted by this receiver.\n\ndefault: `20s`\n\n\n## Enabling the AWS ECS Container Metrics Receiver\n\nTo enable the awsecscontainermetrics receiver, add the name under receiver section in the OpenTelemetry config file. By default, the receiver scrapes the ECS task metadata endpoint every 20s and collects all metrics (For the full list of metrics, see [Available Metrics](#available-metrics)).\n\nThe following configuration collects AWS ECS resource usage metrics by using `awsecscontainermetrics` receiver and sends them to CloudWatch using `awsemf` exporter. Check out [SETUP](https://aws-otel.github.io/docs/setup/ecs) section for configuring AWS Distro for OpenTelemetry Collector in Amazon Elastic Container Service.\n\n```yaml\nreceivers:\n  awsecscontainermetrics:\nexporters:\n  awsemf:\n      namespace: 'ECS/ContainerMetrics/OpenTelemetry'\n      log_group_name: '/ecs/containermetrics/opentelemetry'\n\nservice:\n  pipelines:\n      metrics:\n          receivers: [awsecscontainermetrics]\n          exporters: [awsemf]\n```\n\n## Set Metrics Collection Interval\n\nCustomers can configure `collection_interval` under `awsecscontainermetrics` receiver to scrape and gather metrics at a specific interval. The following example configuration will collect metrics every 40 seconds.\n\n```yaml\nreceivers:\n  awsecscontainermetrics:\n      collection_interval: 40s\nexporters:\n  awsemf:\n      namespace: 'ECS/ContainerMetrics/OpenTelemetry'\n      log_group_name: '/ecs/containermetrics/opentelemetry'\n\nservice:\n  pipelines:\n      metrics:\n          receivers: [awsecscontainermetrics]\n          exporters: [awsemf]\n```\n\n## Collect specific metrics and update metric names\n\nThe previous configurations collect all the metrics and sends them to Amazon CloudWatch using default names. Customers can use `filter` and `metrictransform` processors to send specific metrics and rename them respectively.\n\nThe following configuration example collects only the `ecs.task.memory.utilized` metric and renames it to `MemoryUtilized` before sending to CloudWatch.\n\n```yaml\nreceivers:\n  awsecscontainermetrics:\nexporters:\n  awsemf:\n      namespace: 'ECS/ContainerMetrics/OpenTelemetry'\n      log_group_name: '/ecs/containermetrics/opentelemetry'\nprocessors:\n  filter:\n    metrics:\n      include:\n        match_type: strict\n        metric_names:\n          - ecs.task.memory.utilized\n\n  metricstransform:\n    transforms:\n      - include: ecs.task.memory.utilized\n        action: update\n        new_name: MemoryUtilized\n\nservice:\n  pipelines:\n      metrics:\n          receivers: [awsecscontainermetrics]\n          processors: [filter, metricstransform]\n          exporters: [awsemf]\n```\n\n## Available Metrics\nFollowing is the full list of metrics emitted by this receiver.\n\nTask Level Metrics | Container Level Metrics | Unit \n------------ | ------------- | --------------------\necs.task.memory.usage | container.memory.usage | Bytes\necs.task.memory.usage.max | container.memory.usage.max | Bytes\necs.task.memory.usage.limit | container.memory.usage.limit | Bytes\necs.task.memory.reserved | container.memory.reserved | Megabytes\necs.task.memory.utilized | container.memory.utilized | Megabytes\necs.task.cpu.usage.total | container.cpu.usage.total | Nanoseconds\necs.task.cpu.usage.kernelmode | container.cpu.usage.kernelmode | Nanoseconds\necs.task.cpu.usage.usermode | container.cpu.usage.usermode | Nanoseconds\necs.task.cpu.usage.system | container.cpu.usage.system | Nanoseconds\necs.task.cpu.usage.vcpu | container.cpu.usage.vcpu | vCPU\necs.task.cpu.cores | container.cpu.cores | Count\necs.task.cpu.onlines | container.cpu.onlines | Count\necs.task.cpu.reserved | container.cpu.reserved | vCPU\necs.task.cpu.utilized | container.cpu.utilized | Percent\necs.task.network.rate.rx\t| container.network.rate.rx\t| Bytes/Second\necs.task.network.rate.tx\t| container.network.rate.tx\t| Bytes/Second\necs.task.network.io.usage.rx_bytes\t| container.network.io.usage.rx_bytes\t| Bytes\necs.task.network.io.usage.rx_packets\t| container.network.io.usage.rx_packets\t| Count\necs.task.network.io.usage.rx_errors |\tcontainer.network.io.usage.rx_errors\t| Count\necs.task.network.io.usage.rx_dropped |\tcontainer.network.io.usage.rx_dropped\t| Count\necs.task.network.io.usage.tx_bytes | container.network.io.usage.tx_bytes\t| Bytes\necs.task.network.io.usage.tx_packets\t| container.network.io.usage.tx_packets\t| Count\necs.task.network.io.usage.tx_errors\t| container.network.io.usage.tx_errors\t| Count\necs.task.network.io.usage.tx_dropped\t| container.network.io.usage.tx_dropped\t| Count\necs.task.storage.read_bytes | container.storage.read_bytes| Bytes\necs.task.storage.write_bytes | container.storage.write_bytes | Bytes\n\n\n## Resource Attributes and Metrics Labels\nMetrics emitted by this receiver comes with a set of resource attributes. These resource attributes can be converted to metrics labels using appropriate processors/exporters (See `Full Configuration Examples` section below). Finally, these metrics labels can be set as metrics dimensions while exporting to desired destinations. Check the following table to see available resource attributes for Task and Container level metrics. Container level metrics have three additional attributes than task level metrics.\n\nResource Attributes for Task Level Metrics | Resource Attributes for Container Level Metrics\n-------------------- | -----------------------------\naws.ecs.cluster.name | aws.ecs.cluster.name\naws.ecs.task.family  | aws.ecs.task.family\naws.ecs.task.arn     | aws.ecs.task.arn\naws.ecs.task.id      | aws.ecs.task.id\naws.ecs.task.revision | aws.ecs.task.revision\naws.ecs.service.name | aws.ecs.service.name\ncloud.availability_zone | cloud.availability_zone\ncloud.account.id | cloud.account.id\ncloud.region | cloud.region\naws.ecs.task.pull_started_at | aws.ecs.container.started_at\naws.ecs.task.pull_stopped_at | aws.ecs.container.finished_at\naws.ecs.task.known_status | aws.ecs.container.know_status\naws.ecs.launch_type | aws.ecs.launch_type\n\u0026nbsp; | aws.ecs.container.created_at\n\u0026nbsp; | container.name\n\u0026nbsp; | container.id\n\u0026nbsp; | aws.ecs.docker.name \n\u0026nbsp; | container.image.tag\n\u0026nbsp; | aws.ecs.container.image.id\n\u0026nbsp; | aws.ecs.container.exit_code\n\n## Full Configuration Examples\nThis receiver emits 52 unique metrics. Customer may not want to send all of them to destinations. Following sections will show full configuration files for filtering and transforming existing metrics with different processors/exporters. \n\n### 1. Full configuration for task level metrics\nThe following example shows a full configuration to get most useful task level metrics. It uses `awsecscontainermetrics` receiver to collect all the resource usage metrics from ECS task metadata endpoint. It applies `filter` processor to select only 8 task-level metrics and update metric names using `metricstransform` processor. It also renames the resource attributes using `resource` processor which will be used as metric dimensions in the Amazon CloudWatch `awsemf` exporter. Finally, it sends the metrics to CloudWatch using `awsemf` exporter under the `/aws/ecs/containerinsights/{ClusterName}/performance` namespace where the `{ClusterName}` placeholder will be replaced with actual cluster name. Check the [AWS EMF Exporter](https://aws-otel.github.io/docs/getting-started/cloudwatch-metrics) documentation to see and explore the metrics in Amazon CloudWatch.\n\n**Note:** AWS OpenTelemetry Collector has a [default configuration](https://github.com/aws-observability/aws-otel-collector/blob/main/config/ecs/container-insights/otel-task-metrics-config.yaml) backed into it for Container Insights experience which is smiliar to this one. Follow our [setup](https://aws-otel.github.io/docs/setup/ecs) doc to check how to use that default config.\n\n```yaml\nreceivers:\n  awsecscontainermetrics: # collect 52 metrics\n\nprocessors:\n  filter: # filter metrics\n    metrics:\n      include:\n        match_type: strict\n        metric_names: # select only 8 task level metrics out of 52\n          - ecs.task.memory.reserved\n          - ecs.task.memory.utilized\n          - ecs.task.cpu.reserved\n          - ecs.task.cpu.utilized\n          - ecs.task.network.rate.rx\n          - ecs.task.network.rate.tx\n          - ecs.task.storage.read_bytes\n          - ecs.task.storage.write_bytes\n  metricstransform: # update metric names\n    transforms:\n      - include: ecs.task.memory.utilized\n        action: update\n        new_name: MemoryUtilized\n      - include: ecs.task.memory.reserved\n        action: update\n        new_name: MemoryReserved\n      - include: ecs.task.cpu.utilized\n        action: update\n        new_name: CpuUtilized\n      - include: ecs.task.cpu.reserved\n        action: update\n        new_name: CpuReserved\n      - include: ecs.task.network.rate.rx\n        action: update\n        new_name: NetworkRxBytes\n      - include: ecs.task.network.rate.tx\n        action: update\n        new_name: NetworkTxBytes\n      - include: ecs.task.storage.read_bytes\n        action: update\n        new_name: StorageReadBytes\n      - include: ecs.task.storage.write_bytes\n        action: update\n        new_name: StorageWriteBytes\n  resource:\n    attributes: # rename resource attributes which will be used as dimensions\n      - key: ClusterName\n        from_attribute: aws.ecs.cluster.name\n        action: insert\n      - key: aws.ecs.cluster.name\n        action: delete\n      - key: ServiceName\n        from_attribute: aws.ecs.service.name\n        action: insert\n      - key: aws.ecs.service.name\n        action: delete\n      - key: TaskId\n        from_attribute: aws.ecs.task.id\n        action: insert\n      - key: aws.ecs.task.id\n        action: delete\n      - key: TaskDefinitionFamily\n        from_attribute: aws.ecs.task.family\n        action: insert\n      - key: aws.ecs.task.family\n        action: delete\nexporters:\n  awsemf:\n    namespace: ECS/ContainerInsights\n    log_group_name: '/aws/ecs/containerinsights/{ClusterName}/performance'\n    log_stream_name: '{TaskId}'  # TaskId placeholder will be replaced with actual value\n    resource_to_telemetry_conversion:\n      enabled: true\n    dimension_rollup_option: NoDimensionRollup\n    metric_declarations:\n      dimensions: [ [ ClusterName ], [ ClusterName, TaskDefinitionFamily ] ]\n      metric_name_selectors: [ . ]\nservice:\n  pipelines:\n    metrics:\n      receivers: [awsecscontainermetrics ]\n      processors: [filter, metricstransform, resource]\n      exporters: [ awsemf ]\n```\n\n\n### 2. Full configuration for task- and container-level metrics\n\nThe following example shows a full configuration to get most useful task- and container-level metrics. It uses `awsecscontainermetrics` receiver to collect all the resource usage metrics from ECS task metadata endpoint. It applies `filter` processor to select only 8 task- and container-level metrics and update metric names using `metricstransform` processor. It also renames the resource attributes using `resource` processor which will be used as metric dimensions in the Amazon CloudWatch `awsemf` exporter. Finally, it sends the metrics to CloudWatch using `awsemf` exporter under the /`aws/ecs/containerinsights/{ClusterName}/performance` namespace where the `{ClusterName}` placeholder will be replaced with actual cluster name. Check the [AWS EMF Exporter](https://aws-otel.github.io/docs/getting-started/cloudwatch-metrics) documentation to see and explore the metrics in Amazon CloudWatch.\n\n```yaml\nreceivers:\n    awsecscontainermetrics:\n\nprocessors:\n    filter:\n        metrics:\n            include:\n                match_type: regexp\n                metric_names:\n                    - .*memory.reserved\n                    - .*memory.utilized\n                    - .*cpu.reserved\n                    - .*cpu.utilized\n                    - .*network.rate.rx\n                    - .*network.rate.tx\n                    - .*storage.read_bytes\n                    - .*storage.write_bytes\n    metricstransform:\n        transforms:\n            - include: ecs.task.memory.utilized\n              action: update\n              new_name: MemoryUtilized\n            - include: ecs.task.memory.reserved\n              action: update\n              new_name: MemoryReserved\n            - include: ecs.task.cpu.utilized\n              action: update\n              new_name: CpuUtilized\n            - include: ecs.task.cpu.reserved\n              action: update\n              new_name: CpuReserved\n            - include: ecs.task.network.rate.rx\n              action: update\n              new_name: NetworkRxBytes\n            - include: ecs.task.network.rate.tx\n              action: update\n              new_name: NetworkTxBytes\n            - include: ecs.task.storage.read_bytes\n              action: update\n              new_name: StorageReadBytes\n            - include: ecs.task.storage.write_bytes\n              action: update\n              new_name: StorageWriteBytes\n    resource:\n        attributes:\n            - key: ClusterName\n              from_attribute: aws.ecs.cluster.name\n              action: insert\n            - key: aws.ecs.cluster.name\n              action: delete\n            - key: ServiceName\n              from_attribute: aws.ecs.service.name\n              action: insert\n            - key: aws.ecs.service.name\n              action: delete\n            - key: TaskId\n              from_attribute: aws.ecs.task.id\n              action: insert\n            - key: aws.ecs.task.id\n              action: delete\n            - key: TaskDefinitionFamily\n              from_attribute: aws.ecs.task.family\n              action: insert\n            - key: aws.ecs.task.family\n              action: delete\n            - key: ContainerName\n              from_attribute: container.name\n              action: insert\n            - key: container.name\n              action: delete                  \nexporters:\n    awsemf:\n        namespace: ECS/ContainerInsights\n        log_group_name:  '/aws/ecs/containerinsights/{ClusterName}/performance'\n        log_stream_name: '{TaskId}'\n        resource_to_telemetry_conversion:\n            enabled: true\n        dimension_rollup_option: NoDimensionRollup\n        metric_declarations:\n            - dimensions: [[ClusterName], [ClusterName, TaskDefinitionFamily]]\n              metric_name_selectors: \n                - MemoryUtilized \n                - MemoryReserved \n                - CpuUtilized\n                - CpuReserved\n                - NetworkRxBytes\n                - NetworkTxBytes\n                - StorageReadBytes\n                - StorageWriteBytes\n            - dimensions: [[ClusterName], [ClusterName, TaskDefinitionFamily, ContainerName]]\n              metric_name_selectors: [container.*]\n     \nservice:\n    pipelines:\n        metrics:\n            receivers: [awsecscontainermetrics]\n            processors: [filter, metricstransform, resource]\n            exporters: [awsemf]\n```\n\n## Reference\n1. [Setup OpenTelemetry Collector on Amazon ECS](https://aws-otel.github.io/docs/setup/ecs)\n2. [Getting Started with ECS Container Metrics Receiver in the OpenTelemetry Collector](https://aws-otel.github.io/docs/components/ecs-metrics-receiver)","properties":{"collection_interval":{"description":"CollectionInterval is the interval at which metrics should be collected","title":"collection_interval","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.awsxrayreceiver.Config":{"additionalProperties":false,"description":"Config defines the configurations for an AWS X-Ray receiver.","markdownDescription":"# AWS X-Ray Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: traces   |\n| Distributions | [contrib], [aws], [observiq], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n## Overview\nThe AWS X-Ray receiver accepts segments (i.e. spans) in the [X-Ray Segment format](https://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html).\nThis enables the collector to receive spans emitted by the existing X-Ray SDK. [Centralized sampling](https://github.com/aws/aws-xray-daemon/blob/master/CHANGELOG.md#300-2018-08-28) is also supported via a local TCP port.\n\nThe requests sent to AWS are authenticated using the mechanism documented [here](https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials).\n\n## Configuration\n\nExample:\n\n```yaml\nreceivers:\n  awsxray:\n    endpoint: 0.0.0.0:2000\n    transport: udp\n    proxy_server:\n      endpoint: 0.0.0.0:2000\n      proxy_address: \"\"\n      tls:\n        insecure: false\n        server_name_override: \"\"\n      region: \"\"\n      role_arn: \"\"\n      aws_endpoint: \"\"\n      local_mode: false\n```\n\nThe default configurations below are based on the [default configurations](https://github.com/aws/aws-xray-daemon/blob/master/pkg/cfg/cfg.go#L99) of the existing X-Ray Daemon.\n\n### endpoint (Optional)\nThe UDP address and port on which this receiver listens for X-Ray segment documents emitted by the X-Ray SDK.\n\nDefault: `0.0.0.0:2000`\n\n### transport (Optional)\nThis should always be \"udp\" as X-Ray SDKs only send segments using UDP.\n\nDefault: `udp`\n\n### proxy_server (Optional)\nDefines configurations related to the local TCP proxy server.\n\n### endpoint (Optional)\nThe TCP address and port on which this receiver listens for calls from the X-Ray SDK and relays them to the AWS X-Ray backend to get sampling rules and report sampling statistics.\n\nDefault: `0.0.0.0:2000`\n\n### proxy_address (Optional)\nDefines the proxy address that the local TCP server forwards HTTP requests to AWS X-Ray backend through. If left unconfigured, requests will be sent directly.\n\n### insecure (Optional)\nEnables or disables TLS certificate verification when the local TCP server forwards HTTP requests to the AWS X-Ray backend. This sets the `InsecureSkipVerify` in the [TLSConfig](https://godoc.org/crypto/tls#Config). When setting to true, TLS is susceptible to man-in-the-middle attacks so it should be used only for testing.\n\nDefault: `false`\n\n### server_name_override (Optional)\nThis sets the ``ServerName` in the [TLSConfig](https://godoc.org/crypto/tls#Config).\n\n### region (Optional)\nThe AWS region the local TCP server forwards requests to. When missing, we will try to retrieve this value through environment variables or optionally ECS/EC2 metadata endpoint (depends on `local_mode` below).\n\n### role_arn (Optional)\nThe IAM role used by the local TCP server when communicating with the AWS X-Ray service. If non-empty, the receiver will attempt to call STS to retrieve temporary credentials, otherwise the standard AWS credential [lookup](https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html#specifying-credentials) will be performed.\n\n### aws_endpoint (Optional)\nThe X-Ray service endpoint which the local TCP server forwards requests to.\n\n### local_mode (Optional)\nDetermines whether the ECS/EC2 instance metadata endpoint will be called to fetch the AWS region to send requests to. Set to `true` to skip metadata check.\n\nDefault: `false`","properties":{"endpoint":{"description":"Endpoint configures the address for this network connection.\nFor TCP and UDP networks, the address has the form \"host:port\". The host must be a literal IP address,\nor a host name that can be resolved to IP addresses. The port must be a literal port number or a service name.\nIf the host is a literal IPv6 address it must be enclosed in square brackets, as in \"[2001:db8::1]:80\" or\n\"[fe80::1%zone]:80\". The zone specifies the scope of the literal IPv6 address as defined in RFC 4007.","title":"endpoint","type":"string"},"proxy_server":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.aws.proxy.Config","description":"ProxyServer defines configurations related to the local TCP proxy server.","title":"proxy_server"},"transport":{"description":"Transport to use. Known protocols are \"tcp\", \"tcp4\" (IPv4-only), \"tcp6\" (IPv6-only), \"udp\", \"udp4\" (IPv4-only),\n\"udp6\" (IPv6-only), \"ip\", \"ip4\" (IPv4-only), \"ip6\" (IPv6-only), \"unix\", \"unixgram\" and \"unixpacket\".","title":"transport","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.carbonreceiver.Config":{"additionalProperties":false,"description":"Config defines configuration for the Carbon receiver.","markdownDescription":"# Carbon Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [contrib], [observiq], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe [Carbon](https://github.com/graphite-project/carbon) receiver supports\nCarbon's [plaintext\nprotocol](https://graphite.readthedocs.io/en/stable/feeding-carbon.html#the-plaintext-protocol).\n\n\u003e :information_source: The `wavefront` receiver is based on Carbon and binds to the\nsame port by default. This means the `carbon` and `wavefront` receivers\ncannot both be enabled with their respective default configurations. To\nsupport running both receivers in parallel, change the `endpoint` port on one\nof the receivers.\n\n## Configuration\n\nThe following settings are required:\n\n- `endpoint` (default = `0.0.0.0:2003`): Address and port that the\n  receiver should bind to.\n- `transport` (default = `tcp`): Must be either `tcp` or `udp`.\n\nThe following setting are optional:\n\n- `tcp_idle_timeout` (default = `30s`): The maximum duration that a tcp\n  connection will idle wait for new data. This value is ignored if the\n  transport is not `tcp`.\n\nIn addition, a `parser` section can be defined with the following settings:\n\n- `type` (default `plaintext`): Specifies the type of parser to be used\n  and must be either `plaintext` or `regex`.\n- `config`: Specifies any special configuration of the selected parser.\n\nExample:\n\n```yaml\nreceivers:\n  carbon/receiver_settings:\n    endpoint: localhost:8080\n    transport: udp\n  carbon/regex:\n    parser:\n      type: regex\n      config:\n        rules:\n          - regexp: \"(?P\u003ckey_base\u003etest)\\\\.env(?P\u003ckey_env\u003e[^.]*)\\\\.(?P\u003ckey_host\u003e[^.]*)\"\n            name_prefix: \"name-prefix\"\n            labels:\n              dot.key: dot.value\n              key: value\n            type: cumulative\n          - regexp: \"(?P\u003ckey_just\u003etest)\\\\.(?P\u003ckey_match\u003e.*)\"\n        name_separator: \"_\"\n```\n\nThe full list of settings exposed for this receiver are documented [here](./config.go)\nwith detailed sample configurations [here](./testdata/config.yaml).","properties":{"endpoint":{"description":"Endpoint configures the address for this network connection.\nFor TCP and UDP networks, the address has the form \"host:port\". The host must be a literal IP address,\nor a host name that can be resolved to IP addresses. The port must be a literal port number or a service name.\nIf the host is a literal IPv6 address it must be enclosed in square brackets, as in \"[2001:db8::1]:80\" or\n\"[fe80::1%zone]:80\". The zone specifies the scope of the literal IPv6 address as defined in RFC 4007.","title":"endpoint","type":"string"},"parser":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.carbonreceiver.protocol.Config","description":"Parser specifies a parser and the respective configuration to be used\nby the receiver.","title":"parser"},"tcp_idle_timeout":{"description":"TCPIdleTimeout is the timout for idle TCP connections, it is ignored\nif transport being used is UDP.","title":"tcp_idle_timeout","type":"string"},"transport":{"description":"Transport to use. Known protocols are \"tcp\", \"tcp4\" (IPv4-only), \"tcp6\" (IPv6-only), \"udp\", \"udp4\" (IPv4-only),\n\"udp6\" (IPv6-only), \"ip\", \"ip4\" (IPv4-only), \"ip6\" (IPv6-only), \"unix\", \"unixgram\" and \"unixpacket\".","title":"transport","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.carbonreceiver.protocol.Config":{"additionalProperties":false,"description":"Config is the general configuration for the parser to be used.","properties":{"config":{"description":"Config placeholder for the configuration object of the selected parser.","title":"config"},"type":{"description":"Type of the parser to be used with the arriving data.","title":"type","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.collectdreceiver.Config":{"additionalProperties":false,"description":"Config defines configuration for Collectd receiver.","markdownDescription":"# CollectD `write_http` plugin JSON receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [alpha]: metrics   |\n| Distributions | [contrib], [observiq], [splunk], [sumo] |\n\n[alpha]: https://github.com/open-telemetry/opentelemetry-collector#alpha\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThis receiver can receive data exported by the CollectD's `write_http`\nplugin. Only JSON format is supported. Authentication is not supported at\nthis time.\n\nThis receiver was donated by SignalFx and ported from SignalFx's Gateway\n(https://github.com/signalfx/gateway/tree/master/protocol/collectd). As a\nresult, this receiver supports some additional features that are technically\nnot compatible with stock CollectD's write_http plugin. That said, in\npractice such incompatibilities should never surface. For example, this\nreceiver supports extracting labels from different fields. Given a field\nvalue `field[a=b, k=v]`, this receiver will extract `a` and `b` as label keys\nand, `k` and `v` as the respective label values.\n\n## Configuration\n\nThe following settings are required:\n\n- `endpoint` (default = `localhost:8081`): Address to reach the desired Docker daemon.\n\nThe following settings are optional:\n\n- `attributes_prefix` (no default): Used to add query parameters in key=value format to all metrics.\n- `timeout` (default = `30s`): The request timeout for any docker daemon query.\n\nExample:\n\n```yaml\nreceivers:\n  collectd:\n  collectd/one:\n    attributes_prefix: \"dap_\"\n    endpoint: \"localhost:12345\"\n    timeout: \"50s\"\n```\n\nThe full list of settings exposed for this receiver are documented [here](./config.go)\nwith detailed sample configurations [here](./testdata/config.yaml).","properties":{"attributes_prefix":{"title":"attributes_prefix","type":"string"},"encoding":{"title":"encoding","type":"string"},"endpoint":{"description":"Endpoint configures the address for this network connection.\nThe address has the form \"host:port\". The host must be a literal IP address, or a host name that can be\nresolved to IP addresses. The port must be a literal port number or a service name.\nIf the host is a literal IPv6 address it must be enclosed in square brackets, as in \"[2001:db8::1]:80\" or\n\"[fe80::1%zone]:80\". The zone specifies the scope of the literal IPv6 address as defined in RFC 4007.","title":"endpoint","type":"string"},"timeout":{"title":"timeout","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.couchdbreceiver.Config":{"additionalProperties":false,"description":"Config defines the configuration for the various elements of the receiver agent.","markdownDescription":"# CouchDB Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [contrib], [observiq], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThis receiver fetches stats from a couchdb server using the `/_node/{node-name}/_stats/couchdb` [endpoint](https://docs.couchdb.org/en/latest/api/server/common.html#node-node-name-stats).\n\n## Prerequisites\n\nThis receiver supports Couchdb versions `2.3+` and `3.1+`.\n\n## Configuration\n\nThe following settings are required:\n\n- `username`\n- `password`\n\nThe following settings are optional:\n\n- `endpoint` (default: `http://localhost:5984`): The URL of the couchdb endpoint\n\n- `collection_interval` (default = `60s`): This receiver collects metrics on an interval. This value must be a string readable by Golang's [time.ParseDuration](https://pkg.go.dev/time#ParseDuration). Valid time units are `ns`, `us` (or `Âµs`), `ms`, `s`, `m`, `h`.\n\n### Example Configuration\n\n```yaml\nreceivers:\n  couchdb:\n    endpoint: http://localhost:5984\n    username: otelu\n    password: ${env:COUCHDB_PASSWORD}\n    collection_interval: 60s\n```\n\nThe full list of settings exposed for this receiver are documented [here](./config.go) with detailed sample configurations [here](./testdata/config.yaml). TLS config is documented further under the [opentelemetry collector's configtls package](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/configtls/README.md).\n\n## Metrics\n\nDetails about the metrics produced by this receiver can be found in [metadata.yaml](./metadata.yaml)","properties":{"CustomRoundTripper":{"description":"Custom Round Tripper to allow for individual components to intercept HTTP requests","title":"CustomRoundTripper"},"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth configuration for outgoing HTTP calls.","title":"auth"},"collection_interval":{"title":"collection_interval","type":"string"},"compression":{"description":"The compression key for supported compression types within collector.","title":"compression","type":"string"},"endpoint":{"description":"The target URL to send data to (e.g.: http://some.url:9411/v1/traces).","title":"endpoint","type":"string"},"headers":{"description":"Additional headers attached to each HTTP request sent by the client.\nExisting header values are overwritten if collision happens.\nHeader values are opaque since they may be sensitive.","patternProperties":{".*":{"type":"string"}},"title":"headers","type":"object"},"idle_conn_timeout":{"description":"IdleConnTimeout is the maximum amount of time a connection will remain open before closing itself.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"idle_conn_timeout","type":"string"},"initial_delay":{"title":"initial_delay","type":"string"},"max_conns_per_host":{"description":"MaxConnsPerHost limits the total number of connections per host, including connections in the dialing,\nactive, and idle states.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_conns_per_host","type":"integer"},"max_idle_conns":{"description":"MaxIdleConns is used to set a limit to the maximum idle HTTP connections the client can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns","type":"integer"},"max_idle_conns_per_host":{"description":"MaxIdleConnsPerHost is used to set a limit to the maximum idle HTTP connections the host can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns_per_host","type":"integer"},"metrics":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.couchdbreceiver.internal.metadata.MetricsConfig","title":"metrics"},"password":{"title":"password","type":"string"},"read_buffer_size":{"description":"ReadBufferSize for HTTP client. See http.Transport.ReadBufferSize.","title":"read_buffer_size","type":"integer"},"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.couchdbreceiver.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"},"timeout":{"description":"Timeout parameter configures `http.Client.Timeout`.","title":"timeout","type":"string"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","description":"TLSSetting struct exposes TLS client configuration.","title":"tls"},"username":{"title":"username","type":"string"},"write_buffer_size":{"description":"WriteBufferSize for HTTP client. See http.Transport.WriteBufferSize.","title":"write_buffer_size","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.couchdbreceiver.internal.metadata.MetricConfig":{"additionalProperties":false,"description":"MetricConfig provides common config for a particular metric.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.couchdbreceiver.internal.metadata.MetricsConfig":{"additionalProperties":false,"description":"MetricsConfig provides config for couchdb metrics.","properties":{"couchdb.average_request_time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.couchdbreceiver.internal.metadata.MetricConfig","title":"couchdb.average_request_time"},"couchdb.database.open":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.couchdbreceiver.internal.metadata.MetricConfig","title":"couchdb.database.open"},"couchdb.database.operations":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.couchdbreceiver.internal.metadata.MetricConfig","title":"couchdb.database.operations"},"couchdb.file_descriptor.open":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.couchdbreceiver.internal.metadata.MetricConfig","title":"couchdb.file_descriptor.open"},"couchdb.httpd.bulk_requests":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.couchdbreceiver.internal.metadata.MetricConfig","title":"couchdb.httpd.bulk_requests"},"couchdb.httpd.requests":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.couchdbreceiver.internal.metadata.MetricConfig","title":"couchdb.httpd.requests"},"couchdb.httpd.responses":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.couchdbreceiver.internal.metadata.MetricConfig","title":"couchdb.httpd.responses"},"couchdb.httpd.views":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.couchdbreceiver.internal.metadata.MetricConfig","title":"couchdb.httpd.views"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.couchdbreceiver.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.couchdbreceiver.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for couchdb resource attributes.","properties":{"couchdb.node.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.couchdbreceiver.internal.metadata.ResourceAttributeConfig","title":"couchdb.node.name"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.Config":{"additionalProperties":false,"markdownDescription":"# Docker Stats Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [alpha]: metrics   |\n| Distributions | [contrib], [observiq], [sumo] |\n\n[alpha]: https://github.com/open-telemetry/opentelemetry-collector#alpha\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe Docker Stats receiver queries the local Docker daemon's container stats API for\nall desired running containers on a configured interval.  These stats are for container\nresource usage of cpu, memory, network, and the\n[blkio controller](https://www.kernel.org/doc/Documentation/cgroup-v1/blkio-controller.txt).\n\n\u003e :information_source: Requires Docker API version 1.22+ and only Linux is supported.\n\n## Configuration\n\nThe following settings are optional:\n\n- `endpoint` (default = `unix:///var/run/docker.sock`): Address to reach the desired Docker daemon.\n- `collection_interval` (default = `10s`): The interval at which to gather container stats.\n- `initial_delay` (default = `1s`): defines how long this receiver waits before starting.\n- `container_labels_to_metric_labels` (no default): A map of Docker container label names whose label values to use\nas the specified metric label key.\n- `env_vars_to_metric_labels` (no default): A map of Docker container environment variables whose values to use\nas the specified metric label key.\n- `excluded_images` (no default, all running containers monitored): A list of strings,\n[regexes](https://golang.org/pkg/regexp/), or [globs](https://github.com/gobwas/glob) whose referent container image\nnames will not be among the queried containers. `!`-prefixed negations are possible for all item types to signify that\nonly unmatched container image names should be excluded.\n    - Regexes must be placed between `/` characters: `/my?egex/`.  Negations are to be outside the forward slashes:\n    `!/my?egex/` will exclude all containers whose name doesn't match the compiled regex `my?egex`.\n    - Globs are non-regex items (e.g. `/items/`) containing any of the following: `*[]{}?`.  Negations are supported:\n    `!my*container` will exclude all containers whose image name doesn't match the blob `my*container`.\n- `timeout` (default = `5s`): The request timeout for any docker daemon query.\n- `api_version` (default = `1.22`): The Docker client API version (must be 1.22+). [Docker API versions](https://docs.docker.com/engine/api/).\n- `metrics` (defaults at [./documentation.md](./documentation.md)): Enables/disables individual metrics. See [./documentation.md](./documentation.md) for full detail.\n\nExample:\n\n```yaml\nreceivers:\n  docker_stats:\n    endpoint: http://example.com/\n    collection_interval: 2s\n    timeout: 20s\n    api_version: 1.24\n    container_labels_to_metric_labels:\n      my.container.label: my-metric-label\n      my.other.container.label: my-other-metric-label\n    env_vars_to_metric_labels:\n      MY_ENVIRONMENT_VARIABLE: my-metric-label\n      MY_OTHER_ENVIRONMENT_VARIABLE: my-other-metric-label\n    excluded_images:\n      - undesired-container\n      - /.*undesired.*/\n      - another-*-container\n    metrics: \n      container.cpu.usage.percpu:\n        enabled: true\n      container.network.io.usage.tx_dropped:\n        enabled: false\n```\n\nThe full list of settings exposed for this receiver are documented [here](./config.go)\nwith detailed sample configurations [here](./testdata/config.yaml).\n\n## Deprecations\n\n### Transition to cpu utilization metric name aligned with OpenTelemetry specification\n\nThe Docker Stats receiver has been emitting the following cpu memory metric:\n\n- [container.cpu.percent] for the percentage of CPU used by the container,\n\nThis is in conflict with the OpenTelemetry specification,\nwhich defines [container.cpu.utilization] as the name for this metric.\n\nTo align the emitted metric names with the OpenTelemetry specification,\nthe following process will be followed to phase out the old metrics:\n\n- Between `v0.79.0` and `v0.81.0`, the new metric is introduced and the old metric is marked as deprecated.\n  Only the old metric are emitted by default.\n- Between `v0.82.0` and `v0.84.0`, the old metric is disabled and the new one enabled by default.\n- In `v0.85.0` and up, the old metric is removed.\n\nTo change the enabled state for the specific metrics, use the standard configuration options that are available for all metrics.\n\nHere's an example configuration to disable the old metrics and enable the new metrics:\n\n```yaml\nreceivers:\n  docker_stats:\n    metrics:\n      container.cpu.percent:\n        enabled: false\n      container.cpu.utilization:\n        enabled: true\n\n```\n\n### Migrating from ScraperV1 to ScraperV2\n\n*Note: These changes are now in effect and ScraperV1 have been removed as of v0.71.*\n\nThere are some breaking changes from ScraperV1 to ScraperV2. The work done for these changes is tracked in [#9794](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/9794).\n\n| Breaking Change                     | Action                                                                  |\n|-------------------------------------|-------------------------------------------------------------------------|\n| Many metrics are no longer emitted by default. | See [documentation.md](./documentation.md) to see which metrics are enabled by default. Enable/disable as desired. |\n| BlockIO metrics names changed. The type of operation is no longer in the metric name suffix, and is now in an attribute. For example `container.blockio.io_merged_recursive.read` becomes `container.blockio.io_merged_recursive` with an `operation:read` attribute. | Be aware of the metric name changes and make any adjustments to what your downstream expects from BlockIO metrics. |\n| Memory metrics measured in Bytes are now [non-monotonic sums](https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/metrics/data-model.md#opentelemetry-protocol-data-model-consumer-recommendations) instead of gauges. | Most likely there is no action. The aggregation type is different but the values are the same. Be aware of how your downstream handles gauges vs non-monotonic sums. |\n| Config option `provide_per_core_cpu_metrics` has been removed. | Enable the `container.cpu.usage.percpu` metric as per [documentation.md](./documentation.md). |","properties":{"api_version":{"description":"Docker client API version. Default is 1.22","title":"api_version","type":"number"},"collection_interval":{"title":"collection_interval","type":"string"},"container_labels_to_metric_labels":{"description":"A mapping of container label names to MetricDescriptor label keys.\nThe corresponding container label value will become the DataPoint label value\nfor the mapped name.  E.g. `io.kubernetes.container.name: container_spec_name`\nwould result in a MetricDescriptor label called `container_spec_name` whose\nMetric DataPoints have the value of the `io.kubernetes.container.name` container label.","patternProperties":{".*":{"type":"string"}},"title":"container_labels_to_metric_labels","type":"object"},"endpoint":{"description":"The URL of the docker server.  Default is \"unix:///var/run/docker.sock\"","title":"endpoint","type":"string"},"env_vars_to_metric_labels":{"description":"A mapping of container environment variable names to MetricDescriptor label\nkeys.  The corresponding env var values become the DataPoint label value.\nE.g. `APP_VERSION: version` would result MetricDescriptors having a label\nkey called `version` whose DataPoint label values are the value of the\n`APP_VERSION` environment variable configured for that particular container, if\npresent.","patternProperties":{".*":{"type":"string"}},"title":"env_vars_to_metric_labels","type":"object"},"excluded_images":{"description":"A list of filters whose matching images are to be excluded.  Supports literals, globs, and regex.","items":{"type":"string"},"title":"excluded_images","type":"array"},"initial_delay":{"title":"initial_delay","type":"string"},"metrics":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricsConfig","title":"metrics"},"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"},"timeout":{"description":"The maximum amount of time to wait for docker API responses.  Default is 5s","title":"timeout","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig":{"additionalProperties":false,"description":"MetricConfig provides common config for a particular metric.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricsConfig":{"additionalProperties":false,"description":"MetricsConfig provides config for docker_stats metrics.","properties":{"container.blockio.io_merged_recursive":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.blockio.io_merged_recursive"},"container.blockio.io_queued_recursive":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.blockio.io_queued_recursive"},"container.blockio.io_service_bytes_recursive":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.blockio.io_service_bytes_recursive"},"container.blockio.io_service_time_recursive":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.blockio.io_service_time_recursive"},"container.blockio.io_serviced_recursive":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.blockio.io_serviced_recursive"},"container.blockio.io_time_recursive":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.blockio.io_time_recursive"},"container.blockio.io_wait_time_recursive":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.blockio.io_wait_time_recursive"},"container.blockio.sectors_recursive":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.blockio.sectors_recursive"},"container.cpu.percent":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.cpu.percent"},"container.cpu.throttling_data.periods":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.cpu.throttling_data.periods"},"container.cpu.throttling_data.throttled_periods":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.cpu.throttling_data.throttled_periods"},"container.cpu.throttling_data.throttled_time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.cpu.throttling_data.throttled_time"},"container.cpu.usage.kernelmode":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.cpu.usage.kernelmode"},"container.cpu.usage.percpu":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.cpu.usage.percpu"},"container.cpu.usage.system":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.cpu.usage.system"},"container.cpu.usage.total":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.cpu.usage.total"},"container.cpu.usage.usermode":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.cpu.usage.usermode"},"container.cpu.utilization":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.cpu.utilization"},"container.memory.active_anon":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.active_anon"},"container.memory.active_file":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.active_file"},"container.memory.anon":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.anon"},"container.memory.cache":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.cache"},"container.memory.dirty":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.dirty"},"container.memory.file":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.file"},"container.memory.hierarchical_memory_limit":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.hierarchical_memory_limit"},"container.memory.hierarchical_memsw_limit":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.hierarchical_memsw_limit"},"container.memory.inactive_anon":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.inactive_anon"},"container.memory.inactive_file":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.inactive_file"},"container.memory.mapped_file":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.mapped_file"},"container.memory.percent":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.percent"},"container.memory.pgfault":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.pgfault"},"container.memory.pgmajfault":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.pgmajfault"},"container.memory.pgpgin":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.pgpgin"},"container.memory.pgpgout":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.pgpgout"},"container.memory.rss":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.rss"},"container.memory.rss_huge":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.rss_huge"},"container.memory.total_active_anon":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.total_active_anon"},"container.memory.total_active_file":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.total_active_file"},"container.memory.total_cache":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.total_cache"},"container.memory.total_dirty":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.total_dirty"},"container.memory.total_inactive_anon":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.total_inactive_anon"},"container.memory.total_inactive_file":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.total_inactive_file"},"container.memory.total_mapped_file":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.total_mapped_file"},"container.memory.total_pgfault":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.total_pgfault"},"container.memory.total_pgmajfault":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.total_pgmajfault"},"container.memory.total_pgpgin":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.total_pgpgin"},"container.memory.total_pgpgout":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.total_pgpgout"},"container.memory.total_rss":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.total_rss"},"container.memory.total_rss_huge":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.total_rss_huge"},"container.memory.total_unevictable":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.total_unevictable"},"container.memory.total_writeback":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.total_writeback"},"container.memory.unevictable":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.unevictable"},"container.memory.usage.limit":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.usage.limit"},"container.memory.usage.max":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.usage.max"},"container.memory.usage.total":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.usage.total"},"container.memory.writeback":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.writeback"},"container.network.io.usage.rx_bytes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.network.io.usage.rx_bytes"},"container.network.io.usage.rx_dropped":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.network.io.usage.rx_dropped"},"container.network.io.usage.rx_errors":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.network.io.usage.rx_errors"},"container.network.io.usage.rx_packets":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.network.io.usage.rx_packets"},"container.network.io.usage.tx_bytes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.network.io.usage.tx_bytes"},"container.network.io.usage.tx_dropped":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.network.io.usage.tx_dropped"},"container.network.io.usage.tx_errors":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.network.io.usage.tx_errors"},"container.network.io.usage.tx_packets":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.network.io.usage.tx_packets"},"container.pids.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.pids.count"},"container.pids.limit":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.pids.limit"},"container.uptime":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.MetricConfig","title":"container.uptime"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for docker_stats resource attributes.","properties":{"container.command_line":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.ResourceAttributeConfig","title":"container.command_line"},"container.hostname":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.ResourceAttributeConfig","title":"container.hostname"},"container.id":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.ResourceAttributeConfig","title":"container.id"},"container.image.id":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.ResourceAttributeConfig","title":"container.image.id"},"container.image.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.ResourceAttributeConfig","title":"container.image.name"},"container.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.ResourceAttributeConfig","title":"container.name"},"container.runtime":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.internal.metadata.ResourceAttributeConfig","title":"container.runtime"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dotnetdiagnosticsreceiver.Config":{"additionalProperties":false,"markdownDescription":"## Dotnet Diagnostics Receiver\n\n| Status                   |                |\n| ------------------------ |----------------|\n| Stability                | [deprecated] |\n| Supported pipeline types | metrics        |\n| Distributions            | [contrib]      |\n\nThis receiver provides a capability similar to the\n[dotnet-counters](https://docs.microsoft.com/en-us/dotnet/core/diagnostics/dotnet-counters)\ntool, which takes a .NET process ID and reads metrics from that process,\nproviding them to the CLI. Similarly, this receiver reads metrics from a given\n.NET process, translating them and providing them to the Collector.\n\n#### .NET Counters Overview\n\nThe .NET runtime makes available metrics to interested clients over an IPC\nconnection, listening for requests and responding with metrics sent at a\nspecified interval. All .NET processes newer than 3.0 make available both\ndefault metrics (grouped under the name `System.Runtime`) and any custom metrics\ngenerated via the EventCounter\n[API](https://docs.microsoft.com/en-us/dotnet/api/system.diagnostics.tracing.eventcounter?view=net-5.0)\n.\n\nOnce a .NET process is running, a client (such as this receiver) may connect to\nit over IPC, which is either a _Unix domain socket_ on Linux/macOS, or a _named\npipe_ on Windows. After connecting, the client sends the process a request,\nusing a custom binary encoding, indicating both the counters it's interested in\nand the collection interval, then waits for data. If the request is successful,\nthe .NET process sends metrics, also using a custom binary encoding, over the\nIPC connection, at the specified interval.\n\n#### Operation\n\nAt startup, this recevier looks for a file in `TMPDIR` (or `/tmp` if not set)\ncorresponding to the given PID and a naming convention. If found, a Unix domain\nsocket connection is opened, using the file as the endpoint, and a request is\nmade to the dotnet process for metrics, with the given (in the config)\ncollection interval and counters.\n\nAfter that, it listens for metrics arriving from the connection, and sends them\nto the next consumer as soon as they arrive. If the connection fails, or an\nunexpected value is read, the receiver shuts down.\n\n#### Configuration\n\nThis receiver accepts three configuration fields: `collection_interval`,\n`pid`, and `counters`.\n\n| Field Name | Description | Example | Default |\n| ---------- | ----------- | ------- | ------- |\n| `collection_interval` | The interval between metric collection (converted to seconds) | `1m` | `1s`\n| `pid` | The process ID of the .NET process from which to collect metrics | `1001` | |\n| `counters` | A list of counter groups (sometimes referred to as _providers_ or _event sources_) to request from the .NET process | `[\"MyCounters\"]` | `[\"System.Runtime\", \"Microsoft.AspNetCore.Hosting\"]` |\n\nExample yaml config:\n\n```yaml\nreceivers:\n  dotnet_diagnostics:\n    collection_interval: 10s\n    pid: 23860\n    counters: [ \"MyCounters\", \"System.Runtime\" ]\nexporters:\n  logging:\n    loglevel: info\nservice:\n  pipelines:\n    metrics:\n      receivers: [ dotnet_diagnostics ]\n      exporters: [ logging ]\n```\n\n#### Usage With Receiver Creator\n\nIt is possible to create a config file for this receiver with a hard-coded\nprocess id, but it is expected that this receiver will often be used with a\nreceiver creator, and a host observer, to discover .NET processes at runtime.\n\nExample receiver creator config:\n\n```yaml\nextensions:\n  host_observer:\nreceivers:\n  receiver_creator:\n    watch_observers: [ host_observer ]\n    receivers:\n      dotnet_diagnostics:\n        rule: type.hostport \u0026\u0026 process_name == 'dotnet'\n        config:\n          pid: \"`process_id`\"\nexporters:\n  logging:\n    loglevel: info\nservice:\n  extensions: [ host_observer ]\n  pipelines:\n    metrics:\n      receivers: [ receiver_creator ]\n      exporters: [ logging ]\n```\n\n#### Supported Versions\n\nThis receiver is compatible with .NET Core 3.0 and later versions, running on Linux or\nmacOS. Windows is not yet supported.\n\n#### External Resources\n\nhttps://github.com/dotnet/diagnostics/blob/master/documentation/design-docs/ipc-protocol.md\n\nhttps://github.com/Microsoft/perfview/blob/main/src/TraceEvent/EventPipe/EventPipeFormat.md\n\n[deprecated]: https://github.com/open-telemetry/opentelemetry-collector#deprecated\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib","properties":{"collection_interval":{"title":"collection_interval","type":"string"},"counters":{"description":"A list of counters for the dotnet process to send to the collector. Defaults\nto [\"System.Runtime\", \"Microsoft.AspNetCore.Hosting\"]. Available counters can\nbe displayed by the `dotnet-counters` tool:\nhttps://docs.microsoft.com/en-us/dotnet/core/diagnostics/dotnet-counters","items":{"type":"string"},"title":"counters","type":"array"},"initial_delay":{"title":"initial_delay","type":"string"},"local_debug_dir":{"description":"LocalDebugDir takes an optional directory name where stream data can be written for\noffline analysis and troubleshooting. If LocalDebugDir is empty, no stream data is\nwritten. If it has a value, MaxLocalDebugFiles also needs to be set, and stream\ndata will be written to disk at the specified location using the naming\nconvention `msg.%d.bin` as each message is received, where %d is the current\nmessage number.","title":"local_debug_dir","type":"string"},"max_local_debug_files":{"description":"MaxLocalDebugFiles indicates the maximum number of files kept in LocalDebugDir. When a\nfile is written, the oldest one will be deleted if necessary to keep the\nnumber of files in LocalDebugDir at the specified maximum.","title":"max_local_debug_files","type":"integer"},"pid":{"description":"The process ID of the dotnet process from which to collect diagnostics. This\nprocess ID is used to generate the file glob \"dotnet-diagnostic-%d-*-socket\"\nto locate a file in TMPDIR (or \"/tmp\" if unset). If the file is found, it is\nused as a Unix domain socket (on Linux/Mac) to communicate with the dotnet\nprocess. For ease of use, this receiver is intended to be used with an\nobserver and receiver creator for process discovery and receiver creation.","title":"pid","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.Config":{"additionalProperties":false,"description":"Config is the configuration for the elasticsearch receiver","markdownDescription":"# Elasticsearch Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [contrib], [observiq], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThis receiver queries the Elasticsearch [node stats](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-nodes-stats.html), [cluster health](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-health.html) and [index stats](https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-stats.html) endpoints in order to scrape metrics from a running elasticsearch cluster.\n\n## Prerequisites\n\nThis receiver supports Elasticsearch versions 7.9+\n\nIf Elasticsearch security features are enabled, you must have either the `monitor` or `manage` cluster privilege.\nSee the [Elasticsearch docs](https://www.elastic.co/guide/en/elasticsearch/reference/current/authorization.html) for more information on authorization and [Security privileges](https://www.elastic.co/guide/en/elasticsearch/reference/current/security-privileges.html).\n\n## Configuration\n\nThe following settings are optional:\n\n- `metrics` (default: see `DefaultMetricsSettings` [here](./internal/metadata/generated_metrics.go): Allows enabling and disabling specific metrics from being collected in this receiver.\n- `nodes` (default: `[\"_all\"]`): Allows specifying node filters that define which nodes are scraped for node-level and cluster-level metrics. See [the Elasticsearch documentation](https://www.elastic.co/guide/en/elasticsearch/reference/7.9/cluster.html#cluster-nodes) for allowed filters. If this option is left explicitly empty, then no node-level metrics will be scraped and cluster-level metrics will scrape only metrics related to cluster's health.\n- `skip_cluster_metrics` (default: `false`): If true, cluster-level metrics will not be scraped.\n- `indices` (default: `[\"_all\"]`): Allows specifying index filters that define which indices are scraped for index-level metrics. See [the Elasticsearch documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-stats.html#index-stats-api-path-params) for allowed filters. If this option is left explicitly empty, then no index-level metrics will be scraped.\n- `endpoint` (default = `http://localhost:9200`): The base URL of the Elasticsearch API for the cluster to monitor.\n- `username` (no default): Specifies the username used to authenticate with Elasticsearch using basic auth. Must be specified if password is specified.\n- `password` (no default): Specifies the password used to authenticate with Elasticsearch using basic auth. Must be specified if username is specified.\n- `collection_interval` (default = `10s`): This receiver collects metrics on an interval. This value must be a string readable by Golang's [time.ParseDuration](https://pkg.go.dev/time#ParseDuration). On larger clusters, the interval may need to be lengthened, as querying Elasticsearch for metrics will take longer on clusters with more nodes.\n- `initial_delay` (default = `1s`): defines how long this receiver waits before starting.\n\n### Example Configuration\n\n```yaml\nreceivers:\n  elasticsearch:\n    metrics:\n      elasticsearch.node.fs.disk.available:\n        enabled: false\n    nodes: [\"_local\"]\n    skip_cluster_metrics: true\n    indices: [\".geoip_databases\"]\n    endpoint: http://localhost:9200\n    username: otel\n    password: password\n    collection_interval: 10s\n```\n\nThe full list of settings exposed for this receiver are documented [here](./config.go) with detailed sample configurations [here](./testdata/config.yaml).\n\n## Metrics\n\nThe following metric are available with versions:\n\n- `elasticsearch.indexing_pressure.memory.limit` \u003e= [7.10](https://www.elastic.co/guide/en/elasticsearch/reference/7.16/release-notes-7.10.0.html)\n- `elasticsearch.node.shards.data_set.size` \u003e= [7.13](https://www.elastic.co/guide/en/elasticsearch/reference/7.16/release-notes-7.13.0.html)\n- `elasticsearch.cluster.state_update.count` \u003e= [7.16.0](https://www.elastic.co/guide/en/elasticsearch/reference/7.16/release-notes-7.16.0.html)\n- `elasticsearch.cluster.state_update.time` \u003e= [7.16.0](https://www.elastic.co/guide/en/elasticsearch/reference/7.16/release-notes-7.16.0.html)\n\nDetails about the metrics produced by this receiver can be found in [metadata.yaml](./metadata.yaml)\n\n## Feature gate configurations\n\nSee the [Collector feature gates](https://github.com/open-telemetry/opentelemetry-collector/blob/main/featuregate/README.md#collector-feature-gates) for an overview of feature gates in the collector.\n\n**BETA**: `receiver.elasticsearch.emitNodeVersionAttr`\n\nThe feature gate `receiver.elasticsearch.emitNodeVersionAttr` when enabled will enrich all node metrics with an\nresource attribute representing the node version.\n\nThis feature gate is enabled by default, and eventually the old implementation will be removed. It aims to give users time\nto migrate to the new implementation. The target release for this featuregate to be permanently enabled is 0.82.0.","properties":{"CustomRoundTripper":{"description":"Custom Round Tripper to allow for individual components to intercept HTTP requests","title":"CustomRoundTripper"},"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth configuration for outgoing HTTP calls.","title":"auth"},"collection_interval":{"title":"collection_interval","type":"string"},"compression":{"description":"The compression key for supported compression types within collector.","title":"compression","type":"string"},"endpoint":{"description":"The target URL to send data to (e.g.: http://some.url:9411/v1/traces).","title":"endpoint","type":"string"},"headers":{"description":"Additional headers attached to each HTTP request sent by the client.\nExisting header values are overwritten if collision happens.\nHeader values are opaque since they may be sensitive.","patternProperties":{".*":{"type":"string"}},"title":"headers","type":"object"},"idle_conn_timeout":{"description":"IdleConnTimeout is the maximum amount of time a connection will remain open before closing itself.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"idle_conn_timeout","type":"string"},"indices":{"description":"Indices defines the indices to scrape.\nSee https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-stats.html#index-stats-api-path-params\nfor which names are viable.\nIf Indices is empty, no indices will be scraped.","items":{"type":"string"},"title":"indices","type":"array"},"initial_delay":{"title":"initial_delay","type":"string"},"max_conns_per_host":{"description":"MaxConnsPerHost limits the total number of connections per host, including connections in the dialing,\nactive, and idle states.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_conns_per_host","type":"integer"},"max_idle_conns":{"description":"MaxIdleConns is used to set a limit to the maximum idle HTTP connections the client can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns","type":"integer"},"max_idle_conns_per_host":{"description":"MaxIdleConnsPerHost is used to set a limit to the maximum idle HTTP connections the host can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns_per_host","type":"integer"},"metrics":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricsConfig","title":"metrics"},"nodes":{"description":"Nodes defines the nodes to scrape.\nSee https://www.elastic.co/guide/en/elasticsearch/reference/7.9/cluster.html#cluster-nodes for which selectors may be used here.\nIf Nodes is empty, no nodes will be scraped.","items":{"type":"string"},"title":"nodes","type":"array"},"password":{"description":"Password is the password used when making REST calls to elasticsearch. Must be specified if Username is. Not required.","title":"password","type":"string"},"read_buffer_size":{"description":"ReadBufferSize for HTTP client. See http.Transport.ReadBufferSize.","title":"read_buffer_size","type":"integer"},"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"},"skip_cluster_metrics":{"description":"SkipClusterMetrics indicates whether cluster level metrics from /_cluster/* endpoints should be scraped or not.","title":"skip_cluster_metrics","type":"boolean"},"timeout":{"description":"Timeout parameter configures `http.Client.Timeout`.","title":"timeout","type":"string"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","description":"TLSSetting struct exposes TLS client configuration.","title":"tls"},"username":{"description":"Username is the username used when making REST calls to elasticsearch. Must be specified if Password is. Not required.","title":"username","type":"string"},"write_buffer_size":{"description":"WriteBufferSize for HTTP client. See http.Transport.WriteBufferSize.","title":"write_buffer_size","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig":{"additionalProperties":false,"description":"MetricConfig provides common config for a particular metric.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricsConfig":{"additionalProperties":false,"description":"MetricsConfig provides config for elasticsearch metrics.","properties":{"elasticsearch.breaker.memory.estimated":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.breaker.memory.estimated"},"elasticsearch.breaker.memory.limit":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.breaker.memory.limit"},"elasticsearch.breaker.tripped":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.breaker.tripped"},"elasticsearch.cluster.data_nodes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.cluster.data_nodes"},"elasticsearch.cluster.health":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.cluster.health"},"elasticsearch.cluster.in_flight_fetch":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.cluster.in_flight_fetch"},"elasticsearch.cluster.indices.cache.evictions":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.cluster.indices.cache.evictions"},"elasticsearch.cluster.nodes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.cluster.nodes"},"elasticsearch.cluster.pending_tasks":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.cluster.pending_tasks"},"elasticsearch.cluster.published_states.differences":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.cluster.published_states.differences"},"elasticsearch.cluster.published_states.full":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.cluster.published_states.full"},"elasticsearch.cluster.shards":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.cluster.shards"},"elasticsearch.cluster.state_queue":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.cluster.state_queue"},"elasticsearch.cluster.state_update.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.cluster.state_update.count"},"elasticsearch.cluster.state_update.time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.cluster.state_update.time"},"elasticsearch.index.cache.evictions":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.index.cache.evictions"},"elasticsearch.index.cache.memory.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.index.cache.memory.usage"},"elasticsearch.index.cache.size":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.index.cache.size"},"elasticsearch.index.documents":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.index.documents"},"elasticsearch.index.operations.completed":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.index.operations.completed"},"elasticsearch.index.operations.merge.docs_count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.index.operations.merge.docs_count"},"elasticsearch.index.operations.merge.size":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.index.operations.merge.size"},"elasticsearch.index.operations.time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.index.operations.time"},"elasticsearch.index.segments.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.index.segments.count"},"elasticsearch.index.segments.memory":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.index.segments.memory"},"elasticsearch.index.segments.size":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.index.segments.size"},"elasticsearch.index.shards.size":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.index.shards.size"},"elasticsearch.index.translog.operations":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.index.translog.operations"},"elasticsearch.index.translog.size":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.index.translog.size"},"elasticsearch.indexing_pressure.memory.limit":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.indexing_pressure.memory.limit"},"elasticsearch.indexing_pressure.memory.total.primary_rejections":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.indexing_pressure.memory.total.primary_rejections"},"elasticsearch.indexing_pressure.memory.total.replica_rejections":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.indexing_pressure.memory.total.replica_rejections"},"elasticsearch.memory.indexing_pressure":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.memory.indexing_pressure"},"elasticsearch.node.cache.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.cache.count"},"elasticsearch.node.cache.evictions":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.cache.evictions"},"elasticsearch.node.cache.memory.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.cache.memory.usage"},"elasticsearch.node.cache.size":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.cache.size"},"elasticsearch.node.cluster.connections":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.cluster.connections"},"elasticsearch.node.cluster.io":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.cluster.io"},"elasticsearch.node.disk.io.read":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.disk.io.read"},"elasticsearch.node.disk.io.write":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.disk.io.write"},"elasticsearch.node.documents":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.documents"},"elasticsearch.node.fs.disk.available":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.fs.disk.available"},"elasticsearch.node.fs.disk.free":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.fs.disk.free"},"elasticsearch.node.fs.disk.total":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.fs.disk.total"},"elasticsearch.node.http.connections":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.http.connections"},"elasticsearch.node.ingest.documents":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.ingest.documents"},"elasticsearch.node.ingest.documents.current":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.ingest.documents.current"},"elasticsearch.node.ingest.operations.failed":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.ingest.operations.failed"},"elasticsearch.node.open_files":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.open_files"},"elasticsearch.node.operations.completed":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.operations.completed"},"elasticsearch.node.operations.current":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.operations.current"},"elasticsearch.node.operations.get.completed":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.operations.get.completed"},"elasticsearch.node.operations.get.time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.operations.get.time"},"elasticsearch.node.operations.time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.operations.time"},"elasticsearch.node.pipeline.ingest.documents.current":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.pipeline.ingest.documents.current"},"elasticsearch.node.pipeline.ingest.documents.preprocessed":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.pipeline.ingest.documents.preprocessed"},"elasticsearch.node.pipeline.ingest.operations.failed":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.pipeline.ingest.operations.failed"},"elasticsearch.node.script.cache_evictions":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.script.cache_evictions"},"elasticsearch.node.script.compilation_limit_triggered":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.script.compilation_limit_triggered"},"elasticsearch.node.script.compilations":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.script.compilations"},"elasticsearch.node.segments.memory":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.segments.memory"},"elasticsearch.node.shards.data_set.size":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.shards.data_set.size"},"elasticsearch.node.shards.reserved.size":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.shards.reserved.size"},"elasticsearch.node.shards.size":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.shards.size"},"elasticsearch.node.thread_pool.tasks.finished":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.thread_pool.tasks.finished"},"elasticsearch.node.thread_pool.tasks.queued":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.thread_pool.tasks.queued"},"elasticsearch.node.thread_pool.threads":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.thread_pool.threads"},"elasticsearch.node.translog.operations":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.translog.operations"},"elasticsearch.node.translog.size":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.translog.size"},"elasticsearch.node.translog.uncommitted.size":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.node.translog.uncommitted.size"},"elasticsearch.os.cpu.load_avg.15m":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.os.cpu.load_avg.15m"},"elasticsearch.os.cpu.load_avg.1m":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.os.cpu.load_avg.1m"},"elasticsearch.os.cpu.load_avg.5m":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.os.cpu.load_avg.5m"},"elasticsearch.os.cpu.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.os.cpu.usage"},"elasticsearch.os.memory":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.os.memory"},"elasticsearch.process.cpu.time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.process.cpu.time"},"elasticsearch.process.cpu.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.process.cpu.usage"},"elasticsearch.process.memory.virtual":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"elasticsearch.process.memory.virtual"},"jvm.classes.loaded":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"jvm.classes.loaded"},"jvm.gc.collections.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"jvm.gc.collections.count"},"jvm.gc.collections.elapsed":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"jvm.gc.collections.elapsed"},"jvm.memory.heap.committed":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"jvm.memory.heap.committed"},"jvm.memory.heap.max":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"jvm.memory.heap.max"},"jvm.memory.heap.used":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"jvm.memory.heap.used"},"jvm.memory.heap.utilization":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"jvm.memory.heap.utilization"},"jvm.memory.nonheap.committed":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"jvm.memory.nonheap.committed"},"jvm.memory.nonheap.used":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"jvm.memory.nonheap.used"},"jvm.memory.pool.max":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"jvm.memory.pool.max"},"jvm.memory.pool.used":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"jvm.memory.pool.used"},"jvm.threads.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.MetricConfig","title":"jvm.threads.count"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for elasticsearch resource attributes.","properties":{"elasticsearch.cluster.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.ResourceAttributeConfig","title":"elasticsearch.cluster.name"},"elasticsearch.index.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.ResourceAttributeConfig","title":"elasticsearch.index.name"},"elasticsearch.node.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.ResourceAttributeConfig","title":"elasticsearch.node.name"},"elasticsearch.node.version":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.internal.metadata.ResourceAttributeConfig","title":"elasticsearch.node.version"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.fluentforwardreceiver.Config":{"additionalProperties":false,"description":"Config defines configuration for the fluentforward receiver.","properties":{"endpoint":{"description":"The address to listen on for incoming Fluent Forward events.  Should be\nof the form `\u003cip addr\u003e:\u003cport\u003e` (TCP) or `unix://\u003csocket_path\u003e` (Unix\ndomain socket).","title":"endpoint","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.httpcheckreceiver.Config":{"additionalProperties":false,"description":"Config defines the configuration for the various elements of the receiver agent.","markdownDescription":"# HTTP Check Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [development]: metrics   |\n| Distributions | [contrib], [sumo] |\n\n[development]: https://github.com/open-telemetry/opentelemetry-collector#development\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe HTTP Check Receiver can be used for synthethic checks against HTTP endpoints. This receiver will make a request to the specified `endpoint` using the\nconfigured `method`. This scraper generates a metric with a label for each HTTP response status class with a value of `1` if the status code matches the\nclass. For example, the following metrics will be generated if the endpoint returned a `200`:\n\n```\nhttpcheck.status{http.status_class:1xx, http.status_code:200,...} = 0\nhttpcheck.status{http.status_class:2xx, http.status_code:200,...} = 1\nhttpcheck.status{http.status_class:3xx, http.status_code:200,...} = 0\nhttpcheck.status{http.status_class:4xx, http.status_code:200,...} = 0\nhttpcheck.status{http.status_class:5xx, http.status_code:200,...} = 0\n```\n\n## Configuration\n\nThe following configuration settings are required:\n\n- `endpoint`: The URL of the endpoint to be monitored.\n\nThe following configuration settings are optional:\n\n- `method` (default: `GET`): The method used to call the endpoint.\n- `collection_interval` (default = `60s`): This receiver collects metrics on an interval. Valid time units are `ns`, `us` (or `Âµs`), `ms`, `s`, `m`, `h`.\n- `initial_delay` (default = `1s`): defines how long this receiver waits before starting.\n\n### Example Configuration\n\n```yaml\nreceivers:\n  httpcheck:\n    endpoint: http://endpoint:80\n    method: GET\n    collection_interval: 10s\n```\n\n## Metrics\n\nDetails about the metrics produced by this receiver can be found in [documentation.md](./documentation.md)","properties":{"CustomRoundTripper":{"description":"Custom Round Tripper to allow for individual components to intercept HTTP requests","title":"CustomRoundTripper"},"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth configuration for outgoing HTTP calls.","title":"auth"},"collection_interval":{"title":"collection_interval","type":"string"},"compression":{"description":"The compression key for supported compression types within collector.","title":"compression","type":"string"},"endpoint":{"description":"The target URL to send data to (e.g.: http://some.url:9411/v1/traces).","title":"endpoint","type":"string"},"headers":{"description":"Additional headers attached to each HTTP request sent by the client.\nExisting header values are overwritten if collision happens.\nHeader values are opaque since they may be sensitive.","patternProperties":{".*":{"type":"string"}},"title":"headers","type":"object"},"idle_conn_timeout":{"description":"IdleConnTimeout is the maximum amount of time a connection will remain open before closing itself.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"idle_conn_timeout","type":"string"},"initial_delay":{"title":"initial_delay","type":"string"},"max_conns_per_host":{"description":"MaxConnsPerHost limits the total number of connections per host, including connections in the dialing,\nactive, and idle states.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_conns_per_host","type":"integer"},"max_idle_conns":{"description":"MaxIdleConns is used to set a limit to the maximum idle HTTP connections the client can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns","type":"integer"},"max_idle_conns_per_host":{"description":"MaxIdleConnsPerHost is used to set a limit to the maximum idle HTTP connections the host can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns_per_host","type":"integer"},"method":{"title":"method","type":"string"},"metrics":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.httpcheckreceiver.internal.metadata.MetricsConfig","title":"metrics"},"read_buffer_size":{"description":"ReadBufferSize for HTTP client. See http.Transport.ReadBufferSize.","title":"read_buffer_size","type":"integer"},"timeout":{"description":"Timeout parameter configures `http.Client.Timeout`.","title":"timeout","type":"string"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","description":"TLSSetting struct exposes TLS client configuration.","title":"tls"},"write_buffer_size":{"description":"WriteBufferSize for HTTP client. See http.Transport.WriteBufferSize.","title":"write_buffer_size","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.httpcheckreceiver.internal.metadata.MetricConfig":{"additionalProperties":false,"description":"MetricConfig provides common config for a particular metric.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.httpcheckreceiver.internal.metadata.MetricsConfig":{"additionalProperties":false,"description":"MetricsConfig provides config for httpcheck metrics.","properties":{"httpcheck.duration":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.httpcheckreceiver.internal.metadata.MetricConfig","title":"httpcheck.duration"},"httpcheck.error":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.httpcheckreceiver.internal.metadata.MetricConfig","title":"httpcheck.error"},"httpcheck.status":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.httpcheckreceiver.internal.metadata.MetricConfig","title":"httpcheck.status"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.jaegerreceiver.Config":{"additionalProperties":false,"description":"Config defines configuration for Jaeger receiver.","properties":{"protocols":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.jaegerreceiver.Protocols","title":"protocols"},"remote_sampling":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.jaegerreceiver.RemoteSamplingConfig","title":"remote_sampling"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.jaegerreceiver.ProtocolUDP":{"additionalProperties":false,"description":"ProtocolUDP is the configuration for a UDP protocol.","properties":{"endpoint":{"title":"endpoint","type":"string"},"max_packet_size":{"title":"max_packet_size","type":"integer"},"queue_size":{"title":"queue_size","type":"integer"},"socket_buffer_size":{"title":"socket_buffer_size","type":"integer"},"workers":{"title":"workers","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.jaegerreceiver.Protocols":{"additionalProperties":false,"description":"Protocols is the configuration for the supported protocols.","properties":{"grpc":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configgrpc.GRPCServerSettings","title":"grpc"},"thrift_binary":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.jaegerreceiver.ProtocolUDP","title":"thrift_binary"},"thrift_compact":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.jaegerreceiver.ProtocolUDP","title":"thrift_compact"},"thrift_http":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.confighttp.HTTPServerSettings","title":"thrift_http"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.jaegerreceiver.RemoteSamplingConfig":{"additionalProperties":false,"description":"RemoteSamplingConfig defines config key for remote sampling fetch endpoint","markdownDescription":"# Jaeger Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: traces   |\n| Distributions | [core], [contrib], [aws], [observiq], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[core]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nReceives trace data in [Jaeger](https://www.jaegertracing.io/) format.\n\n## Getting Started\n\nBy default, the Jaeger receiver will not serve any protocol. A protocol must be\nnamed under the `protocols` object for the jaeger receiver to start. The\nbelow protocols are supported, each supports an optional `endpoint`\nobject configuration parameter.\n\n- `grpc` (default `endpoint` = 0.0.0.0:14250)\n- `thrift_binary` (default `endpoint` = 0.0.0.0:6832)\n- `thrift_compact` (default `endpoint` = 0.0.0.0:6831)\n- `thrift_http` (default `endpoint` = 0.0.0.0:14268)\n\nExamples:\n\n```yaml\nreceivers:\n  jaeger:\n    protocols:\n      grpc:\n  jaeger/withendpoint:\n    protocols:\n      grpc:\n        endpoint: 0.0.0.0:14260\n```\n\n## Advanced Configuration\n\nUDP protocols (currently `thrift_binary` and `thrift_compact`) allow setting additional\nserver options:\n\n- `queue_size` (default 1000) sets max not yet handled requests to server\n- `max_packet_size` (default 65_000) sets max UDP packet size\n- `workers` (default 10) sets number of workers consuming the server queue\n- `socket_buffer_size` (default 0 - no buffer) sets buffer size of connection socket in bytes\n\nExamples:\n\n```yaml\nprotocols:\n  thrift_binary:\n    endpoint: 0.0.0.0:6832\n    queue_size: 5_000\n    max_packet_size: 131_072\n    workers: 50\n    socket_buffer_size: 8_388_608\n```\n\nSeveral helper files are leveraged to provide additional capabilities automatically:\n\n- [gRPC settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/configgrpc/README.md) including CORS\n- [TLS and mTLS settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/configtls/README.md)\n\n## Remote Sampling\n\nSince version [v0.61.0](https://github.com/open-telemetry/opentelemetry-collector-contrib/releases/tag/v0.61.0), remote sampling is no longer supported by the jaeger receiver. Since version [v0.59.0](https://github.com/open-telemetry/opentelemetry-collector-contrib/releases/tag/v0.59.0), the [jaegerremotesapmpling](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/v0.61.0/extension/jaegerremotesampling/README.md) extension is available that can be used instead.","properties":{"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth configuration for outgoing RPCs.","title":"auth"},"balancer_name":{"description":"Sets the balancer in grpclb_policy to discover the servers. Default is pick_first.\nhttps://github.com/grpc/grpc-go/blob/master/examples/features/load_balancing/README.md","title":"balancer_name","type":"string"},"compression":{"description":"The compression key for supported compression types within collector.","title":"compression","type":"string"},"endpoint":{"description":"The target to which the exporter is going to send traces or metrics,\nusing the gRPC protocol. The valid syntax is described at\nhttps://github.com/grpc/grpc/blob/master/doc/naming.md.","title":"endpoint","type":"string"},"headers":{"description":"The headers associated with gRPC requests.","patternProperties":{".*":{"type":"string"}},"title":"headers","type":"object"},"host_endpoint":{"title":"host_endpoint","type":"string"},"keepalive":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configgrpc.KeepaliveClientConfig","description":"The keepalive parameters for gRPC client. See grpc.WithKeepaliveParams.\n(https://godoc.org/google.golang.org/grpc#WithKeepaliveParams).","title":"keepalive"},"read_buffer_size":{"description":"ReadBufferSize for gRPC client. See grpc.WithReadBufferSize.\n(https://godoc.org/google.golang.org/grpc#WithReadBufferSize).","title":"read_buffer_size","type":"integer"},"strategy_file":{"title":"strategy_file","type":"string"},"strategy_file_reload_interval":{"title":"strategy_file_reload_interval","type":"string"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","description":"TLSSetting struct exposes TLS client configuration.","title":"tls"},"wait_for_ready":{"description":"WaitForReady parameter configures client to wait for ready state before sending data.\n(https://github.com/grpc/grpc/blob/master/doc/wait-for-ready.md)","title":"wait_for_ready","type":"boolean"},"write_buffer_size":{"description":"WriteBufferSize for gRPC gRPC. See grpc.WithWriteBufferSize.\n(https://godoc.org/google.golang.org/grpc#WithWriteBufferSize).","title":"write_buffer_size","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.jmxreceiver.Config":{"additionalProperties":false,"markdownDescription":"# JMX Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [alpha]: metrics   |\n| Distributions | [contrib], [observiq], [splunk], [sumo] |\n\n[alpha]: https://github.com/open-telemetry/opentelemetry-collector#alpha\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\n### Overview\n\nThe JMX Receiver will work in conjunction with the [OpenTelemetry JMX Metric Gatherer](https://github.com/open-telemetry/opentelemetry-java-contrib/blob/main/jmx-metrics/README.md)\nto report metrics from a target MBean server using a built-in `otel` helper-utilizing Groovy script.\n\n### Details\n\nThis receiver will launch a child JRE process running the JMX Metric Gatherer configured with your specified JMX\nconnection information and target Groovy script.  It then reports metrics to an implicitly created OTLP receiver.\nIn order to use you will need to download the most [recent release](https://repo1.maven.org/maven2/io/opentelemetry/contrib/opentelemetry-java-contrib-jmx-metrics/)\nof the JMX Metric Gatherer JAR and configure the receiver with its path.  It is assumed that the JRE is\navailable on your system.\n\n# Configuration\n\nNote: this receiver is in alpha and functionality and configuration fields are subject to change.\n\nExample configuration:\n\n```yaml\nreceivers:\n  jmx:\n    jar_path: /opt/opentelemetry-java-contrib-jmx-metrics.jar\n    endpoint: my_jmx_host:12345\n    target_system: jvm\n    collection_interval: 10s\n    initial_delay: 1s\n    # optional: the same as specifying OTLP receiver endpoint.\n    otlp:\n      endpoint: mycollectorotlpreceiver:4317\n    username: my_jmx_username\n    # determined by the environment variable value\n    password: ${env:MY_JMX_PASSWORD}\n    resource_attributes: my.attr=my.value,my.other.attr=my.other.value\n    log_level: info\n    additional_jars:\n      - /path/to/other.jar\n```\n\n### jar_path (default: `/opt/opentelemetry-java-contrib-jmx-metrics.jar`)\n\nThe path for the JMX Metric Gatherer uber JAR to run. This must represent a released version 1.9+ of the jar, \nwhich can be downloaded from [github](https://github.com/open-telemetry/opentelemetry-java-contrib/releases). \nIf a non-released version is required, you can specify a custom version by providing the sha256 hash of your \ncustom version of the jar during collector build time using the `ldflags` option. \n\n```bash\ngo build -ldflags \"-X github.com/open-telemetry/opentelemetry-collector-contrib/receiver/jmxreceiver.MetricsGathererHash=\u003csha256hash\u003e\" ...\n```\n\n### endpoint\nThe [JMX Service URL](https://docs.oracle.com/javase/8/docs/api/javax/management/remote/JMXServiceURL.html) or host\nand port used to construct the Service URL the Metric Gatherer's JMX client should use. Value must be in the form of\n`service:jmx:\u003cprotocol\u003e:\u003csap\u003e` or `host:port`. Values in `host:port` form will be used to create a Service URL of\n`service:jmx:rmi:///jndi/rmi://\u003chost\u003e:\u003cport\u003e/jmxrmi`.\n\nWhen in or coerced to `service:jmx:\u003cprotocol\u003e:\u003csap\u003e` form, corresponds to the `otel.jmx.service.url` property.\n\n_Required._\n\n### target_system\n\nThe built-in target system (or systems) metric gatherer script to run.\nMust be a subset of: `\"activemq\"`, `\"cassandra\"`, `\"hbase\"`, `\"hadoop\"`,  `\"jetty\"`, `\"jvm\"`, `\"kafka\"`, `\"kafka-consumer\"`, `\"kafka-producer\"`, `\"solr\"`, `\"tomcat\"`, `\"wildfly\"`.\n\nIf additional target systems must be supported (because of a custom JMX metrics gatherer jar configured using the \n`MetricsGathererHash` build time config), they can be added with another build time flag.\n\n```bash\ngo build -ldflags \"-X github.com/open-telemetry/opentelemetry-collector-contrib/receiver/jmxreceiver.MetricsGathererHash=\u003csha256hash\u003e\n       -X github.com/open-telemetry/opentelemetry-collector-contrib/receiver/jmxreceiver.AdditionalTargetSystems=newtarget,othernewtarget\" ...\n```\n\nCorresponds to the `otel.jmx.target.system` property.\n\n### collection_interval (default: `10s`)\n\nThe interval time for the Groovy script to be run and metrics to be exported by the JMX Metric Gatherer within the persistent JRE process.\n\nCorresponds to the `otel.jmx.interval.milliseconds` property.\n\n### initial_delay (default: `1s`)\n\nDefines how long this receiver waits before starting.\n\n### username\n\nThe username to use for JMX authentication.\n\nCorresponds to the `otel.jmx.username` property.\n\n### password\n\nThe password to use for JMX authentication.\n\nCorresponds to the `otel.jmx.password` property.\n\n### otlp.endpoint (default: `0.0.0.0:\u003crandom open port\u003e`)\n\nThe otlp exporter endpoint to which to listen and submit metrics.\n\nCorresponds to the `otel.exporter.otlp.endpoint` property.\n\n### otlp.timeout (default: `5s`)\n\nThe otlp exporter request timeout.\n\nCorresponds to the `otel.exporter.otlp.metric.timeout` property.\n\n### otlp.headers\n\nThe headers to include in otlp metric submission requests.\n\nCorresponds to the `otel.exporter.otlp.metadata` property.\n\n### keystore_path\n\nThe keystore path is required if SSL is enabled on the target JVM.\n\nCorresponds to the `javax.net.ssl.keyStore` property.\n\n### keystore_password\n\nThe keystore file password if required by SSL.\n\nCorresponds to the `javax.net.ssl.keyStorePassword` property.\n\n### keystore_type\n\nThe keystore type if required by SSL.\n\nCorresponds to the `javax.net.ssl.keyStoreType` property.\n\n### truststore_path \n\nThe truststore path if the SSL profile is required.\n\nCorresponds to the `javax.net.ssl.trustStore` property.\n\n### truststore_password\n\nThe truststore file password if required by SSL.\n\nCorresponds to the `javax.net.ssl.trustStorePassword` property.\n\n### truststore_type\n\nThe truststore type if required by SSL.\n\nCorresponds to the `javax.net.ssl.trustStoreType` property.\n\n### remote_profile\n\nSupported JMX remote profiles are TLS in combination with SASL profiles: SASL/PLAIN, SASL/DIGEST-MD5 and SASL/CRAM-MD5.\nShould be one of: `\"SASL/PLAIN\"`, `\"SASL/DIGEST-MD5\"`, `\"SASL/CRAM-MD5\"`, `\"TLS SASL/PLAIN\"`, `\"TLS SASL/DIGEST-MD5\"`,\nor `\"TLS SASL/CRAM-MD5\"`, though no enforcement is applied.\n\nCorresponds to the `otel.jmx.remote.profile` property.\n\n### realm\n\nThe realm, as required by remote profile SASL/DIGEST-MD5.\n\nCorresponds to the `otel.jmx.realm` property.\n\n### additional_jars\n\nAdditional JARs to be included in the java command classpath. This is currently only used for support for `wildfly`, where the Additional Jar should be a version of the jboss-client jar found on your wildfly installation.\n\n### resource_attributes\n\nList of resource attributes that will be applied to any metrics emitted from the metrics gatherer.\n\nCorresponds to the `otel.resource.attributes` property.\n\n### log_level\n\nSLF4J log level for the JMX metrics gatherer. Must be one of: `\"trace\"`, `\"debug\"`, `\"info\"`, `\"warn\"`, `\"error\"`, `\"off\"`. If not provided, will attempt to match to the current log level of the collector.\n\nCorresponds to the `org.slf4j.simpleLogger.defaultLogLevel` property.","properties":{"additional_jars":{"description":"Array of additional JARs to be added to the the class path when launching the JMX Metric Gatherer JAR","items":{"type":"string"},"title":"additional_jars","type":"array"},"collection_interval":{"description":"The duration in between groovy script invocations and metric exports (10 seconds by default).\nWill be converted to milliseconds.","title":"collection_interval","type":"string"},"endpoint":{"description":"The Service URL or host:port for the target coerced to one of form: service:jmx:rmi:///jndi/rmi://\u003chost\u003e:\u003cport\u003e/jmxrmi.","title":"endpoint","type":"string"},"jar_path":{"description":"The path for the JMX Metric Gatherer uber JAR (/opt/opentelemetry-java-contrib-jmx-metrics.jar by default).","title":"jar_path","type":"string"},"keystore_password":{"description":"The keystore password for SSL","title":"keystore_password","type":"string"},"keystore_path":{"description":"The keystore path for SSL","title":"keystore_path","type":"string"},"keystore_type":{"description":"The keystore type for SSL","title":"keystore_type","type":"string"},"log_level":{"description":"Log level used by the JMX metric gatherer. Should be one of:\n`\"trace\"`, `\"debug\"`, `\"info\"`, `\"warn\"`, `\"error\"`, `\"off\"`","title":"log_level","type":"string"},"otlp":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.jmxreceiver.otlpExporterConfig","description":"The exporter settings for","title":"otlp"},"password":{"description":"The JMX password","title":"password","type":"string"},"realm":{"description":"The SASL/DIGEST-MD5 realm","title":"realm","type":"string"},"remote_profile":{"description":"The JMX remote profile.  Should be one of:\n`\"SASL/PLAIN\"`, `\"SASL/DIGEST-MD5\"`, `\"SASL/CRAM-MD5\"`, `\"TLS SASL/PLAIN\"`, `\"TLS SASL/DIGEST-MD5\"`, or\n`\"TLS SASL/CRAM-MD5\"`, though no enforcement is applied.","title":"remote_profile","type":"string"},"resource_attributes":{"description":"Map of resource attributes used by the Java SDK Autoconfigure to set resource attributes","patternProperties":{".*":{"type":"string"}},"title":"resource_attributes","type":"object"},"target_system":{"description":"The target system for the metric gatherer whose built in groovy script to run.","title":"target_system","type":"string"},"truststore_password":{"description":"The truststore password for SSL","title":"truststore_password","type":"string"},"truststore_path":{"description":"The truststore path for SSL","title":"truststore_path","type":"string"},"truststore_type":{"description":"The truststore type for SSL","title":"truststore_type","type":"string"},"username":{"description":"The JMX username","title":"username","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.jmxreceiver.otlpExporterConfig":{"additionalProperties":false,"properties":{"endpoint":{"title":"endpoint","type":"string"},"headers":{"patternProperties":{".*":{"type":"string"}},"title":"headers","type":"object"},"timeout":{"description":"Timeout is the timeout for every attempt to send data to the backend.","title":"timeout","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.k8sclusterreceiver.Config":{"additionalProperties":false,"description":"Config defines configuration for kubernetes cluster receiver.","markdownDescription":"# Kubernetes Cluster Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [contrib], [observiq], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe Kubernetes Cluster receiver collects cluster-level metrics from the Kubernetes\nAPI server. It uses the K8s API to listen for updates. A single instance of this\nreceiver can be used to monitor a cluster.\n\nCurrently this receiver supports authentication via service accounts only. See [example](#example)\nfor more information.\n\n## Configuration\n\nThe following settings are required:\n\n- `auth_type` (default = `serviceAccount`): Determines how to authenticate to\nthe K8s API server. This can be one of `none` (for no auth), `serviceAccount`\n(to use the standard service account token provided to the agent pod), or\n`kubeConfig` to use credentials from `~/.kube/config`.\n\nThe following settings are optional:\n\n- `collection_interval` (default = `10s`): This receiver continuously watches\nfor events using K8s API. However, the metrics collected are emitted only\nonce every collection interval. `collection_interval` will determine the\nfrequency at which metrics are emitted by this receiver.\n- `node_conditions_to_report` (default = `[Ready]`): An array of node\nconditions this receiver should report. See\n[here](https://kubernetes.io/docs/concepts/architecture/nodes/#condition) for\nlist of node conditions. The receiver will emit one metric per entry in the\narray.\n- `distribution` (default = `kubernetes`): The Kubernetes distribution being used\nby the cluster. Currently supported versions are `kubernetes` and `openshift`. Setting\nthe value to `openshift` enables OpenShift specific metrics in addition to standard\nkubernetes ones.\n- `allocatable_types_to_report` (default = `[]`): An array of allocatable resource types this receiver should report.\nThe following allocatable resource types are available.\n  - cpu\n  - memory\n  - ephemeral-storage\n  - storage\n\nExample:\n\n```yaml\n  k8s_cluster:\n    auth_type: kubeConfig\n    node_conditions_to_report: [Ready, MemoryPressure]\n    allocatable_types_to_report: [cpu, memory]\n```\n\nThe full list of settings exposed for this receiver are documented [here](./config.go)\nwith detailed sample configurations [here](./testdata/config.yaml).\n\n### node_conditions_to_report\n\nFor example, with the config below the receiver will emit two metrics\n`k8s.node.condition_ready` and `k8s.node.condition_memory_pressure`, one\nfor each condition in the config. The value will be `1` if the `ConditionStatus` for the\ncorresponding `Condition` is `True`, `0` if it is `False` and -1 if it is `Unknown`.\n\n```yaml\n...\nk8s_cluster:\n  node_conditions_to_report:\n    - Ready\n    - MemoryPressure\n...\n```\n\n### metadata_exporters\n\nA list of metadata exporters to which metadata being collected by this receiver\nshould be synced. Exporters specified in this list are expected to implement the\nfollowing interface. If an exporter that does not implement the interface is listed,\nstartup will fail.\n\n```yaml\ntype MetadataExporter interface {\n  ConsumeMetadata(metadata []*MetadataUpdate) error\n}\n\ntype MetadataUpdate struct {\n  ResourceIDKey string\n  ResourceID    ResourceID\n  MetadataDelta\n}\n\ntype MetadataDelta struct {\n  MetadataToAdd    map[string]string\n  MetadataToRemove map[string]string\n  MetadataToUpdate map[string]string\n}\n```\n\nSee [here](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/pkg/experimentalmetricmetadata/metadata.go) for details about the above types.\n\n\n## Example\n\nHere is an example deployment of the collector that sets up this receiver along with\nthe logging exporter.\n\nFollow the below sections to setup various Kubernetes resources required for the deployment.\n\n### Configuration\n\nCreate a ConfigMap with the config for `otelcontribcol`:\n\n```bash\ncat \u003c\u003cEOF | kubectl apply -f -\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: otelcontribcol\n  labels:\n    app: otelcontribcol\ndata:\n  config.yaml: |\n    receivers:\n      k8s_cluster:\n        collection_interval: 10s\n    exporters:\n      logging:\n    service:\n      pipelines:\n        metrics:\n          receivers: [k8s_cluster]\n          exporters: [logging]\nEOF\n```\n\n### Service Account\n\nCreate a service account that the collector should use.\n\n```bash\n\u003c\u003cEOF | kubectl apply -f -\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  labels:\n    app: otelcontribcol\n  name: otelcontribcol\nEOF\n```\n\n### RBAC\n\nUse the below commands to create a `ClusterRole` with required permissions and a \n`ClusterRoleBinding` to grant the role to the service account created above.\n\n```bash\n\u003c\u003cEOF | kubectl apply -f -\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: otelcontribcol\n  labels:\n    app: otelcontribcol\nrules:\n- apiGroups:\n  - \"\"\n  resources:\n  - events\n  - namespaces\n  - namespaces/status\n  - nodes\n  - nodes/spec\n  - pods\n  - pods/status\n  - replicationcontrollers\n  - replicationcontrollers/status\n  - resourcequotas\n  - services\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - apps\n  resources:\n  - daemonsets\n  - deployments\n  - replicasets\n  - statefulsets\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - extensions\n  resources:\n  - daemonsets\n  - deployments\n  - replicasets\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - batch\n  resources:\n  - jobs\n  - cronjobs\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n    - autoscaling\n  resources:\n    - horizontalpodautoscalers\n  verbs:\n    - get\n    - list\n    - watch\nEOF\n```\n\n```bash\n\u003c\u003cEOF | kubectl apply -f -\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: otelcontribcol\n  labels:\n    app: otelcontribcol\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: otelcontribcol\nsubjects:\n- kind: ServiceAccount\n  name: otelcontribcol\n  namespace: default\nEOF\n```\n\n### Deployment\n\nCreate a [Deployment](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/) to deploy the collector.\n\n```bash\n\u003c\u003cEOF | kubectl apply -f -\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: otelcontribcol\n  labels:\n    app: otelcontribcol\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: otelcontribcol\n  template:\n    metadata:\n      labels:\n        app: otelcontribcol\n    spec:\n      serviceAccountName: otelcontribcol\n      containers:\n      - name: otelcontribcol\n        image: otel/opentelemetry-collector-contrib\n        args: [\"--config\", \"/etc/config/config.yaml\"]\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n        imagePullPolicy: IfNotPresent\n      volumes:\n        - name: config\n          configMap:\n            name: otelcontribcol\nEOF\n```\n\n### OpenShift\n\nYou can enable OpenShift support to collect OpenShift specific metrics in addition to the default\nkubernetes ones. To do this, set the `distribution` key to `openshift`.\n\nExample:\n\n```yaml\n  k8s_cluster:\n    distribution: openshift\n```\n\nAdd the following rules to your ClusterRole:\n\n```yaml\n- apigroups:\n  - quota.openshift.io\n  resources:\n  - clusterresourcequotas\n  verbs:\n  - get\n  - list\n  - watch\n```","properties":{"allocatable_types_to_report":{"description":"Allocate resource types to report. See all resource types, see\nhere: https://kubernetes.io/docs/concepts/architecture/nodes/#capacity","items":{"type":"string"},"title":"allocatable_types_to_report","type":"array"},"auth_type":{"description":"How to authenticate to the K8s API server.  This can be one of `none`\n(for no auth), `serviceAccount` (to use the standard service account\ntoken provided to the agent pod), or `kubeConfig` to use credentials\nfrom `~/.kube/config`.","title":"auth_type","type":"string"},"collection_interval":{"description":"Collection interval for metrics.","title":"collection_interval","type":"string"},"distribution":{"description":"Whether OpenShift supprot should be enabled or not.","title":"distribution","type":"string"},"metadata_exporters":{"description":"List of exporters to which metadata from this receiver should be forwarded to.","items":{"type":"string"},"title":"metadata_exporters","type":"array"},"node_conditions_to_report":{"description":"Node condition types to report. See all condition types, see\nhere: https://kubernetes.io/docs/concepts/architecture/nodes/#condition.","items":{"type":"string"},"title":"node_conditions_to_report","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.k8seventsreceiver.Config":{"additionalProperties":false,"description":"Config defines configuration for kubernetes events receiver.","markdownDescription":"# Kubernetes Events Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [alpha]: logs   |\n| Distributions | [contrib], [observiq], [splunk], [sumo] |\n\n[alpha]: https://github.com/open-telemetry/opentelemetry-collector#alpha\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe kubernetes Events receiver collects events from the Kubernetes\nAPI server. It collects all the new or updated events that come in.\n\nCurrently this receiver supports authentication via service accounts only.\nSee [example](#example) for more information.\n\n## Configuration\n\nThe following settings are optional:\n\n- `auth_type` (default = `serviceAccount`): Determines how to authenticate to\nthe K8s API server. This can be one of `none` (for no auth), `serviceAccount`\n(to use the standard service account token provided to the agent pod), or\n`kubeConfig` to use credentials from `~/.kube/config`.\n- `namespaces` (default = `all`): An array of `namespaces` to collect events from.\nThis receiver will continuously watch all the `namespaces` mentioned in the array for\nnew events.\n\nExamples:\n\n```yaml\n  k8s_events:\n    auth_type: kubeConfig\n    namespaces: [default, my_namespace]\n```\n\nThe full list of settings exposed for this receiver are documented [here](./config.go)\nwith detailed sample configurations [here](./testdata/config.yaml).\n\n## Example\n\nHere is an example deployment of the collector that sets up this receiver along with\nthe [OTLP Exporter](https://github.com/open-telemetry/opentelemetry-collector/blob/main/exporter/otlpexporter/README.md).\n\nFollow the below sections to setup various Kubernetes resources required for the deployment.\n\n### Configuration\n\nCreate a ConfigMap with the config for `otelcontribcol`. Replace `OTLP_ENDPOINT`\nwith valid value.\n\n```bash\ncat \u003c\u003cEOF | kubectl apply -f -\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: otelcontribcol\n  labels:\n    app: otelcontribcol\ndata:\n  config.yaml: |\n    receivers:\n      k8s_events:\n        namespaces: [default, my_namespace]\n    exporters:\n      otlp:\n        endpoint: \u003cOTLP_ENDPOINT\u003e\n        tls:\n          insecure: true\n\n    service:\n      pipelines:\n        logs:\n          receivers: [k8s_events]\n          exporters: [otlp]\nEOF\n```\n\n### Service Account\n\nCreate a service account that the collector should use.\n\n```bash\n\u003c\u003cEOF | kubectl apply -f -\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  labels:\n    app: otelcontribcol\n  name: otelcontribcol\nEOF\n```\n\n### RBAC\n\nUse the below commands to create a `ClusterRole` with required permissions and a\n`ClusterRoleBinding` to grant the role to the service account created above.\n\n```bash\n\u003c\u003cEOF | kubectl apply -f -\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRole\nmetadata:\n  name: otelcontribcol\n  labels:\n    app: otelcontribcol\nrules:\n- apiGroups:\n  - \"\"\n  resources:\n  - events\n  - namespaces\n  - namespaces/status\n  - nodes\n  - nodes/spec\n  - pods\n  - pods/status\n  - replicationcontrollers\n  - replicationcontrollers/status\n  - resourcequotas\n  - services\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - apps\n  resources:\n  - daemonsets\n  - deployments\n  - replicasets\n  - statefulsets\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - extensions\n  resources:\n  - daemonsets\n  - deployments\n  - replicasets\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - batch\n  resources:\n  - jobs\n  - cronjobs\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n    - autoscaling\n  resources:\n    - horizontalpodautoscalers\n  verbs:\n    - get\n    - list\n    - watch\nEOF\n```\n\n```bash\n\u003c\u003cEOF | kubectl apply -f -\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n  name: otelcontribcol\n  labels:\n    app: otelcontribcol\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: otelcontribcol\nsubjects:\n- kind: ServiceAccount\n  name: otelcontribcol\n  namespace: default\nEOF\n```\n\n### Deployment\n\nCreate a [Deployment](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/) to deploy the collector.\n\n```bash\n\u003c\u003cEOF | kubectl apply -f -\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: otelcontribcol\n  labels:\n    app: otelcontribcol\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: otelcontribcol\n  template:\n    metadata:\n      labels:\n        app: otelcontribcol\n    spec:\n      serviceAccountName: otelcontribcol\n      containers:\n      - name: otelcontribcol\n        image: otelcontribcol:latest # specify image\n        args: [\"--config\", \"/etc/config/config.yaml\"]\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n        imagePullPolicy: IfNotPresent\n      volumes:\n        - name: config\n          configMap:\n            name: otelcontribcol\nEOF\n```","properties":{"auth_type":{"description":"How to authenticate to the K8s API server.  This can be one of `none`\n(for no auth), `serviceAccount` (to use the standard service account\ntoken provided to the agent pod), or `kubeConfig` to use credentials\nfrom `~/.kube/config`.","title":"auth_type","type":"string"},"namespaces":{"description":"List of â€˜namespacesâ€™ to collect events from.","items":{"type":"string"},"title":"namespaces","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.k8sobjectsreceiver.Config":{"additionalProperties":false,"properties":{"auth_type":{"description":"How to authenticate to the K8s API server.  This can be one of `none`\n(for no auth), `serviceAccount` (to use the standard service account\ntoken provided to the agent pod), or `kubeConfig` to use credentials\nfrom `~/.kube/config`.","title":"auth_type","type":"string"},"objects":{"items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.k8sobjectsreceiver.K8sObjectsConfig"},"title":"objects","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.k8sobjectsreceiver.K8sObjectsConfig":{"additionalProperties":false,"markdownDescription":"# Kubernetes Objects Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [alpha]: logs   |\n| Distributions | [contrib], [splunk], [sumo] |\n\n[alpha]: https://github.com/open-telemetry/opentelemetry-collector#alpha\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe kubernetes Objects receiver collects(pull/watch) objects from the Kubernetes API server.\n\nCurrently this receiver supports authentication via service accounts only.\nSee [example](#example) for more information.\n\n## Getting Started\n\nThe following is example configuration\n\n```yaml\n  k8sobjects:\n    auth_type: serviceAccount\n    objects:\n      - name: pods\n        mode: pull\n        label_selector: environment in (production),tier in (frontend)\n        field_selector: status.phase=Running\n        interval: 15m\n      - name: events\n        mode: watch\n        group: events.k8s.io\n        namespaces: [default]\n```\n\nBrief description of configuration properties:\n- `auth_type` (default = `serviceAccount`): Determines how to authenticate to\nthe K8s API server. This can be one of `none` (for no auth), `serviceAccount`\n(to use the standard service account token provided to the agent pod), or\n`kubeConfig` to use credentials from `~/.kube/config`.\n- `name`: Name of the resource object to collect\n- `mode`: define in which way it collects this type of object, either \"poll\" or \"watch\".\n  - `pull` mode will read all objects of this type use the list API at an interval.\n  - `watch` mode will setup a long connection using the watch API to just get updates.\n- `label_selector`: select objects by label(s)\n- `field_selector`: select objects by field(s)\n- `interval`: the interval at which object is pulled, default 60 minutes. Only useful for `pull` mode.\n- `resource_version` allows watch resources starting from a specific version (default = `1`). Only available for `watch` mode.\n- `namespaces`: An array of `namespaces` to collect events from. (default = `all`)\n- `group`: API group name. It is an optional config. When given resource object is present in multiple groups,\nuse this config to specify the group to select. By default, it will select the first group.\nFor example, `events` resource is available in both `v1` and `events.k8s.io/v1` APIGroup. In \nthis case, it will select `v1` by default.\n\n\nThe full list of settings exposed for this receiver are documented [here](./config.go)\nwith detailed sample configurations [here](./testdata/config.yaml).\n\nFollow the below sections to setup various Kubernetes resources required for the deployment.\n\n### Configuration\n\nCreate a ConfigMap with the config for `otelcontribcol`. Replace `OTLP_ENDPOINT`\nwith valid value.\n\n```bash\ncat \u003c\u003cEOF | kubectl apply -f -\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: otelcontribcol\n  labels:\n    app: otelcontribcol\ndata:\n  config.yaml: |\n    receivers:\n      k8sobjects:\n        objects:\n          - name: pods\n            mode: pull\n          - name: events\n            mode: watch\n    exporters:\n      otlp:\n        endpoint: \u003cOTLP_ENDPOINT\u003e\n        tls:\n          insecure: true\n\n    service:\n      pipelines:\n        logs:\n          receivers: [k8sobjects]\n          exporters: [otlp]\nEOF\n```\n\n### Service Account\n\nCreate a service account that the collector should use.\n\n```bash\n\u003c\u003cEOF | kubectl apply -f -\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  labels:\n    app: otelcontribcol\n  name: otelcontribcol\nEOF\n```\n\n### RBAC\n\nUse the below commands to create a `ClusterRole` with required permissions and a\n`ClusterRoleBinding` to grant the role to the service account created above.\nFollowing config will work for collecting pods and events only. You need to add\nappropriate rule for collecting other objects.\n\n```bash\n\u003c\u003cEOF | kubectl apply -f -\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: otelcontribcol\n  labels:\n    app: otelcontribcol\nrules:\n- apiGroups:\n  - \"\"\n  resources:\n  - events\n  - pods\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups: \n  - \"events.k8s.io\"\n  resources:\n  - events\n  verbs:\n  - watch\nEOF\n```\n\n```bash\n\u003c\u003cEOF | kubectl apply -f -\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: otelcontribcol\n  labels:\n    app: otelcontribcol\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: otelcontribcol\nsubjects:\n- kind: ServiceAccount\n  name: otelcontribcol\n  namespace: default\nEOF\n```\n\n### Deployment\n\nCreate a [Deployment](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/) to deploy the collector.\nNote: This receiver must be deployed as one replica, otherwise it'll be producing duplicated data.\n\n```bash\n\u003c\u003cEOF | kubectl apply -f -\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: otelcontribcol\n  labels:\n    app: otelcontribcol\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: otelcontribcol\n  template:\n    metadata:\n      labels:\n        app: otelcontribcol\n    spec:\n      serviceAccountName: otelcontribcol\n      containers:\n      - name: otelcontribcol\n        image: otelcontribcol:latest # specify image\n        args: [\"--config\", \"/etc/config/config.yaml\"]\n        volumeMounts:\n        - name: config\n          mountPath: /etc/config\n        imagePullPolicy: IfNotPresent\n      volumes:\n        - name: config\n          configMap:\n            name: otelcontribcol\nEOF\n```\n\n## Troubleshooting\n\nIf receiver returns error similar to below, make sure that resource is added to `ClusterRole`.\n```\n{\"kind\": \"receiver\", \"name\": \"k8sobjects\", \"pipeline\": \"logs\", \"resource\": \"events.k8s.io/v1, Resource=events\", \"error\": \"unknown\"}\n```","properties":{"field_selector":{"title":"field_selector","type":"string"},"group":{"title":"group","type":"string"},"interval":{"title":"interval","type":"string"},"label_selector":{"title":"label_selector","type":"string"},"mode":{"title":"mode","type":"string"},"name":{"title":"name","type":"string"},"namespaces":{"items":{"type":"string"},"title":"namespaces","type":"array"},"resource_version":{"title":"resource_version","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kafkametricsreceiver.Config":{"additionalProperties":false,"description":"Config represents user settings for kafkametrics receiver","markdownDescription":"# Kafka Metrics Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [contrib], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nKafka metrics receiver collects kafka metrics (brokers, topics, partitions, consumer groups) from kafka server,\nconverting into otlp.\n\n## Getting Started\n\nRequired settings (no defaults):\n\n- `protocol_version`: Kafka protocol version\n- `scrapers`: any combination of the following scrapers can be enabled.\n    - `topics`\n    - `consumers`\n    - `brokers`\n    \nMetrics collected by the associated scraper are listed [here](metadata.yaml)\n\nOptional Settings (with defaults):\n\n- `brokers` (default = localhost:9092): the list of brokers to read from.\n- `topic_match` (default = ^[^_].*$): regex pattern of topics to filter on metrics collection. The default filter excludes internal topics (starting with `_`).\n- `group_match` (default = .*): regex pattern of consumer groups to filter on for metrics.\n- `client_id` (default = otel-metrics-receiver): consumer client id\n- `collection_interval` (default = 1m): frequency of metric collection/scraping.\n- `initial_delay` (default = `1s`): defines how long this receiver waits before starting.\n- `auth` (default none)\n    - `plain_text`\n        - `username`: The username to use.\n        - `password`: The password to use\n    - `tls`\n        - `ca_file`: path to the CA cert. For a client this verifies the server certificate. Should only be used\n          if `insecure` is set to true.\n        - `cert_file`: path to the TLS cert to use for TLS required connections. Should only be used if `insecure` is\n          set to true.\n        - `key_file`: path to the TLS key to use for TLS required connections. Should only be used if `insecure` is set\n          to true.\n        - `insecure` (default = false): Disable verifying the server's certificate chain and host\n          name (`InsecureSkipVerify` in the tls config)\n        - `server_name_override`: ServerName indicates the name of the server requested by the client in order to\n          support virtual hosting.\n    - `kerberos`\n        - `service_name`: Kerberos service name\n        - `realm`: Kerberos realm\n        - `use_keytab`:  Use of keytab instead of password, if this is true, keytab file will be used instead of\n          password\n        - `username`: The Kerberos username used for authenticate with KDC\n        - `password`: The Kerberos password used for authenticate with KDC\n        - `config_file`: Path to Kerberos configuration. i.e /etc/krb5.conf\n        - `keytab_file`: Path to keytab file. i.e /etc/security/kafka.keytab\n\n## Examples:\n\n1) Basic configuration with all scrapers:\n\n```yaml\nreceivers:\n  kafkametrics:\n    protocol_version: 2.0.0\n    scrapers:\n      - brokers\n      - topics\n      - consumers\n```\n\n2) Configuration with more optional settings:\n\nFor this example:\n- collection interval is 5 secs.\n\n```yaml\nreceivers:\n  kafkametrics:\n    brokers: 10.10.10.10:9092\n    protocol_version: 2.0.0\n    scrapers:\n      - brokers\n      - topics\n      - consumers\n    auth:\n      tls:\n        ca_file: ca.pem\n        cert_file: cert.pem\n        key_file: key.pem\n    collection_interval: 5s\n```","properties":{"auth":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.kafkaexporter.Authentication","description":"Authentication data","title":"auth"},"brokers":{"description":"The list of kafka brokers (default localhost:9092)","items":{"type":"string"},"title":"brokers","type":"array"},"client_id":{"description":"ClientID is the id associated with the consumer that reads from topics in kafka.","title":"client_id","type":"string"},"collection_interval":{"title":"collection_interval","type":"string"},"group_match":{"description":"GroupMatch consumer groups to collect on","title":"group_match","type":"string"},"initial_delay":{"title":"initial_delay","type":"string"},"metrics":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kafkametricsreceiver.internal.metadata.MetricsConfig","title":"metrics"},"protocol_version":{"description":"ProtocolVersion Kafka protocol version","title":"protocol_version","type":"string"},"scrapers":{"description":"Scrapers defines which metric data points to be captured from kafka","items":{"type":"string"},"title":"scrapers","type":"array"},"topic_match":{"description":"TopicMatch topics to collect metrics on","title":"topic_match","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kafkametricsreceiver.internal.metadata.MetricConfig":{"additionalProperties":false,"description":"MetricConfig provides common config for a particular metric.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kafkametricsreceiver.internal.metadata.MetricsConfig":{"additionalProperties":false,"description":"MetricsConfig provides config for kafkametrics metrics.","properties":{"kafka.brokers":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kafkametricsreceiver.internal.metadata.MetricConfig","title":"kafka.brokers"},"kafka.consumer_group.lag":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kafkametricsreceiver.internal.metadata.MetricConfig","title":"kafka.consumer_group.lag"},"kafka.consumer_group.lag_sum":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kafkametricsreceiver.internal.metadata.MetricConfig","title":"kafka.consumer_group.lag_sum"},"kafka.consumer_group.members":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kafkametricsreceiver.internal.metadata.MetricConfig","title":"kafka.consumer_group.members"},"kafka.consumer_group.offset":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kafkametricsreceiver.internal.metadata.MetricConfig","title":"kafka.consumer_group.offset"},"kafka.consumer_group.offset_sum":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kafkametricsreceiver.internal.metadata.MetricConfig","title":"kafka.consumer_group.offset_sum"},"kafka.partition.current_offset":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kafkametricsreceiver.internal.metadata.MetricConfig","title":"kafka.partition.current_offset"},"kafka.partition.oldest_offset":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kafkametricsreceiver.internal.metadata.MetricConfig","title":"kafka.partition.oldest_offset"},"kafka.partition.replicas":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kafkametricsreceiver.internal.metadata.MetricConfig","title":"kafka.partition.replicas"},"kafka.partition.replicas_in_sync":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kafkametricsreceiver.internal.metadata.MetricConfig","title":"kafka.partition.replicas_in_sync"},"kafka.topic.partitions":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kafkametricsreceiver.internal.metadata.MetricConfig","title":"kafka.topic.partitions"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kafkareceiver.AutoCommit":{"additionalProperties":false,"properties":{"enable":{"description":"Whether or not to auto-commit updated offsets back to the broker.\n(default enabled).","title":"enable","type":"boolean"},"interval":{"description":"How frequently to commit updated offsets. Ineffective unless\nauto-commit is enabled (default 1s)","title":"interval","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kafkareceiver.Config":{"additionalProperties":false,"description":"Config defines configuration for Kafka receiver.","properties":{"auth":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.kafkaexporter.Authentication","title":"auth"},"autocommit":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kafkareceiver.AutoCommit","description":"Controls the auto-commit functionality","title":"autocommit"},"brokers":{"description":"The list of kafka brokers (default localhost:9092)","items":{"type":"string"},"title":"brokers","type":"array"},"client_id":{"description":"The consumer client ID that receiver will use (default \"otel-collector\")","title":"client_id","type":"string"},"encoding":{"description":"Encoding of the messages (default \"otlp_proto\")","title":"encoding","type":"string"},"group_id":{"description":"The consumer group that receiver will be consuming messages from (default \"otel-collector\")","title":"group_id","type":"string"},"initial_offset":{"description":"The initial offset to use if no offset was previously committed.\nMust be `latest` or `earliest` (default \"latest\").","title":"initial_offset","type":"string"},"message_marking":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kafkareceiver.MessageMarking","description":"Controls the way the messages are marked as consumed","title":"message_marking"},"metadata":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.kafkaexporter.Metadata","description":"Metadata is the namespace for metadata management properties used by the\nClient, and shared by the Producer/Consumer.","title":"metadata"},"protocol_version":{"description":"Kafka protocol version","title":"protocol_version","type":"string"},"topic":{"description":"The name of the kafka topic to consume from (default \"otlp_spans\")","title":"topic","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kafkareceiver.MessageMarking":{"additionalProperties":false,"properties":{"after":{"description":"If true, the messages are marked after the pipeline execution","title":"after","type":"boolean"},"on_error":{"description":"If false, only the successfully processed messages are marked, it has no impact if\nAfter is set to false.\nNote: this can block the entire partition in case a message processing returns\na permanent error.","title":"on_error","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.Config":{"additionalProperties":false,"markdownDescription":"# Kubelet Stats Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [contrib], [observiq], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe Kubelet Stats Receiver pulls pod metrics from the API server on a kubelet\nand sends it down the metric pipeline for further processing.\n\n## Configuration\n\nA kubelet runs on a kubernetes node and has an API server to which this\nreceiver connects. To configure this receiver, you have to tell it how\nto connect and authenticate to the API server and how often to collect data\nand send it to the next consumer.\n\nKubelet Stats Receiver supports both secure Kubelet endpoint exposed at port 10250 by default and read-only\nKubelet endpoint exposed at port 10255. If `auth_type` set to `none`, the read-only endpoint will be used. The secure \nendpoint will be used if `auth_type` set to any of the following values:\n\n- `tls` tells the receiver to use TLS for auth and requires that the fields\n`ca_file`, `key_file`, and `cert_file` also be set.\n- `serviceAccount` tells this receiver to use the default service account token\nto authenticate to the kubelet API.\n- `kubeConfig` tells this receiver to use the kubeconfig file (KUBECONFIG env variable or ~/.kube/config)\nto authenticate and use API server proxy to access the kubelet API.\n- `initial_delay` (default = `1s`): defines how long this receiver waits before starting.\n\n### TLS Example\n\n```yaml\nreceivers:\n  kubeletstats:\n    collection_interval: 20s\n    initial_delay: 1s\n    auth_type: \"tls\"\n    ca_file: \"/path/to/ca.crt\"\n    key_file: \"/path/to/apiserver.key\"\n    cert_file: \"/path/to/apiserver.crt\"\n    endpoint: \"https://192.168.64.1:10250\"\n    insecure_skip_verify: true\nexporters:\n  file:\n    path: \"fileexporter.txt\"\nservice:\n  pipelines:\n    metrics:\n      receivers: [kubeletstats]\n      exporters: [file]\n```\n\n### Service Account Authentication Example\n\nAlthough it's possible to use kubernetes' hostNetwork feature to talk to the\nkubelet api from a pod, the preferred approach is to use the downward API.\n\nMake sure the pod spec sets the node name as follows:\n\n```yaml\nenv:\n  - name: K8S_NODE_NAME\n    valueFrom:\n      fieldRef:\n        fieldPath: spec.nodeName\n```\n\nThen the otel config can reference the `K8S_NODE_NAME` environment variable:\n\n```yaml\nreceivers:\n  kubeletstats:\n    collection_interval: 20s\n    auth_type: \"serviceAccount\"\n    endpoint: \"https://${env:K8S_NODE_NAME}:10250\"\n    insecure_skip_verify: true\nexporters:\n  file:\n    path: \"fileexporter.txt\"\nservice:\n  pipelines:\n    metrics:\n      receivers: [kubeletstats]\n      exporters: [file]\n```\n\nNote: a missing or empty `endpoint` will cause the hostname on which the\ncollector is running to be used as the endpoint. If the hostNetwork flag is\nset, and the collector is running in a pod, this hostname will resolve to the\nnode's network namespace.\n\n### Read Only Endpoint Example\n\nThe following config can be used to collect Kubelet metrics from read-only endpoint:\n\n```yaml\nreceivers:\n  kubeletstats:\n    collection_interval: 20s\n    auth_type: \"none\"\n    endpoint: \"http://${env:K8S_NODE_NAME}:10255\"\nexporters:\n  file:\n    path: \"fileexporter.txt\"\nservice:\n  pipelines:\n    metrics:\n      receivers: [kubeletstats]\n      exporters: [file]\n```\n\n### Kubeconfig example\n\nThe following config can be used to collect Kubelet metrics from read-only endpoint, proxied by the API server:\n\n```yaml\nreceivers:\n  kubeletstats:\n    collection_interval: 20s\n    auth_type: \"kubeConfig\"\n    insecure_skip_verify: true\n    endpoint: \"${env:K8S_NODE_NAME}\"\nexporters:\n  file:\n    path: \"fileexporter.txt\"\nservice:\n  pipelines:\n    metrics:\n      receivers: [kubeletstats]\n      exporters: [file]\n```\nNote that using `auth_type` `kubeConfig`, the endpoint should only be the node name as the communication to the kubelet is proxied by the API server configured in the `kubeConfig`.\n`insecure_skip_verify` still applies by overriding the `kubeConfig` settings.\n\n### Extra metadata labels\n\nBy default, all produced metrics get resource labels based on what kubelet /stats/summary endpoint provides.\nFor some use cases it might be not enough. So it's possible to leverage other endpoints to fetch\nadditional metadata entities and set them as extra labels on metric resource. Currently supported metadata\ninclude the following:\n\n- `container.id` - to augment metrics with Container ID label obtained from container statuses exposed via `/pods`.\n- `k8s.volume.type` - to collect volume type from the Pod spec exposed via `/pods` and have it as a label on volume metrics.\nIf there's more information available from the endpoint than just volume type, those are sycned as well depending on\nthe available fields and the type of volume. For example, `aws.volume.id` would be synced from `awsElasticBlockStore`\nand `gcp.pd.name` is synced for `gcePersistentDisk`.\n\nIf you want to have `container.id` label added to your metrics, use `extra_metadata_labels` field to enable\nit, for example:\n\n```yaml\nreceivers:\n  kubeletstats:\n    collection_interval: 10s\n    auth_type: \"serviceAccount\"\n    endpoint: \"${env:K8S_NODE_NAME}:10250\"\n    insecure_skip_verify: true\n    extra_metadata_labels:\n      - container.id\n```\n\nIf `extra_metadata_labels` is not set, no additional API calls is done to fetch extra metadata.\n\n#### Collecting Additional Volume Metadata\n\nWhen dealing with Persistent Volume Claims, it is possible to optionally sync metdadata from the underlying\nstorage resource rather than just the volume claim. This is achieved by talking to the Kubernetes API. Below\nis an example, configuration to achieve this.\n\n```yaml\nreceivers:\n  kubeletstats:\n    collection_interval: 10s\n    auth_type: \"serviceAccount\"\n    endpoint: \"${env:K8S_NODE_NAME}:10250\"\n    insecure_skip_verify: true\n    extra_metadata_labels:\n      - k8s.volume.type\n    k8s_api_config:\n      auth_type: serviceAccount\n```\n\nIf `k8s_api_config` set, the receiver will attempt to collect metadata from underlying storage resources for\nPersistent Volume Claims. For example, if a Pod is using a PVC backed by an EBS instance on AWS, the receiver\nwould set the `k8s.volume.type` label to be `awsElasticBlockStore` rather than `persistentVolumeClaim`.\n\n### Metric Groups\n\nA list of metric groups from which metrics should be collected. By default, metrics from containers,\npods and nodes will be collected. If `metric_groups` is set, only metrics from the listed groups\nwill be collected. Valid groups are `container`, `pod`, `node` and `volume`. For example, if you're\nlooking to collect only `node` and `pod` metrics from the receiver use the following configuration.\n\n```yaml\nreceivers:\n  kubeletstats:\n    collection_interval: 10s\n    auth_type: \"serviceAccount\"\n    endpoint: \"${env:K8S_NODE_NAME}:10250\"\n    insecure_skip_verify: true\n    metric_groups:\n      - node\n      - pod\n```\n\n### Optional parameters\n\nThe following parameters can also be specified:\n\n- `collection_interval` (default = `10s`): The interval at which to collect data.\n- `insecure_skip_verify` (default = `false`): Whether or not to skip certificate verification.\n\nThe full list of settings exposed for this receiver are documented [here](./config.go)\nwith detailed sample configurations [here](./testdata/config.yaml).\n\n## Metrics\n\nDetails about the metrics produced by this receiver can be found in [metadata.yaml](./metadata.yaml) with further documentation in [documentation.md](./documentation.md)","properties":{"auth_type":{"description":"How to authenticate to the K8s API server.  This can be one of `none`\n(for no auth), `serviceAccount` (to use the standard service account\ntoken provided to the agent pod), or `kubeConfig` to use credentials\nfrom `~/.kube/config`.","title":"auth_type","type":"string"},"ca_file":{"description":"Path to the CA cert. For a client this verifies the server certificate.\nFor a server this verifies client certificates. If empty uses system root CA.\n(optional)","title":"ca_file","type":"string"},"ca_pem":{"description":"In memory PEM encoded cert. (optional)","title":"ca_pem","type":"string"},"cert_file":{"description":"Path to the TLS cert to use for TLS required connections. (optional)","title":"cert_file","type":"string"},"cert_pem":{"description":"In memory PEM encoded TLS cert to use for TLS required connections. (optional)","title":"cert_pem","type":"string"},"collection_interval":{"title":"collection_interval","type":"string"},"endpoint":{"description":"Endpoint configures the address for this network connection.\nThe address has the form \"host:port\". The host must be a literal IP address, or a host name that can be\nresolved to IP addresses. The port must be a literal port number or a service name.\nIf the host is a literal IPv6 address it must be enclosed in square brackets, as in \"[2001:db8::1]:80\" or\n\"[fe80::1%zone]:80\". The zone specifies the scope of the literal IPv6 address as defined in RFC 4007.","title":"endpoint","type":"string"},"extra_metadata_labels":{"description":"ExtraMetadataLabels contains list of extra metadata that should be taken from /pods endpoint\nand put as extra labels on metrics resource.\nNo additional metadata is fetched by default, so there are no extra calls to /pods endpoint.\nSupported values include container.id and k8s.volume.type.","items":{"type":"string"},"title":"extra_metadata_labels","type":"array"},"initial_delay":{"title":"initial_delay","type":"string"},"insecure_skip_verify":{"description":"InsecureSkipVerify controls whether the client verifies the server's\ncertificate chain and host name.","title":"insecure_skip_verify","type":"boolean"},"k8s_api_config":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.internal.k8sconfig.APIConfig","description":"Configuration of the Kubernetes API client.","title":"k8s_api_config"},"key_file":{"description":"Path to the TLS key to use for TLS required connections. (optional)","title":"key_file","type":"string"},"key_pem":{"description":"In memory PEM encoded TLS key to use for TLS required connections. (optional)","title":"key_pem","type":"string"},"max_version":{"description":"MaxVersion sets the maximum TLS version that is acceptable.\nIf not set, refer to crypto/tls for defaults. (optional)","title":"max_version","type":"string"},"metric_groups":{"description":"MetricGroupsToCollect provides a list of metrics groups to collect metrics from.\n\"container\", \"pod\", \"node\" and \"volume\" are the only valid groups.","items":{"type":"string"},"title":"metric_groups","type":"array"},"metrics":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricsConfig","title":"metrics"},"min_version":{"description":"MinVersion sets the minimum TLS version that is acceptable.\nIf not set, TLS 1.2 will be used. (optional)","title":"min_version","type":"string"},"reload_interval":{"description":"ReloadInterval specifies the duration after which the certificate will be reloaded\nIf not set, it will never be reloaded (optional)","title":"reload_interval","type":"string"},"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig":{"additionalProperties":false,"description":"MetricConfig provides common config for a particular metric.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricsConfig":{"additionalProperties":false,"description":"MetricsConfig provides config for kubeletstats metrics.","properties":{"container.cpu.time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"container.cpu.time"},"container.cpu.utilization":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"container.cpu.utilization"},"container.filesystem.available":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"container.filesystem.available"},"container.filesystem.capacity":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"container.filesystem.capacity"},"container.filesystem.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"container.filesystem.usage"},"container.memory.available":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.available"},"container.memory.major_page_faults":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.major_page_faults"},"container.memory.page_faults":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.page_faults"},"container.memory.rss":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.rss"},"container.memory.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.usage"},"container.memory.working_set":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"container.memory.working_set"},"k8s.node.cpu.time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.node.cpu.time"},"k8s.node.cpu.utilization":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.node.cpu.utilization"},"k8s.node.filesystem.available":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.node.filesystem.available"},"k8s.node.filesystem.capacity":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.node.filesystem.capacity"},"k8s.node.filesystem.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.node.filesystem.usage"},"k8s.node.memory.available":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.node.memory.available"},"k8s.node.memory.major_page_faults":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.node.memory.major_page_faults"},"k8s.node.memory.page_faults":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.node.memory.page_faults"},"k8s.node.memory.rss":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.node.memory.rss"},"k8s.node.memory.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.node.memory.usage"},"k8s.node.memory.working_set":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.node.memory.working_set"},"k8s.node.network.errors":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.node.network.errors"},"k8s.node.network.io":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.node.network.io"},"k8s.pod.cpu.time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.pod.cpu.time"},"k8s.pod.cpu.utilization":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.pod.cpu.utilization"},"k8s.pod.filesystem.available":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.pod.filesystem.available"},"k8s.pod.filesystem.capacity":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.pod.filesystem.capacity"},"k8s.pod.filesystem.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.pod.filesystem.usage"},"k8s.pod.memory.available":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.pod.memory.available"},"k8s.pod.memory.major_page_faults":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.pod.memory.major_page_faults"},"k8s.pod.memory.page_faults":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.pod.memory.page_faults"},"k8s.pod.memory.rss":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.pod.memory.rss"},"k8s.pod.memory.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.pod.memory.usage"},"k8s.pod.memory.working_set":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.pod.memory.working_set"},"k8s.pod.network.errors":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.pod.network.errors"},"k8s.pod.network.io":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.pod.network.io"},"k8s.volume.available":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.volume.available"},"k8s.volume.capacity":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.volume.capacity"},"k8s.volume.inodes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.volume.inodes"},"k8s.volume.inodes.free":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.volume.inodes.free"},"k8s.volume.inodes.used":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.MetricConfig","title":"k8s.volume.inodes.used"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for kubeletstats resource attributes.","properties":{"aws.volume.id":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.ResourceAttributeConfig","title":"aws.volume.id"},"container.id":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.ResourceAttributeConfig","title":"container.id"},"fs.type":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.ResourceAttributeConfig","title":"fs.type"},"gce.pd.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.ResourceAttributeConfig","title":"gce.pd.name"},"glusterfs.endpoints.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.ResourceAttributeConfig","title":"glusterfs.endpoints.name"},"glusterfs.path":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.ResourceAttributeConfig","title":"glusterfs.path"},"k8s.container.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.ResourceAttributeConfig","title":"k8s.container.name"},"k8s.namespace.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.ResourceAttributeConfig","title":"k8s.namespace.name"},"k8s.node.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.ResourceAttributeConfig","title":"k8s.node.name"},"k8s.persistentvolumeclaim.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.ResourceAttributeConfig","title":"k8s.persistentvolumeclaim.name"},"k8s.pod.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.ResourceAttributeConfig","title":"k8s.pod.name"},"k8s.pod.uid":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.ResourceAttributeConfig","title":"k8s.pod.uid"},"k8s.volume.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.ResourceAttributeConfig","title":"k8s.volume.name"},"k8s.volume.type":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.ResourceAttributeConfig","title":"k8s.volume.type"},"partition":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.internal.metadata.ResourceAttributeConfig","title":"partition"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.memcachedreceiver.Config":{"additionalProperties":false,"markdownDescription":"# Memcached Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [contrib], [observiq], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThis receiver can fetch stats from a Memcached instance using the [stats\ncommand](https://github.com/memcached/memcached/wiki/Commands#statistics). A\ndetailed description of all the stats available is at\nhttps://github.com/memcached/memcached/blob/master/doc/protocol.txt#L1159.\n\n## Details\n\n## Configuration\n\n\u003e :information_source: This receiver is in beta and configuration fields are subject to change.\n\nThe following settings are required:\n\n- `endpoint` (default: `localhost:11211`): The hostname/IP address and port or, unix socket file path of the memcached instance\n\nThe following settings are optional:\n\n- `collection_interval` (default = `10s`): This receiver runs on an interval.\nEach time it runs, it queries memcached, creates metrics, and sends them to the\nnext consumer. The `collection_interval` configuration option tells this\nreceiver the duration between runs. This value must be a string readable by\nGolang's `ParseDuration` function (example: `1h30m`). Valid time units are\n`ns`, `us` (or `Âµs`), `ms`, `s`, `m`, `h`.\n- `initial_delay` (default = `1s`): defines how long this receiver waits before starting.\n\nExample:\n\n```yaml\nreceivers:\n  memcached:\n    endpoint: \"localhost:11211\"\n    collection_interval: 10s\n```\n\nThe full list of settings exposed for this receiver are documented [here](./config.go)\nwith detailed sample configurations [here](./testdata/config.yaml).\n\n## Metrics\n\nDetails about the metrics produced by this receiver can be found in [metadata.yaml](./metadata.yaml) with further documentation in [documentation.md](./documentation.md)","properties":{"collection_interval":{"title":"collection_interval","type":"string"},"endpoint":{"description":"Endpoint configures the address for this network connection.\nFor TCP and UDP networks, the address has the form \"host:port\". The host must be a literal IP address,\nor a host name that can be resolved to IP addresses. The port must be a literal port number or a service name.\nIf the host is a literal IPv6 address it must be enclosed in square brackets, as in \"[2001:db8::1]:80\" or\n\"[fe80::1%zone]:80\". The zone specifies the scope of the literal IPv6 address as defined in RFC 4007.","title":"endpoint","type":"string"},"initial_delay":{"title":"initial_delay","type":"string"},"metrics":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.memcachedreceiver.internal.metadata.MetricsConfig","title":"metrics"},"timeout":{"description":"Timeout for the memcache stats request","title":"timeout","type":"string"},"transport":{"description":"Transport to use. Known protocols are \"tcp\", \"tcp4\" (IPv4-only), \"tcp6\" (IPv6-only), \"udp\", \"udp4\" (IPv4-only),\n\"udp6\" (IPv6-only), \"ip\", \"ip4\" (IPv4-only), \"ip6\" (IPv6-only), \"unix\", \"unixgram\" and \"unixpacket\".","title":"transport","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.memcachedreceiver.internal.metadata.MetricConfig":{"additionalProperties":false,"description":"MetricConfig provides common config for a particular metric.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.memcachedreceiver.internal.metadata.MetricsConfig":{"additionalProperties":false,"description":"MetricsConfig provides config for memcached metrics.","properties":{"memcached.bytes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.memcachedreceiver.internal.metadata.MetricConfig","title":"memcached.bytes"},"memcached.commands":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.memcachedreceiver.internal.metadata.MetricConfig","title":"memcached.commands"},"memcached.connections.current":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.memcachedreceiver.internal.metadata.MetricConfig","title":"memcached.connections.current"},"memcached.connections.total":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.memcachedreceiver.internal.metadata.MetricConfig","title":"memcached.connections.total"},"memcached.cpu.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.memcachedreceiver.internal.metadata.MetricConfig","title":"memcached.cpu.usage"},"memcached.current_items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.memcachedreceiver.internal.metadata.MetricConfig","title":"memcached.current_items"},"memcached.evictions":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.memcachedreceiver.internal.metadata.MetricConfig","title":"memcached.evictions"},"memcached.network":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.memcachedreceiver.internal.metadata.MetricConfig","title":"memcached.network"},"memcached.operation_hit_ratio":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.memcachedreceiver.internal.metadata.MetricConfig","title":"memcached.operation_hit_ratio"},"memcached.operations":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.memcachedreceiver.internal.metadata.MetricConfig","title":"memcached.operations"},"memcached.threads":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.memcachedreceiver.internal.metadata.MetricConfig","title":"memcached.threads"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.AccessLogsConfig":{"additionalProperties":false,"properties":{"auth_result":{"title":"auth_result","type":"boolean"},"enabled":{"title":"enabled","type":"boolean"},"max_pages":{"title":"max_pages","type":"integer"},"page_size":{"title":"page_size","type":"integer"},"poll_interval":{"title":"poll_interval","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.AlertConfig":{"additionalProperties":false,"properties":{"enabled":{"title":"enabled","type":"boolean"},"endpoint":{"title":"endpoint","type":"string"},"max_pages":{"title":"max_pages","type":"integer"},"mode":{"title":"mode","type":"string"},"page_size":{"title":"page_size","type":"integer"},"poll_interval":{"title":"poll_interval","type":"string"},"projects":{"description":"these parameters are only relevant in retrieval mode","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.ProjectConfig"},"title":"projects","type":"array"},"secret":{"title":"secret","type":"string"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSServerSetting","title":"tls"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.Config":{"additionalProperties":false,"markdownDescription":"# MongoDB Atlas Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics, logs   |\n| Distributions | [contrib], [observiq], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nReceives metrics from [MongoDB Atlas](https://www.mongodb.com/cloud/atlas) \nvia their [monitoring APIs](https://docs.atlas.mongodb.com/reference/api/monitoring-and-logs/),\nas well as alerts via a configured [webhook](https://www.mongodb.com/docs/atlas/tutorial/third-party-service-integrations/)\nand events from [events APIs](https://www.mongodb.com/docs/atlas/reference/api/events/).\n\n## Getting Started\n\nThe MongoDB Atlas receiver takes the following parameters. `public_key` and \n`private_key` are the only two required values to receive metrics and logs and are obtained via the\n\"API Keys\" tab of the MongoDB Atlas Project Access Manager. In the example\nbelow both values are being pulled from the environment.\n\nIn order to collect logs, at least one project must be specified. By default, logs for all clusters within a project will be collected. Clusters can be limited using either the `include_clusters` or `exclude_clusters` setting.\n\nIn order to collect project events, the requesting API key needs the appropriate permission which at minimum is the `Project Read Only` role. Project events are specific to a single project.\n\nIn order to collect organization events, the requesting API key needs the appropriate permission which at minimum is the `Organization Member` role. Organization events are collected across all the projects hosted on Atlas within the organization. These events are not associated with a project.\n\nMongoDB Atlas [Documentation](https://www.mongodb.com/docs/atlas/reference/api/logs/#logs) recommends a polling interval of 5 minutes.\n\n- `public_key` (required for metrics, logs, or alerts in `poll` mode)\n- `private_key` (required for metrics, logs, or alerts in `poll` mode)\n- `granularity` (default `PT1M` - See [MongoDB Atlas Documentation](https://docs.atlas.mongodb.com/reference/api/process-measurements/))\n- `collection_interval` (default `3m`) This receiver collects metrics on an interval. Valid time units are `ns`, `us` (or `Âµs`), `ms`, `s`, `m`, `h`.\n- `storage` (optional) The component ID of a storage extension which can be used when polling for `alerts` or `events` . The storage extension prevents duplication of data after a collector restart by remembering which data were previously collected.\n- `retry_on_failure`\n  - `enabled` (default true)\n  - `initial_interval` (default 5s)\n  - `max_interval` (default 30s)\n  - `max_elapsed_time` (default 5m)\n- `alerts`\n  - `enabled` (default false)\n  - `mode` (default `listen`. Options are `poll` or `listen`)\n  - `secret` (required if using `listen` mode)\n  - `endpoint` (required if using `listen` mode)\n  - `poll_interval` (default `5m`, only relevant using `poll` mode)\n  - `page_size` (default `100`)\n    - When in `poll` mode, this is the number of alerts that will be processed per request to the MongoDB Atlas API.\n  - `max_pages` (default `10`)\n    - When in `poll` mode, this will limit how many pages of alerts the receiver will request for each project.\n  - `projects` (required if using `poll` mode)\n    - `name` (required if using `poll mode`)\n    - `include_clusters` (default empty, exclusive with `exclude_clusters`)\n    - `exclude_clusters` (default empty, exclusive with `include_clusters`)\n      - If both `include_clusters` and `exclude_clusters` are empty, then all clusters in the project will be included\n  - `tls` (relevant only for `listen` mode)\n    - `key_file`\n    - `cert_file`\n- `logs`\n  - `enabled` (default false)\n  - `projects` (required if enabled)\n    - `name` (required if enabled)\n    - `collect_host_logs` (default true)\n    - `collect_audit_logs` (default false)\n      - Audit logging must be [enabled for your MongoDB Atlas project](https://www.mongodb.com/docs/atlas/database-auditing/) in order to scrape audit logs.\n    - `access_logs`\n      - `enabled` (default true, if the `access_logs` parameter is defined)\n      - `auth_result`\n        - If specified, will limit the access logs queried to successful accesses (true) or failed accesses (false). If not specified, all will be collected\n      - `page_size` (default `20000`)\n        - This is the number of access logs that will be processed per request to the MongoDB Atlas API. The maximum value is 20000.\n      - `max_pages` (default `10`)\n        - This will limit how many pages of access logs the receiver will request from the MongoDB Atlas API for a project.\n      - `poll_interval` (default `5m`)\n        - This will define how frequently the MongoDB Atlas API is queried for Access Logs for the given project.\n    - `include_clusters` (default empty)\n    - `exclude_clusters` (default empty)\n- `events`\n  - `projects`\n    - `name` Name of the Project to discover events from.\n  - `organizations`\n    - `id` ID of the Organization to discover events from.\n  - `poll_interval` (default `1m`)\n    - How often the receiver will poll the Events API for new events.\n  - `page_size` (default `100`)\n    - This is the number of events that will be processed per request to the MongoDB Atlas API.\n  - `max_pages` (default `25`)\n    - This will limit how many pages of events the receiver will request from the MongoDB Atlas API for each project.\n  - `types` (defaults to all types of events)\n    - This is a list of [event types](https://www.mongodb.com/docs/atlas/reference/api/events-orgs-get-all/#event-type-values) that the receiver will request from the API. If specified, the receiver will collect only the indicated types of events.\n\nExamples:\n\nReceive metrics:\n\n```yaml\nreceivers:\n  mongodbatlas:\n    public_key: ${env:MONGODB_ATLAS_PUBLIC_KEY}\n    private_key: ${env:MONGODB_ATLAS_PRIVATE_KEY}\n```\n\nListen for alerts (default mode):\n\n```yaml\nreceivers:\n  mongodbatlas:\n    alerts:\n      enabled: true\n      secret: \"some_secret\"\n      endpoint: \"0.0.0.0:7706\"\n```\n\nPoll alerts from API:\n\n```yaml\nreceivers:\n  mongodbatlas:\n    public_key: \u003credacted\u003e\n    private_key: \u003credacted\u003e\n    alerts:\n      enabled: true\n      mode: poll\n      projects:\n      - name: Project 0\n        include_clusters: [Cluster0]\n      poll_interval: 1m\n    # use of a storage extension is recommended to reduce chance of duplicated alerts\n    storage: file_storage\n```\n\nReceive logs:\n\n```yaml\nreceivers:\n  mongodbatlas:\n    logs:\n      enabled: true\n      projects: \n        - name: \"project 1\"\n          collect_audit_logs: true\n          collect_host_logs: true\n```\n\nReceive events:\n\n```yaml\nreceivers:\n  mongodbatlas:\n    events:\n      projects:\n        - name: \"project 1\"\n      organizations:\n        - id: \"5b478b3afc4625789ce616a3\"\n      poll_interval: 1m\n      page_size: 100\n      max_pages: 25\n    # use of a storage extension is recommended to reduce chance of duplicated events\n    storage: file_storage\n```\n\nPoll Access Logs from API:\n\n```yaml\nreceivers:\n  mongodbatlas:\n    public_key: \u003credacted\u003e\n    private_key: \u003credacted\u003e\n    logs:\n      enabled: true\n      projects:\n      - name: Project 0\n        include_clusters: [Cluster0]\n        access_logs:\n          page_size: 20000\n          max_pages: 10\n          poll_interval: 5m\n    # use of a storage extension is recommended to reduce chance of duplicated access logs\n    storage: file_storage\n```","properties":{"alerts":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.AlertConfig","title":"alerts"},"collection_interval":{"title":"collection_interval","type":"string"},"events":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.EventsConfig","title":"events"},"granularity":{"title":"granularity","type":"string"},"initial_delay":{"title":"initial_delay","type":"string"},"logs":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.LogConfig","title":"logs"},"metrics":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricsConfig","title":"metrics"},"private_key":{"title":"private_key","type":"string"},"public_key":{"title":"public_key","type":"string"},"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"},"retry_on_failure":{"$ref":"#/$defs/go.opentelemetry.io.collector.exporter.exporterhelper.RetrySettings","title":"retry_on_failure"},"storage":{"title":"storage","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.EventsConfig":{"additionalProperties":false,"description":"EventsConfig is the configuration options for events collection","properties":{"max_pages":{"title":"max_pages","type":"integer"},"organizations":{"items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.OrgConfig"},"title":"organizations","type":"array"},"page_size":{"title":"page_size","type":"integer"},"poll_interval":{"title":"poll_interval","type":"string"},"projects":{"items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.ProjectConfig"},"title":"projects","type":"array"},"types":{"items":{"type":"string"},"title":"types","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.LogConfig":{"additionalProperties":false,"properties":{"enabled":{"title":"enabled","type":"boolean"},"projects":{"items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.LogsProjectConfig"},"title":"projects","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.LogsProjectConfig":{"additionalProperties":false,"properties":{"access_logs":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.AccessLogsConfig","title":"access_logs"},"collect_audit_logs":{"title":"collect_audit_logs","type":"boolean"},"collect_host_logs":{"title":"collect_host_logs","type":"boolean"},"exclude_clusters":{"items":{"type":"string"},"title":"exclude_clusters","type":"array"},"include_clusters":{"items":{"type":"string"},"title":"include_clusters","type":"array"},"name":{"title":"name","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.OrgConfig":{"additionalProperties":false,"properties":{"id":{"title":"id","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.ProjectConfig":{"additionalProperties":false,"properties":{"exclude_clusters":{"items":{"type":"string"},"title":"exclude_clusters","type":"array"},"include_clusters":{"items":{"type":"string"},"title":"include_clusters","type":"array"},"name":{"title":"name","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig":{"additionalProperties":false,"description":"MetricConfig provides common config for a particular metric.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricsConfig":{"additionalProperties":false,"description":"MetricsConfig provides config for mongodbatlas metrics.","properties":{"mongodbatlas.db.counts":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.db.counts"},"mongodbatlas.db.size":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.db.size"},"mongodbatlas.disk.partition.iops.average":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.disk.partition.iops.average"},"mongodbatlas.disk.partition.iops.max":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.disk.partition.iops.max"},"mongodbatlas.disk.partition.latency.average":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.disk.partition.latency.average"},"mongodbatlas.disk.partition.latency.max":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.disk.partition.latency.max"},"mongodbatlas.disk.partition.space.average":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.disk.partition.space.average"},"mongodbatlas.disk.partition.space.max":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.disk.partition.space.max"},"mongodbatlas.disk.partition.usage.average":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.disk.partition.usage.average"},"mongodbatlas.disk.partition.usage.max":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.disk.partition.usage.max"},"mongodbatlas.disk.partition.utilization.average":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.disk.partition.utilization.average"},"mongodbatlas.disk.partition.utilization.max":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.disk.partition.utilization.max"},"mongodbatlas.process.asserts":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.asserts"},"mongodbatlas.process.background_flush":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.background_flush"},"mongodbatlas.process.cache.io":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.cache.io"},"mongodbatlas.process.cache.size":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.cache.size"},"mongodbatlas.process.connections":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.connections"},"mongodbatlas.process.cpu.children.normalized.usage.average":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.cpu.children.normalized.usage.average"},"mongodbatlas.process.cpu.children.normalized.usage.max":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.cpu.children.normalized.usage.max"},"mongodbatlas.process.cpu.children.usage.average":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.cpu.children.usage.average"},"mongodbatlas.process.cpu.children.usage.max":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.cpu.children.usage.max"},"mongodbatlas.process.cpu.normalized.usage.average":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.cpu.normalized.usage.average"},"mongodbatlas.process.cpu.normalized.usage.max":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.cpu.normalized.usage.max"},"mongodbatlas.process.cpu.usage.average":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.cpu.usage.average"},"mongodbatlas.process.cpu.usage.max":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.cpu.usage.max"},"mongodbatlas.process.cursors":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.cursors"},"mongodbatlas.process.db.document.rate":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.db.document.rate"},"mongodbatlas.process.db.operations.rate":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.db.operations.rate"},"mongodbatlas.process.db.operations.time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.db.operations.time"},"mongodbatlas.process.db.query_executor.scanned":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.db.query_executor.scanned"},"mongodbatlas.process.db.query_targeting.scanned_per_returned":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.db.query_targeting.scanned_per_returned"},"mongodbatlas.process.db.storage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.db.storage"},"mongodbatlas.process.global_lock":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.global_lock"},"mongodbatlas.process.index.btree_miss_ratio":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.index.btree_miss_ratio"},"mongodbatlas.process.index.counters":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.index.counters"},"mongodbatlas.process.journaling.commits":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.journaling.commits"},"mongodbatlas.process.journaling.data_files":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.journaling.data_files"},"mongodbatlas.process.journaling.written":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.journaling.written"},"mongodbatlas.process.memory.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.memory.usage"},"mongodbatlas.process.network.io":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.network.io"},"mongodbatlas.process.network.requests":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.network.requests"},"mongodbatlas.process.oplog.rate":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.oplog.rate"},"mongodbatlas.process.oplog.time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.oplog.time"},"mongodbatlas.process.page_faults":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.page_faults"},"mongodbatlas.process.restarts":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.restarts"},"mongodbatlas.process.tickets":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.process.tickets"},"mongodbatlas.system.cpu.normalized.usage.average":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.system.cpu.normalized.usage.average"},"mongodbatlas.system.cpu.normalized.usage.max":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.system.cpu.normalized.usage.max"},"mongodbatlas.system.cpu.usage.average":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.system.cpu.usage.average"},"mongodbatlas.system.cpu.usage.max":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.system.cpu.usage.max"},"mongodbatlas.system.fts.cpu.normalized.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.system.fts.cpu.normalized.usage"},"mongodbatlas.system.fts.cpu.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.system.fts.cpu.usage"},"mongodbatlas.system.fts.disk.used":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.system.fts.disk.used"},"mongodbatlas.system.fts.memory.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.system.fts.memory.usage"},"mongodbatlas.system.memory.usage.average":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.system.memory.usage.average"},"mongodbatlas.system.memory.usage.max":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.system.memory.usage.max"},"mongodbatlas.system.network.io.average":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.system.network.io.average"},"mongodbatlas.system.network.io.max":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.system.network.io.max"},"mongodbatlas.system.paging.io.average":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.system.paging.io.average"},"mongodbatlas.system.paging.io.max":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.system.paging.io.max"},"mongodbatlas.system.paging.usage.average":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.system.paging.usage.average"},"mongodbatlas.system.paging.usage.max":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.MetricConfig","title":"mongodbatlas.system.paging.usage.max"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for mongodbatlas resource attributes.","properties":{"mongodb_atlas.cluster.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.ResourceAttributeConfig","title":"mongodb_atlas.cluster.name"},"mongodb_atlas.db.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.ResourceAttributeConfig","title":"mongodb_atlas.db.name"},"mongodb_atlas.disk.partition":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.ResourceAttributeConfig","title":"mongodb_atlas.disk.partition"},"mongodb_atlas.host.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.ResourceAttributeConfig","title":"mongodb_atlas.host.name"},"mongodb_atlas.org_name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.ResourceAttributeConfig","title":"mongodb_atlas.org_name"},"mongodb_atlas.process.id":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.ResourceAttributeConfig","title":"mongodb_atlas.process.id"},"mongodb_atlas.process.port":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.ResourceAttributeConfig","title":"mongodb_atlas.process.port"},"mongodb_atlas.process.type_name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.ResourceAttributeConfig","title":"mongodb_atlas.process.type_name"},"mongodb_atlas.project.id":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.ResourceAttributeConfig","title":"mongodb_atlas.project.id"},"mongodb_atlas.project.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.ResourceAttributeConfig","title":"mongodb_atlas.project.name"},"mongodb_atlas.user.alias":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.internal.metadata.ResourceAttributeConfig","title":"mongodb_atlas.user.alias"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.Config":{"additionalProperties":false,"markdownDescription":"# MongoDB Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [contrib], [observiq], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThis receiver fetches stats from a MongoDB instance using the [golang\nmongo driver](https://github.com/mongodb/mongo-go-driver). Stats are collected\nvia MongoDB's `dbStats` and `serverStatus` commands.\n\n## Purpose\n\nThe purpose of this receiver is to allow users to monitor metrics from standalone MongoDB clusters. This includes non-Atlas managed MongoDB Servers.\n\n## Prerequisites\n\nThis receiver supports MongoDB versions:\n\n- 4.0+\n- 5.0\n\nMongodb recommends to set up a least privilege user (LPU) with a [`clusterMonitor` role](https://www.mongodb.com/docs/v5.0/reference/built-in-roles/#mongodb-authrole-clusterMonitor) in order to collect metrics. Please refer to [lpu.sh](./testdata/integration/scripts/lpu.sh) for an example of how to configure these permissions.\n\n## Configuration\n\nThe following settings are optional:\n\n- `hosts` (default: [`localhost:27017`]): list of `host:port` or unix domain socket endpoints.\n  - For standalone MongoDB deployments this is the hostname and port of the mongod instance\n  - For replica sets specify the hostnames and ports of the mongod instances that are in the replica set configuration. If the `replica_set` field is specified, nodes will be autodiscovered.\n  - For a sharded MongoDB deployment, please specify a list of the `mongos` hosts.\n- `username`: If authentication is required, the user can with `clusterMonitor` permissions can be provided here.\n- `password`: If authentication is required, the password can be provided here.\n- `collection_interval`: (default = `1m`): This receiver collects metrics on an interval. This value must be a string readable by Golang's [time.ParseDuration](https://pkg.go.dev/time#ParseDuration). Valid time units are `ns`, `us` (or `Âµs`), `ms`, `s`, `m`, `h`.\n- `initial_delay` (default = `1s`): defines how long this receiver waits before starting.\n- `replica_set`: If the deployment of MongoDB is a replica set then this allows users to specify the replica set name which allows for autodiscovery of other nodes in the replica set.\n- `timeout`: (default = `1m`) The timeout of running commands against mongo.\n- `tls`: (defaults defined [here](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/configtls/README.md)): TLS control. By default insecure settings are rejected and certificate verification is on.\n\n### Example Configuration\n\n```yaml\nreceivers:\n  mongodb:\n    hosts:\n      - endpoint: localhost:27017\n    username: otel\n    password: ${env:MONGODB_PASSWORD}\n    collection_interval: 60s\n    initial_delay: 1s\n    tls:\n      insecure: true\n      insecure_skip_verify: true\n```\n\nThe full list of settings exposed for this receiver are documented [here](./config.go) with detailed sample configurations [here](./testdata/config.yaml).\n\n## Metrics\n\nThe following metric are available with versions:\n\n- `mongodb.extent.count` \u003c 4.4 with mmapv1 storage engine\n- `mongodb.session.count` \u003e= 3.0 with wiredTiger storage engine\n- `mongodb.cache.operations` \u003e= 3.0 with wiredTiger storage engine\n- `mongodb.connection.count` with attribute `active` is available \u003e= 4.0\n- `mongodb.index.access.count` \u003e= 4.0\n\nDetails about the metrics produced by this receiver can be found in [metadata.yaml](./metadata.yaml)","properties":{"collection_interval":{"title":"collection_interval","type":"string"},"hosts":{"items":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.confignet.NetAddr"},"title":"hosts","type":"array"},"initial_delay":{"title":"initial_delay","type":"string"},"metrics":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricsConfig","title":"metrics"},"password":{"title":"password","type":"string"},"replica_set":{"title":"replica_set","type":"string"},"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"},"timeout":{"title":"timeout","type":"string"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","title":"tls"},"username":{"title":"username","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig":{"additionalProperties":false,"description":"MetricConfig provides common config for a particular metric.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricsConfig":{"additionalProperties":false,"description":"MetricsConfig provides config for mongodb metrics.","properties":{"mongodb.cache.operations":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.cache.operations"},"mongodb.collection.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.collection.count"},"mongodb.connection.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.connection.count"},"mongodb.cursor.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.cursor.count"},"mongodb.cursor.timeout.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.cursor.timeout.count"},"mongodb.data.size":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.data.size"},"mongodb.database.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.database.count"},"mongodb.document.operation.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.document.operation.count"},"mongodb.extent.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.extent.count"},"mongodb.global_lock.time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.global_lock.time"},"mongodb.health":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.health"},"mongodb.index.access.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.index.access.count"},"mongodb.index.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.index.count"},"mongodb.index.size":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.index.size"},"mongodb.lock.acquire.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.lock.acquire.count"},"mongodb.lock.acquire.time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.lock.acquire.time"},"mongodb.lock.acquire.wait_count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.lock.acquire.wait_count"},"mongodb.lock.deadlock.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.lock.deadlock.count"},"mongodb.memory.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.memory.usage"},"mongodb.network.io.receive":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.network.io.receive"},"mongodb.network.io.transmit":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.network.io.transmit"},"mongodb.network.request.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.network.request.count"},"mongodb.object.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.object.count"},"mongodb.operation.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.operation.count"},"mongodb.operation.latency.time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.operation.latency.time"},"mongodb.operation.repl.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.operation.repl.count"},"mongodb.operation.time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.operation.time"},"mongodb.session.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.session.count"},"mongodb.storage.size":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.storage.size"},"mongodb.uptime":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.MetricConfig","title":"mongodb.uptime"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for mongodb resource attributes.","properties":{"database":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.internal.metadata.ResourceAttributeConfig","title":"database"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.Config":{"additionalProperties":false,"markdownDescription":"# MySQL Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [contrib], [observiq], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThis receiver queries MySQL's global status and InnoDB tables.\n\n## Prerequisites\n\nThis receiver supports MySQL version 8.0\n\nCollecting most metrics requires the ability to execute `SHOW GLOBAL STATUS`.\n\n## Configuration\n\n\nThe following settings are optional:\n- `endpoint`: (default = `localhost:3306`)\n- `username`: (default = `root`)\n- `password`: The password to the username.\n- `allow_native_passwords`: (default = `true`)\n- `database`: The database name. If not specified, metrics will be collected for all databases.\n\n- `collection_interval` (default = `10s`): This receiver collects metrics on an interval. This value must be a string readable by Golang's [time.ParseDuration](https://pkg.go.dev/time#ParseDuration). Valid time units are `ns`, `us` (or `Âµs`), `ms`, `s`, `m`, `h`.\n- `initial_delay` (default = `1s`): defines how long this receiver waits before starting.\n\n- `transport`: (default = `tcp`): Defines the network to use for connecting to the server.\n- `statement_events`: Additional configuration for query to build `mysql.statement_events.count` and `mysql.statement_events.wait.time` metrics:\n  - `digest_text_limit` - maximum length of `digest_text`. Longer text will be truncated (default=`120`)\n  - `time_limit` - maximum time from since the statements have been observed last time (default=`24h`)\n  - `limit` - limit of records, which is maximum number of generated metrics (default=`250`)\n\n### Example Configuration\n\n```yaml\nreceivers:\n  mysql:\n    endpoint: localhost:3306\n    username: otel\n    password: ${env:MYSQL_PASSWORD}\n    database: otel\n    collection_interval: 10s\n    initial_delay: 1s\n    statement_events:\n      digest_text_limit: 120\n      time_limit: 24h\n      limit: 250\n```\n\nThe full list of settings exposed for this receiver are documented [here](./config.go) with detailed sample configurations [here](./testdata/config.yaml).\n\n## Metrics\n\nDetails about the metrics produced by this receiver can be found in [metadata.yaml](./metadata.yaml)","properties":{"allow_native_passwords":{"title":"allow_native_passwords","type":"boolean"},"collection_interval":{"title":"collection_interval","type":"string"},"database":{"title":"database","type":"string"},"endpoint":{"description":"Endpoint configures the address for this network connection.\nFor TCP and UDP networks, the address has the form \"host:port\". The host must be a literal IP address,\nor a host name that can be resolved to IP addresses. The port must be a literal port number or a service name.\nIf the host is a literal IPv6 address it must be enclosed in square brackets, as in \"[2001:db8::1]:80\" or\n\"[fe80::1%zone]:80\". The zone specifies the scope of the literal IPv6 address as defined in RFC 4007.","title":"endpoint","type":"string"},"initial_delay":{"title":"initial_delay","type":"string"},"metrics":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricsConfig","title":"metrics"},"password":{"title":"password","type":"string"},"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"},"statement_events":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.StatementEventsConfig","title":"statement_events"},"transport":{"description":"Transport to use. Known protocols are \"tcp\", \"tcp4\" (IPv4-only), \"tcp6\" (IPv6-only), \"udp\", \"udp4\" (IPv4-only),\n\"udp6\" (IPv6-only), \"ip\", \"ip4\" (IPv4-only), \"ip6\" (IPv6-only), \"unix\", \"unixgram\" and \"unixpacket\".","title":"transport","type":"string"},"username":{"title":"username","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.StatementEventsConfig":{"additionalProperties":false,"properties":{"digest_text_limit":{"title":"digest_text_limit","type":"integer"},"limit":{"title":"limit","type":"integer"},"time_limit":{"title":"time_limit","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig":{"additionalProperties":false,"description":"MetricConfig provides common config for a particular metric.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricsConfig":{"additionalProperties":false,"description":"MetricsConfig provides config for mysql metrics.","properties":{"mysql.buffer_pool.data_pages":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.buffer_pool.data_pages"},"mysql.buffer_pool.limit":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.buffer_pool.limit"},"mysql.buffer_pool.operations":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.buffer_pool.operations"},"mysql.buffer_pool.page_flushes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.buffer_pool.page_flushes"},"mysql.buffer_pool.pages":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.buffer_pool.pages"},"mysql.buffer_pool.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.buffer_pool.usage"},"mysql.client.network.io":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.client.network.io"},"mysql.commands":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.commands"},"mysql.connection.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.connection.count"},"mysql.connection.errors":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.connection.errors"},"mysql.double_writes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.double_writes"},"mysql.handlers":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.handlers"},"mysql.index.io.wait.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.index.io.wait.count"},"mysql.index.io.wait.time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.index.io.wait.time"},"mysql.joins":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.joins"},"mysql.locked_connects":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.locked_connects"},"mysql.locks":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.locks"},"mysql.log_operations":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.log_operations"},"mysql.mysqlx_connections":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.mysqlx_connections"},"mysql.mysqlx_worker_threads":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.mysqlx_worker_threads"},"mysql.opened_resources":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.opened_resources"},"mysql.operations":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.operations"},"mysql.page_operations":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.page_operations"},"mysql.prepared_statements":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.prepared_statements"},"mysql.query.client.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.query.client.count"},"mysql.query.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.query.count"},"mysql.query.slow.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.query.slow.count"},"mysql.replica.sql_delay":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.replica.sql_delay"},"mysql.replica.time_behind_source":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.replica.time_behind_source"},"mysql.row_locks":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.row_locks"},"mysql.row_operations":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.row_operations"},"mysql.sorts":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.sorts"},"mysql.statement_event.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.statement_event.count"},"mysql.statement_event.wait.time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.statement_event.wait.time"},"mysql.table.io.wait.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.table.io.wait.count"},"mysql.table.io.wait.time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.table.io.wait.time"},"mysql.table.lock_wait.read.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.table.lock_wait.read.count"},"mysql.table.lock_wait.read.time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.table.lock_wait.read.time"},"mysql.table.lock_wait.write.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.table.lock_wait.write.count"},"mysql.table.lock_wait.write.time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.table.lock_wait.write.time"},"mysql.table_open_cache":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.table_open_cache"},"mysql.threads":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.threads"},"mysql.tmp_resources":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.tmp_resources"},"mysql.uptime":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.MetricConfig","title":"mysql.uptime"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for mysql resource attributes.","properties":{"mysql.instance.endpoint":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.internal.metadata.ResourceAttributeConfig","title":"mysql.instance.endpoint"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.nginxreceiver.Config":{"additionalProperties":false,"markdownDescription":"# Nginx Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [contrib], [observiq], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThis receiver can fetch stats from a Nginx instance using the `ngx_http_stub_status_module` module's `status` endpoint.\n\n## Details\n\n## Configuration\n\n### Nginx Module\nYou must configure NGINX to expose status information by editing the NGINX\nconfiguration.  Please see\n[ngx_http_stub_status_module](http://nginx.org/en/docs/http/ngx_http_stub_status_module.html)\nfor a guide to configuring the NGINX stats module `ngx_http_stub_status_module`.\n\n### Receiver Config\n\n\u003e :information_source: This receiver is in beta and configuration fields are subject to change.\n\nThe following settings are required:\n\n- `endpoint` (default: `http://localhost:80/status`): The URL of the nginx status endpoint\n\nThe following settings are optional:\n\n- `collection_interval` (default = `10s`): This receiver runs on an interval.\nEach time it runs, it queries nginx, creates metrics, and sends them to the\nnext consumer. The `collection_interval` configuration option tells this\nreceiver the duration between runs. This value must be a string readable by\nGolang's `ParseDuration` function (example: `1h30m`). Valid time units are\n`ns`, `us` (or `Âµs`), `ms`, `s`, `m`, `h`.\n- `initial_delay` (default = `1s`): defines how long this receiver waits before starting.\n\nExample:\n\n```yaml\nreceivers:\n  nginx:\n    endpoint: \"http://localhost:80/status\"\n    collection_interval: 10s\n```\n\nThe full list of settings exposed for this receiver are documented [here](./config.go)\nwith detailed sample configurations [here](./testdata/config.yaml).\n\n## Feature gate configurations\n\nSee the [Collector feature gates](https://github.com/open-telemetry/opentelemetry-collector/blob/main/featuregate/README.md#collector-feature-gates) for an overview of feature gates in the collector.\n\n**ALPHA**: `receiver.nginx.emitCurrentConnectionsAsSum`\n\nThe feature gate `receiver.nginx.emitConnectionsCurrentAsSum` once enabled will change the data type of the\n`nginx.connections_current` metric from a gauge to a non-monotonic sum.\n\nThis feature gate will eventually be enabled by default, and eventually the old implementation will be removed. It aims\nto give users time to migrate to the new implementation. The target release for this featuregate to be enabled by default\nis 0.80.0.","properties":{"CustomRoundTripper":{"description":"Custom Round Tripper to allow for individual components to intercept HTTP requests","title":"CustomRoundTripper"},"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth configuration for outgoing HTTP calls.","title":"auth"},"collection_interval":{"title":"collection_interval","type":"string"},"compression":{"description":"The compression key for supported compression types within collector.","title":"compression","type":"string"},"endpoint":{"description":"The target URL to send data to (e.g.: http://some.url:9411/v1/traces).","title":"endpoint","type":"string"},"headers":{"description":"Additional headers attached to each HTTP request sent by the client.\nExisting header values are overwritten if collision happens.\nHeader values are opaque since they may be sensitive.","patternProperties":{".*":{"type":"string"}},"title":"headers","type":"object"},"idle_conn_timeout":{"description":"IdleConnTimeout is the maximum amount of time a connection will remain open before closing itself.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"idle_conn_timeout","type":"string"},"initial_delay":{"title":"initial_delay","type":"string"},"max_conns_per_host":{"description":"MaxConnsPerHost limits the total number of connections per host, including connections in the dialing,\nactive, and idle states.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_conns_per_host","type":"integer"},"max_idle_conns":{"description":"MaxIdleConns is used to set a limit to the maximum idle HTTP connections the client can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns","type":"integer"},"max_idle_conns_per_host":{"description":"MaxIdleConnsPerHost is used to set a limit to the maximum idle HTTP connections the host can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns_per_host","type":"integer"},"metrics":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.nginxreceiver.internal.metadata.MetricsConfig","title":"metrics"},"read_buffer_size":{"description":"ReadBufferSize for HTTP client. See http.Transport.ReadBufferSize.","title":"read_buffer_size","type":"integer"},"timeout":{"description":"Timeout parameter configures `http.Client.Timeout`.","title":"timeout","type":"string"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","description":"TLSSetting struct exposes TLS client configuration.","title":"tls"},"write_buffer_size":{"description":"WriteBufferSize for HTTP client. See http.Transport.WriteBufferSize.","title":"write_buffer_size","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.nginxreceiver.internal.metadata.MetricConfig":{"additionalProperties":false,"description":"MetricConfig provides common config for a particular metric.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.nginxreceiver.internal.metadata.MetricsConfig":{"additionalProperties":false,"description":"MetricsConfig provides config for nginx metrics.","properties":{"nginx.connections_accepted":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.nginxreceiver.internal.metadata.MetricConfig","title":"nginx.connections_accepted"},"nginx.connections_current":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.nginxreceiver.internal.metadata.MetricConfig","title":"nginx.connections_current"},"nginx.connections_handled":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.nginxreceiver.internal.metadata.MetricConfig","title":"nginx.connections_handled"},"nginx.requests":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.nginxreceiver.internal.metadata.MetricConfig","title":"nginx.requests"},"temp.connections_current":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.nginxreceiver.internal.metadata.MetricConfig","title":"temp.connections_current"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.opencensusreceiver.Config":{"additionalProperties":false,"description":"Config defines configuration for OpenCensus receiver.","markdownDescription":"# OpenCensus Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics, traces   |\n| Distributions | [core], [contrib], [observiq], [redhat], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[core]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[redhat]: https://github.com/os-observability/redhat-opentelemetry-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nReceives data via gRPC or HTTP using [OpenCensus]( https://opencensus.io/)\nformat.\n\n## Getting Started\n\nAll that is required to enable the OpenCensus receiver is to include it in the\nreceiver definitions.\n\n```yaml\nreceivers:\n  opencensus:\n```\n\nThe following settings are configurable:\n\n- `endpoint` (default = 0.0.0.0:55678): host:port to which the receiver is\n  going to receive data. The valid syntax is described at\n  https://github.com/grpc/grpc/blob/master/doc/naming.md.\n\n## Advanced Configuration\n\nSeveral helper files are leveraged to provide additional capabilities automatically:\n\n- [gRPC settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/configgrpc/README.md) including CORS\n- [TLS and mTLS settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/configtls/README.md)\n- [Queuing, retry and timeout settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/exporter/exporterhelper/README.md)\n\n## Writing with HTTP/JSON\n\nThe OpenCensus receiver can receive trace export calls via HTTP/JSON in\naddition to gRPC. The HTTP/JSON address is the same as gRPC as the protocol is\nrecognized and processed accordingly.\n\nTo write traces with HTTP/JSON, `POST` to `[address]/v1/trace`. The JSON message\nformat parallels the gRPC protobuf format, see this\n[OpenApi spec for it](https://github.com/census-instrumentation/opencensus-proto/blob/master/gen-openapi/opencensus/proto/agent/trace/v1/trace_service.swagger.json).\n\nThe HTTP/JSON endpoint can also optionally configure\n[CORS](https://fetch.spec.whatwg.org/#cors-protocol), which is enabled by\nspecifying a list of allowed CORS origins in the `cors_allowed_origins` field:\n\n```yaml\nreceivers:\n  opencensus:\n    cors_allowed_origins:\n    - http://test.com\n    # Origins can have wildcards with *, use * by itself to match any origin.\n    - https://*.example.com\n```","properties":{"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth for this receiver","title":"auth"},"cors_allowed_origins":{"description":"CorsOrigins are the allowed CORS origins for HTTP/JSON requests to grpc-gateway adapter\nfor the OpenCensus receiver. See github.com/rs/cors\nAn empty list means that CORS is not enabled at all. A wildcard (*) can be\nused to match any origin or one or more characters of an origin.","items":{"type":"string"},"title":"cors_allowed_origins","type":"array"},"endpoint":{"description":"Endpoint configures the address for this network connection.\nFor TCP and UDP networks, the address has the form \"host:port\". The host must be a literal IP address,\nor a host name that can be resolved to IP addresses. The port must be a literal port number or a service name.\nIf the host is a literal IPv6 address it must be enclosed in square brackets, as in \"[2001:db8::1]:80\" or\n\"[fe80::1%zone]:80\". The zone specifies the scope of the literal IPv6 address as defined in RFC 4007.","title":"endpoint","type":"string"},"include_metadata":{"description":"Include propagates the incoming connection's metadata to downstream consumers.\nExperimental: *NOTE* this option is subject to change or removal in the future.","title":"include_metadata","type":"boolean"},"keepalive":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configgrpc.KeepaliveServerConfig","description":"Keepalive anchor for all the settings related to keepalive.","title":"keepalive"},"max_concurrent_streams":{"description":"MaxConcurrentStreams sets the limit on the number of concurrent streams to each ServerTransport.\nIt has effect only for streaming RPCs.","title":"max_concurrent_streams","type":"integer"},"max_recv_msg_size_mib":{"description":"MaxRecvMsgSizeMiB sets the maximum size (in MiB) of messages accepted by the server.","title":"max_recv_msg_size_mib","type":"integer"},"read_buffer_size":{"description":"ReadBufferSize for gRPC server. See grpc.ReadBufferSize.\n(https://godoc.org/google.golang.org/grpc#ReadBufferSize).","title":"read_buffer_size","type":"integer"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSServerSetting","description":"Configures the protocol to use TLS.\nThe default value is nil, which will cause the protocol to not use TLS.","title":"tls"},"transport":{"description":"Transport to use. Known protocols are \"tcp\", \"tcp4\" (IPv4-only), \"tcp6\" (IPv6-only), \"udp\", \"udp4\" (IPv4-only),\n\"udp6\" (IPv6-only), \"ip\", \"ip4\" (IPv4-only), \"ip6\" (IPv6-only), \"unix\", \"unixgram\" and \"unixpacket\".","title":"transport","type":"string"},"write_buffer_size":{"description":"WriteBufferSize for gRPC server. See grpc.WriteBufferSize.\n(https://godoc.org/google.golang.org/grpc#WriteBufferSize).","title":"write_buffer_size","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.Config":{"additionalProperties":false,"markdownDescription":"# Oracle DB receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [alpha]: metrics   |\n| Distributions | [contrib], [splunk] |\n\n[alpha]: https://github.com/open-telemetry/opentelemetry-collector#alpha\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThis receiver collects metrics from an Oracle Database.\n\nThe receiver connects to a database host and performs periodically queries.\n\n## Getting Started\n\nTo use the OracleDB receiver you must define how to connect to your DB. This can be done in two ways,\ndefined in the [Primary](#primary-configuration-option) and [Secondary](#secondary-configuration-option) configuration\noption sections. Defining one of the two configurations is required. If both are defined, the primary\noption will be used.\n\n### Primary Configuration Option\n\nRequired options:\n- `datasource`: Oracle database connection string. Special characters must be encoded. Refer to Oracle Go Driver go_ora documentation for full connection string options.\n\nExample:\n\n```yaml\nreceivers:\n  oracledb:\n    datasource: \"oracle://otel:password@localhost:51521/XE\"\n```\n\n### Secondary Configuration Option\n\nRequired options:\n- `endpoint`: Endpoint used to connect to the OracleDB server. Must be in the format of `host:port`\n- `password`: Password for the OracleDB connection. Special characters are allowed.\n- `service`: OracleDB Service that the receiver should connect to.\n- `username`: Username for the OracleDB connection.\n\nExample:\n```yaml\nreceivers:\n  oracledb:\n    endpoint: localhost:51521\n    password: p@sswo%d\n    service: XE\n    username: otel\n```\n\n## Permissions\n\nDepending on which metrics you collect, you will need to assign those permissions to the database user:\n```\nGRANT SELECT ON V_$SESSION TO \u003cusername\u003e;\nGRANT SELECT ON V_$SYSSTAT TO \u003cusername\u003e;\nGRANT SELECT ON V_$RESOURCE_LIMIT TO \u003cusername\u003e;\nGRANT SELECT ON DBA_TABLESPACES TO \u003cusername\u003e;\nGRANT SELECT ON DBA_DATA_FILES TO \u003cusername\u003e;\n```\n\n## Enabling metrics.\n\nSee [documentation](./documentation.md).\n\nYou can enable or disable selective metrics.\n\nExample:\n\n```yaml\nreceivers:\n  oracledb:\n    datasource: \"oracle://otel:password@localhost:51521/XE\"\n    metrics:\n      oracledb.query.cpu_time:\n        enabled: false\n      oracledb.query.physical_read_requests:\n        enabled: true\n```","properties":{"collection_interval":{"title":"collection_interval","type":"string"},"datasource":{"title":"datasource","type":"string"},"endpoint":{"title":"endpoint","type":"string"},"initial_delay":{"title":"initial_delay","type":"string"},"metrics":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricsConfig","title":"metrics"},"password":{"title":"password","type":"string"},"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"},"service":{"title":"service","type":"string"},"username":{"title":"username","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig":{"additionalProperties":false,"description":"MetricConfig provides common config for a particular metric.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricsConfig":{"additionalProperties":false,"description":"MetricsConfig provides config for oracledb metrics.","properties":{"oracledb.consistent_gets":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.consistent_gets"},"oracledb.cpu_time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.cpu_time"},"oracledb.db_block_gets":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.db_block_gets"},"oracledb.dml_locks.limit":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.dml_locks.limit"},"oracledb.dml_locks.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.dml_locks.usage"},"oracledb.enqueue_deadlocks":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.enqueue_deadlocks"},"oracledb.enqueue_locks.limit":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.enqueue_locks.limit"},"oracledb.enqueue_locks.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.enqueue_locks.usage"},"oracledb.enqueue_resources.limit":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.enqueue_resources.limit"},"oracledb.enqueue_resources.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.enqueue_resources.usage"},"oracledb.exchange_deadlocks":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.exchange_deadlocks"},"oracledb.executions":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.executions"},"oracledb.hard_parses":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.hard_parses"},"oracledb.logical_reads":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.logical_reads"},"oracledb.parse_calls":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.parse_calls"},"oracledb.pga_memory":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.pga_memory"},"oracledb.physical_reads":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.physical_reads"},"oracledb.processes.limit":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.processes.limit"},"oracledb.processes.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.processes.usage"},"oracledb.sessions.limit":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.sessions.limit"},"oracledb.sessions.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.sessions.usage"},"oracledb.tablespace_size.limit":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.tablespace_size.limit"},"oracledb.tablespace_size.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.tablespace_size.usage"},"oracledb.transactions.limit":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.transactions.limit"},"oracledb.transactions.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.transactions.usage"},"oracledb.user_commits":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.user_commits"},"oracledb.user_rollbacks":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.MetricConfig","title":"oracledb.user_rollbacks"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for oracledb resource attributes.","properties":{"oracledb.instance.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.internal.metadata.ResourceAttributeConfig","title":"oracledb.instance.name"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.podmanreceiver.Config":{"additionalProperties":false,"properties":{"api_version":{"title":"api_version","type":"string"},"collection_interval":{"title":"collection_interval","type":"string"},"endpoint":{"description":"The URL of the podman server.  Default is \"unix:///run/podman/podman.sock\"","title":"endpoint","type":"string"},"initial_delay":{"title":"initial_delay","type":"string"},"ssh_key":{"title":"ssh_key","type":"string"},"ssh_passphrase":{"title":"ssh_passphrase","type":"string"},"timeout":{"description":"The maximum amount of time to wait for Podman API responses.  Default is 5s","title":"timeout","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.Config":{"additionalProperties":false,"markdownDescription":"# PostgreSQL Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [contrib], [observiq], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThis receiver queries the PostgreSQL [statistics collector](https://www.postgresql.org/docs/9.6/monitoring-stats.html).\n\n\u003e :construction: This receiver is in **BETA**. Configuration fields and metric data model are subject to change.\n\n## Prerequisites\n\nThis receiver supports PostgreSQL versions 9.6+\n\nThe monitoring user must be granted `SELECT` on `pg_stat_database`.\n\n## Configuration\n\nThe following settings are required to create a database connection:\n\n- `username`\n- `password`\n\nThe following settings are optional:\n\n- `endpoint` (default = `localhost:5432`): The endpoint of the postgresql server. Whether using TCP or Unix sockets, this value should be `host:port`. If `transport` is set to `unix`, the endpoint will internally be translated from `host:port` to `/host.s.PGSQL.port`\n- `transport` (default = `tcp`): The transport protocol being used to connect to postgresql. Available options are `tcp` and `unix`.\n\n- `databases` (default = `[]`): The list of databases for which the receiver will attempt to collect statistics. If an empty list is provided, the receiver will attempt to collect statistics for all non-template databases.\n\nThe following settings are also optional and nested under `tls` to help configure client transport security\n\n- `insecure` (default = `false`): Whether to enable client transport security for the postgresql connection.\n- `insecure_skip_verify` (default = `true`): Whether to validate server name and certificate if client transport security is enabled.\n- `cert_file` (default = `$HOME/.postgresql/postgresql.crt`): A cerficate used for client authentication, if necessary.\n- `key_file` (default = `$HOME/.postgresql/postgresql.key`): An SSL key used for client authentication, if necessary.\n- `ca_file` (default = \"\"): A set of certificate authorities used to validate the database server's SSL certificate.\n\n- `collection_interval` (default = `10s`): This receiver collects metrics on an interval. This value must be a string readable by Golang's [time.ParseDuration](https://pkg.go.dev/time#ParseDuration). Valid time units are `ns`, `us` (or `Âµs`), `ms`, `s`, `m`, `h`.\n- `initial_delay` (default = `1s`): defines how long this receiver waits before starting.\n\n### Example Configuration\n\n```yaml\nreceivers:\n  postgresql:\n    endpoint: localhost:5432\n    transport: tcp\n    username: otel\n    password: ${env:POSTGRESQL_PASSWORD}\n    databases:\n      - otel\n    collection_interval: 10s\n    tls:\n      insecure: false\n      insecure_skip_verify: false\n      ca_file: /home/otel/authorities.crt\n      cert_file: /home/otel/mypostgrescert.crt\n      key_file: /home/otel/mypostgreskey.key\n```\n\nThe full list of settings exposed for this receiver are documented [here](./config.go) with detailed sample configurations [here](./testdata/config.yaml). TLS config is documented further under the [opentelemetry collector's configtls package](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/configtls/README.md). \n\n## Metrics\n\nDetails about the metrics produced by this receiver can be found in [metadata.yaml](./metadata.yaml)","properties":{"collection_interval":{"title":"collection_interval","type":"string"},"databases":{"items":{"type":"string"},"title":"databases","type":"array"},"endpoint":{"description":"Endpoint configures the address for this network connection.\nFor TCP and UDP networks, the address has the form \"host:port\". The host must be a literal IP address,\nor a host name that can be resolved to IP addresses. The port must be a literal port number or a service name.\nIf the host is a literal IPv6 address it must be enclosed in square brackets, as in \"[2001:db8::1]:80\" or\n\"[fe80::1%zone]:80\". The zone specifies the scope of the literal IPv6 address as defined in RFC 4007.","title":"endpoint","type":"string"},"initial_delay":{"title":"initial_delay","type":"string"},"metrics":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricsConfig","title":"metrics"},"password":{"title":"password","type":"string"},"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","title":"tls"},"transport":{"description":"Transport to use. Known protocols are \"tcp\", \"tcp4\" (IPv4-only), \"tcp6\" (IPv6-only), \"udp\", \"udp4\" (IPv4-only),\n\"udp6\" (IPv6-only), \"ip\", \"ip4\" (IPv4-only), \"ip6\" (IPv6-only), \"unix\", \"unixgram\" and \"unixpacket\".","title":"transport","type":"string"},"username":{"title":"username","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricConfig":{"additionalProperties":false,"description":"MetricConfig provides common config for a particular metric.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricsConfig":{"additionalProperties":false,"description":"MetricsConfig provides config for postgresql metrics.","properties":{"postgresql.backends":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricConfig","title":"postgresql.backends"},"postgresql.bgwriter.buffers.allocated":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricConfig","title":"postgresql.bgwriter.buffers.allocated"},"postgresql.bgwriter.buffers.writes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricConfig","title":"postgresql.bgwriter.buffers.writes"},"postgresql.bgwriter.checkpoint.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricConfig","title":"postgresql.bgwriter.checkpoint.count"},"postgresql.bgwriter.duration":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricConfig","title":"postgresql.bgwriter.duration"},"postgresql.bgwriter.maxwritten":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricConfig","title":"postgresql.bgwriter.maxwritten"},"postgresql.blocks_read":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricConfig","title":"postgresql.blocks_read"},"postgresql.commits":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricConfig","title":"postgresql.commits"},"postgresql.connection.max":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricConfig","title":"postgresql.connection.max"},"postgresql.database.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricConfig","title":"postgresql.database.count"},"postgresql.db_size":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricConfig","title":"postgresql.db_size"},"postgresql.index.scans":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricConfig","title":"postgresql.index.scans"},"postgresql.index.size":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricConfig","title":"postgresql.index.size"},"postgresql.operations":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricConfig","title":"postgresql.operations"},"postgresql.replication.data_delay":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricConfig","title":"postgresql.replication.data_delay"},"postgresql.rollbacks":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricConfig","title":"postgresql.rollbacks"},"postgresql.rows":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricConfig","title":"postgresql.rows"},"postgresql.table.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricConfig","title":"postgresql.table.count"},"postgresql.table.size":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricConfig","title":"postgresql.table.size"},"postgresql.table.vacuum.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricConfig","title":"postgresql.table.vacuum.count"},"postgresql.wal.age":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricConfig","title":"postgresql.wal.age"},"postgresql.wal.lag":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.MetricConfig","title":"postgresql.wal.lag"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for postgresql resource attributes.","properties":{"postgresql.database.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.ResourceAttributeConfig","title":"postgresql.database.name"},"postgresql.index.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.ResourceAttributeConfig","title":"postgresql.index.name"},"postgresql.table.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.internal.metadata.ResourceAttributeConfig","title":"postgresql.table.name"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.prometheusexecreceiver.Config":{"additionalProperties":false,"description":"Config definition for prometheus_exec configuration","markdownDescription":"# Deprecated prometheus_exec Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [deprecated]: metrics   |\n| Distributions | [splunk] |\n\n[deprecated]: https://github.com/open-telemetry/opentelemetry-collector#deprecated\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThis receiver has been deprecated due to security concerns around the ability to specify the execution of\nany arbitrary processes via its configuration. See [#6722](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/6722) for additional details.\n\nThis receiver makes it easy for a user to collect metrics from third-party\nservices **via Prometheus exporters**. It's meant for people who want a\nplug-and-play solution to getting metrics from those third-party services\nthat sometimes simply don't natively export metrics or speak any\ninstrumentation protocols (MySQL, Apache, Nginx, JVM, etc.) while taking\nadvantage of the large [Prometheus\nexporters](https://prometheus.io/docs/instrumenting/exporters/) ecosystem.\n\nThrough the configuration file, you can indicate which binaries to run\n(usually [Prometheus\nexporters](https://prometheus.io/docs/instrumenting/exporters/), which are\ncustom binaries that expose the third-party services' metrics using the\nPrometheus protocol) and `prometheus_exec` will take care of starting the\nspecified binaries with their equivalent Prometheus receiver. This receiver\nalso supports starting binaries with flags and environment variables,\nretrying them with exponential backoff if they crash, string templating, and\nrandom port assignments.\n\n\u003e :information_source: If you do not need to spawn the binaries locally,\nplease consider using the [core Prometheus\nreceiver](../prometheusreceiver)\nor the [Simple Prometheus\nreceiver](../simpleprometheusreceiver).\n\n## Configuration\n\nFor each `prometheus_exec` defined in the configuration file, the specified\ncommand will be run. The command *should* start a binary that exposes\nPrometheus metrics and an equivalent Prometheus receiver will be instantiated\nto scrape its metrics, if configured correctly.\n\nThe full list of settings exposed for this receiver are documented [here](./config.go)\nwith detailed sample configurations [here](./testdata/config.yaml).\n\nThe following settings are required:\n\n- `exec` (no default): The string of the command to be run, with any flags\nneeded. The format should be: `directory/binary_to_run flag1 flag2`.\n\nThe following settings are optional:\n\n- `env` (no default): To use environment variables, under the `env` key\nshould be a list of key (`name`) - value (`value`) pairs. They are\ncase-sensitive. When running a command, these environment variables are added\nto the pre-existing environment variables the Collector is currently running\nwith.\n- `scrape_interval` (default = `60s`): How long the delay between scrapes\ndone by the receiver is.\n- `port` (no default): A number indicating the port the receiver should be\nscraping the binary's metrics from.\n\nTwo important notes about `port`:\n\n1. If it is omitted, we will try to randomly generate a port\nfor you, and retry until we find one that is free. Beware when using this,\nsince you also need to indicate your binary to listen on that same port with\nthe use of a flag and string templating inside the command, which is covered\nin 2.\n\n2. **All** instances of `{{port}}` in any string of any key for the enclosing\n`prometheus_exec` will be replaced with either the port value indicated or\nthe randomly generated one if no port value is set with the `port` key.\nString templating of `{{port}}` is supported in `exec`, `custom_name` and\n`env`.\n\nExample:\n\n```yaml\nreceivers:\n    # this receiver will listen on port 9117\n    prometheus_exec/apache:\n        exec: ./apache_exporter\n        port: 9117\n\n    # this receiver will listen on port 9187 and {{port}} inside the command will become 9187\n    prometheus_exec/postgresql:\n        exec: ./postgres_exporter --web.listen-address=:{{port}}\n        port: 9187\n\n    # this receiver will listen on a random port and that port will be substituting the {{port}} inside the command\n    prometheus_exec/mysql:\n        exec: ./mysqld_exporter --web.listen-address=:{{port}}\n        scrape_interval: 60s\n        env:\n          - name: DATA_SOURCE_NAME\n            value: user:password@(hostname:port)/dbname\n          - name: SECONDARY_PORT\n            value: {{port}}\n```\n\nThe full list of settings exposed for this receiver are documented [here](./config.go)\nwith detailed sample configurations [here](./testdata/config.yaml).","properties":{"env":{"description":"Env is a list of env variables to pass to a specific command","items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.prometheusexecreceiver.subprocessmanager.EnvConfig"},"title":"env","type":"array"},"exec":{"description":"Command is the command to be run (binary + flags, separated by commas)","title":"exec","type":"string"},"port":{"description":"Port is the port assigned to the Receiver, and to the {{port}} template variables","title":"port","type":"integer"},"scrape_interval":{"description":"Generic receiver config\nScrapeInterval is the time between each scrape completed by the Receiver","title":"scrape_interval","type":"string"},"scrape_timeout":{"description":"ScrapeTimeout is the time to wait before throttling a scrape request","title":"scrape_timeout","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.prometheusexecreceiver.subprocessmanager.EnvConfig":{"additionalProperties":false,"description":"EnvConfig is the config definition of each key-value pair for environment variables","properties":{"name":{"description":"Name is the name of the environment variable","title":"name","type":"string"},"value":{"description":"Value is the value of the variable","title":"value","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.prometheusreceiver.Config":{"additionalProperties":false,"description":"Config defines configuration for Prometheus receiver.","markdownDescription":"# Prometheus Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [core], [contrib], [aws], [observiq], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[core]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nReceives metric data in [Prometheus](https://prometheus.io/) format. See the\n[Design](DESIGN.md) for additional information on this receiver.\n\n## âš ï¸ Warning\n\nNote: This component is currently work in progress. It has several limitations\nand please don't use it if the following limitations is a concern:\n\n* Collector cannot auto-scale the scraping yet when multiple replicas of the\n  collector is run. \n* When running multiple replicas of the collector with the same config, it will\n  scrape the targets multiple times.\n* Users need to configure each replica with different scraping configuration\n  if they want to manually shard the scraping.\n* The Prometheus receiver is a stateful component.\n\n## Unsupported features\nThe Prometheus receiver is meant to minimally be a drop-in replacement for Prometheus. However,\nthere are advanced features of Prometheus that we don't support and thus explicitly will return\nan error for if the receiver's configuration YAML/code contains any of the following\n\n- [x] alert_config.alertmanagers\n- [x] alert_config.relabel_configs\n- [x] remote_read\n- [x] remote_write\n- [x] rule_files\n\n\n## Getting Started\n\nThis receiver is a drop-in replacement for getting Prometheus to scrape your\nservices. It supports [the full set of Prometheus configuration in `scrape_config`][sc],\nincluding service discovery. Just like you would write in a YAML configuration\nfile before starting Prometheus, such as with:\n\n**Note**: Since the collector configuration supports env variable substitution\n`$` characters in your prometheus configuration are interpreted as environment\nvariables.  If you want to use $ characters in your prometheus configuration,\nyou must escape them using `$$`.\n\n```shell\nprometheus --config.file=prom.yaml\n```\n\n**Feature gates**:\n\n- `receiver.prometheusreceiver.UseCreatedMetric`: Start time for Summary, Histogram \n  and Sum metrics can be retrieved from `_created` metrics. Currently, this behaviour\n  is disabled by default. To enable it, use the following feature gate option:\n\n```shell\n\"--feature-gates=receiver.prometheusreceiver.UseCreatedMetric\"\n```\n\nYou can copy and paste that same configuration under:\n\n```yaml\nreceivers:\n  prometheus:\n    config:\n```\n\nFor example:\n\n```yaml\nreceivers:\n    prometheus:\n      config:\n        scrape_configs:\n          - job_name: 'otel-collector'\n            scrape_interval: 5s\n            static_configs:\n              - targets: ['0.0.0.0:8888']\n          - job_name: k8s\n            kubernetes_sd_configs:\n            - role: pod\n            relabel_configs:\n            - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]\n              regex: \"true\"\n              action: keep\n            metric_relabel_configs:\n            - source_labels: [__name__]\n              regex: \"(request_duration_seconds.*|response_duration_seconds.*)\"\n              action: keep\n```\n\n## OpenTelemetry Operator \nAdditional to this static job definitions this receiver allows to query a list of jobs from the \nOpenTelemetryOperators TargetAllocator or a compatible endpoint. \n\n```yaml\nreceivers:\n  prometheus:\n    target_allocator:\n      endpoint: http://my-targetallocator-service\n      interval: 30s\n      collector_id: collector-1\n```\n## Exemplars\nThis receiver accepts exemplars coming in Prometheus format and converts it to OTLP format.\n1. Value is expected to be received in `float64` format\n2. Timestamp is expected to be received in `ms`\n3. Labels with key `span_id` in prometheus exemplars are set as OTLP `span id` and labels with key `trace_id` are set as `trace id`\n4. Rest of the labels are copied as it is to OTLP format\n\n[sc]: https://github.com/prometheus/prometheus/blob/v2.28.1/docs/configuration/configuration.md#scrape_config","properties":{"buffer_count":{"title":"buffer_count","type":"integer"},"buffer_period":{"title":"buffer_period","type":"string"},"config":{"description":"ConfigPlaceholder is just an entry to make the configuration pass a check\nthat requires that all keys present in the config actually exist on the\nstructure, ie.: it will error if an unknown key is present.","title":"config"},"start_time_metric_regex":{"title":"start_time_metric_regex","type":"string"},"target_allocator":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.prometheusreceiver.targetAllocator","title":"target_allocator"},"use_start_time_metric":{"description":"UseStartTimeMetric enables retrieving the start time of all counter metrics\nfrom the process_start_time_seconds metric. This is only correct if all counters on that endpoint\nstarted after the process start time, and the process is the only actor exporting the metric after\nthe process started. It should not be used in \"exporters\" which export counters that may have\nstarted before the process itself. Use only if you know what you are doing, as this may result\nin incorrect rate calculations.","title":"use_start_time_metric","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.prometheusreceiver.targetAllocator":{"additionalProperties":false,"properties":{"collector_id":{"title":"collector_id","type":"string"},"endpoint":{"title":"endpoint","type":"string"},"http_sd_config":{"title":"http_sd_config"},"interval":{"title":"interval","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.pulsarreceiver.Athenz":{"additionalProperties":false,"properties":{"key_id":{"title":"key_id","type":"string"},"principal_header":{"title":"principal_header","type":"string"},"private_key":{"title":"private_key","type":"string"},"provider_domain":{"title":"provider_domain","type":"string"},"tenant_domain":{"title":"tenant_domain","type":"string"},"tenant_service":{"title":"tenant_service","type":"string"},"zts_url":{"title":"zts_url","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.pulsarreceiver.Authentication":{"additionalProperties":false,"properties":{"athenz":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.pulsarreceiver.Athenz","title":"athenz"},"oauth2":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.pulsarreceiver.OAuth2","title":"oauth2"},"tls":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.pulsarreceiver.TLS","title":"tls"},"token":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.pulsarreceiver.Token","title":"token"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.pulsarreceiver.Config":{"additionalProperties":false,"markdownDescription":"# Pulsar Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [alpha]: metrics, traces, logs   |\n| Distributions | [contrib] |\n\n[alpha]: https://github.com/open-telemetry/opentelemetry-collector#alpha\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n\u003c!-- end autogenerated section --\u003e\n\nPulsar receiver receives logs, metrics, and traces from Pulsar.\n\n## Getting Started\n\nThe following settings can be optionally configured:\n- `endpoint` (default = pulsar://localhost:6650): The url of pulsar cluster.\n- `topic` (default = otlp_spans for traces, otlp_metrics for metrics, otlp_logs for logs): The name of the pulsar topic to consume from.\n- `encoding` (default = otlp_proto): The encoding of the payload sent to pulsar. Available encodings:\n    - `otlp_proto`: the payload is deserialized to `ExportTraceServiceRequest`.\n    - `jaeger_proto`: the payload is deserialized to a single Jaeger proto `Span`.\n    - `jaeger_json`: the payload is deserialized to a single Jaeger JSON Span using `jsonpb`.\n    - `zipkin_proto`: the payload is deserialized into a list of Zipkin proto spans.\n    - `zipkin_json`: the payload is deserialized into a list of Zipkin V2 JSON spans.\n    - `zipkin_thrift`: the payload is deserialized into a list of Zipkin Thrift spans.\n- `consumer_name`: specifies the consumer name.\n- `auth`\n  - `tls`\n    - `cert_file`:\n    - `key_file`:\n  - `token`\n    - `token`\n  - `oauth2`\n    - `issuer_url`:\n    - `client_id`:\n    - `audience`: \n  - `athenz`\n    - `provider_domain`:\n    - `tenant_domain`:\n    - `tenant_service`:\n    - `private_key`:\n    - `key_id`:\n    - `principal_header`:\n    - `zts_url`:\n- `subscription` (default = otlp_subscription): the subscription name of consumer.\n- `tls_trust_certs_file_path`: path to the CA cert. For a client this verifies the server certificate. Should\n  only be used if `insecure` is set to true.\n- `tls_allow_insecure_connection`: configure whether the Pulsar client accept untrusted TLS certificate from broker (default: false)\n\n\nExample configuration:\n```yaml\nreceivers:\n  pulsar:\n    endpoint: pulsar://localhost:6650\n    topic: otlp-spans\n    subscription: otlp_spans_sub\n    consumer_name: otlp_spans_sub_1\n    encoding: otlp_proto\n    auth:\n      tls:\n        cert_file: cert.pem\n        key_file: key.pem\n    tls_allow_insecure_connection: false\n    tls_trust_certs_file_path: ca.pem\n```","properties":{"auth":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.pulsarreceiver.Authentication","title":"auth"},"consumer_name":{"description":"Name specifies the consumer name.","title":"consumer_name","type":"string"},"encoding":{"description":"Encoding of the messages (default \"otlp_proto\")","title":"encoding","type":"string"},"endpoint":{"description":"Configure the service URL for the Pulsar service.","title":"endpoint","type":"string"},"subscription":{"description":"The Subscription that receiver will be consuming messages from (default \"otlp_subscription\")","title":"subscription","type":"string"},"tls_allow_insecure_connection":{"description":"Configure whether the Pulsar client accept untrusted TLS certificate from broker (default: false)","title":"tls_allow_insecure_connection","type":"boolean"},"tls_trust_certs_file_path":{"description":"Set the path to the trusted TLS certificate file","title":"tls_trust_certs_file_path","type":"string"},"topic":{"description":"The topic of pulsar to consume logs,metrics,traces. (default = \"otlp_traces\" for traces,\n\"otlp_metrics\" for metrics, \"otlp_logs\" for logs)","title":"topic","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.pulsarreceiver.OAuth2":{"additionalProperties":false,"properties":{"audience":{"title":"audience","type":"string"},"client_id":{"title":"client_id","type":"string"},"issuer_url":{"title":"issuer_url","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.pulsarreceiver.TLS":{"additionalProperties":false,"properties":{"cert_file":{"title":"cert_file","type":"string"},"key_file":{"title":"key_file","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.pulsarreceiver.Token":{"additionalProperties":false,"properties":{"token":{"title":"token","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.rabbitmqreceiver.Config":{"additionalProperties":false,"description":"Config defines the configuration for the various elements of the receiver agent.","markdownDescription":"# RabbitMQ Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [contrib], [observiq], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThis receiver fetches stats from a RabbitMQ node using the [RabbitMQ Management Plugin](https://www.rabbitmq.com/management.html).\n\n\u003e :construction: This receiver is in **BETA**. Configuration fields and metric data model are subject to change.\n## Prerequisites\n\nThis receiver supports RabbitMQ versions `3.8` and `3.9`.\n\nThe RabbitMQ Management Plugin must be enabled by following the [official instructions](https://www.rabbitmq.com/management.html#getting-started).\n\nAlso, a user with at least [monitoring](https://www.rabbitmq.com/management.html#permissions) level permissions must be used for monitoring.\n\n## Configuration\n\nThe following settings are required:\n- `username`\n- `password`\n\nThe following settings are optional:\n\n- `endpoint` (default: `http://localhost:15672`): The URL of the node to be monitored.\n- `collection_interval` (default = `10s`): This receiver collects metrics on an interval. Valid time units are `ns`, `us` (or `Âµs`), `ms`, `s`, `m`, `h`.\n- `tls` (defaults defined [here](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/configtls/README.md)): TLS control. By default insecure settings are rejected and certificate verification is on.\n\n### Example Configuration\n\n```yaml\nreceivers:\n  rabbitmq:\n    endpoint: http://localhost:15672\n    username: otelu\n    password: ${env:RABBITMQ_PASSWORD}\n    collection_interval: 10s\n```\n\nThe full list of settings exposed for this receiver are documented [here](./config.go) with detailed sample configurations [here](./testdata/config.yaml). TLS config is documented further under the [opentelemetry collector's configtls package](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/configtls/README.md).\n\n## Metrics\n\nDetails about the metrics produced by this receiver can be found in [metadata.yaml](./metadata.yaml)","properties":{"CustomRoundTripper":{"description":"Custom Round Tripper to allow for individual components to intercept HTTP requests","title":"CustomRoundTripper"},"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth configuration for outgoing HTTP calls.","title":"auth"},"collection_interval":{"title":"collection_interval","type":"string"},"compression":{"description":"The compression key for supported compression types within collector.","title":"compression","type":"string"},"endpoint":{"description":"The target URL to send data to (e.g.: http://some.url:9411/v1/traces).","title":"endpoint","type":"string"},"headers":{"description":"Additional headers attached to each HTTP request sent by the client.\nExisting header values are overwritten if collision happens.\nHeader values are opaque since they may be sensitive.","patternProperties":{".*":{"type":"string"}},"title":"headers","type":"object"},"idle_conn_timeout":{"description":"IdleConnTimeout is the maximum amount of time a connection will remain open before closing itself.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"idle_conn_timeout","type":"string"},"initial_delay":{"title":"initial_delay","type":"string"},"max_conns_per_host":{"description":"MaxConnsPerHost limits the total number of connections per host, including connections in the dialing,\nactive, and idle states.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_conns_per_host","type":"integer"},"max_idle_conns":{"description":"MaxIdleConns is used to set a limit to the maximum idle HTTP connections the client can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns","type":"integer"},"max_idle_conns_per_host":{"description":"MaxIdleConnsPerHost is used to set a limit to the maximum idle HTTP connections the host can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns_per_host","type":"integer"},"metrics":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.rabbitmqreceiver.internal.metadata.MetricsConfig","title":"metrics"},"password":{"title":"password","type":"string"},"read_buffer_size":{"description":"ReadBufferSize for HTTP client. See http.Transport.ReadBufferSize.","title":"read_buffer_size","type":"integer"},"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.rabbitmqreceiver.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"},"timeout":{"description":"Timeout parameter configures `http.Client.Timeout`.","title":"timeout","type":"string"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","description":"TLSSetting struct exposes TLS client configuration.","title":"tls"},"username":{"title":"username","type":"string"},"write_buffer_size":{"description":"WriteBufferSize for HTTP client. See http.Transport.WriteBufferSize.","title":"write_buffer_size","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.rabbitmqreceiver.internal.metadata.MetricConfig":{"additionalProperties":false,"description":"MetricConfig provides common config for a particular metric.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.rabbitmqreceiver.internal.metadata.MetricsConfig":{"additionalProperties":false,"description":"MetricsConfig provides config for rabbitmq metrics.","properties":{"rabbitmq.consumer.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.rabbitmqreceiver.internal.metadata.MetricConfig","title":"rabbitmq.consumer.count"},"rabbitmq.message.acknowledged":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.rabbitmqreceiver.internal.metadata.MetricConfig","title":"rabbitmq.message.acknowledged"},"rabbitmq.message.current":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.rabbitmqreceiver.internal.metadata.MetricConfig","title":"rabbitmq.message.current"},"rabbitmq.message.delivered":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.rabbitmqreceiver.internal.metadata.MetricConfig","title":"rabbitmq.message.delivered"},"rabbitmq.message.dropped":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.rabbitmqreceiver.internal.metadata.MetricConfig","title":"rabbitmq.message.dropped"},"rabbitmq.message.published":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.rabbitmqreceiver.internal.metadata.MetricConfig","title":"rabbitmq.message.published"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.rabbitmqreceiver.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.rabbitmqreceiver.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for rabbitmq resource attributes.","properties":{"rabbitmq.node.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.rabbitmqreceiver.internal.metadata.ResourceAttributeConfig","title":"rabbitmq.node.name"},"rabbitmq.queue.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.rabbitmqreceiver.internal.metadata.ResourceAttributeConfig","title":"rabbitmq.queue.name"},"rabbitmq.vhost.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.rabbitmqreceiver.internal.metadata.ResourceAttributeConfig","title":"rabbitmq.vhost.name"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.receivercreator.Config":{"additionalProperties":false,"description":"Config defines configuration for receiver_creator.","markdownDescription":"# Receiver Creator\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [alpha]: logs, traces   |\n|               | [beta]: metrics   |\n| Distributions | [contrib], [splunk], [sumo] |\n\n[alpha]: https://github.com/open-telemetry/opentelemetry-collector#alpha\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThis receiver can instantiate other receivers at runtime based on whether\nobserved endpoints match a configured rule. To use the receiver creator, you\nmust first configure one or more\n[observers](../../extension/observer/README.md) that will discover networked\nendpoints that you may be interested in. The configured rules will be\nevaluated for each endpoint discovered. If the rule evaluates to true then\nthe receiver for that rule will be started against the matched endpoint.\n\nIf you use the receiver creator in multiple pipelines of differing telemetry types,\nbut a given dynamically instantiated receiver doesn't support one of the pipeline's type,\nit will effectively lead to a logged no-op that won't cause a collector service failure.\n\n## Configuration\n\n**watch_observers**\n\nA list of observers previously defined to be run in the `extensions` section.\nreceiver_creator will watch for endpoints generated by these observers.\n\n**receivers**\n\nA map of receiver names (e.g. `redis/1`) to a template for when and how to\ninstantiate that receiver.\n\n**receivers.\u0026lt;receiver_type/id\u0026gt;.rule**\n\nRule expression using [expvar\nsyntax](https://github.com/antonmedv/expr/blob/master/docs/Language-Definition.md).\nVariables available are detailed below in [Rule\nExpressions](#rule-expressions).\n\n**receivers.\u0026lt;receiver_type/id\u0026gt;.config**\n\nThis is configuration that will be used when creating the receiver at\nruntime.\n\nThis option can use static and dynamic configuration values. Static values\nare normal YAML values. However, the value can also be dynamically constructed\nfrom the discovered endpoint object. Dynamic values are surrounded by\nbackticks (\\`). If a literal backtick is needed use \\\\` to escape it. Dynamic\nvalues can be used with static values in which case they are concatenated.\nFor example:\n\n```yaml\nconfig:\n   secure_url: https://`pod.labels[\"secure_host\"]`\n```\n\nThe value of `secure_url` will be `https://` concatenated with the value of\nthe `secure_host` label.\n\nThis can also be used when the discovered endpoint needs to be changed\ndynamically. For instance, suppose the IP `1.2.3.4` is discovered without a\nport but the port needs to be set inside endpoint. You could do:\n\n```yaml\nconfig:\n   endpoint: '`endpoint`:8080'\n```\n\nIf your target receiver provides an `endpoint` config field and you aren't\nmanually setting it like the above example, the observer endpoint target value\nwill automatically be sourced. If no `endpoint` field is available you are\nrequired to specify any necessary fields.\n\n**receivers.resource_attributes**\n\n```yaml\nresource_attributes:\n  \u003cendpoint type\u003e:\n    \u003cattribute\u003e: \u003cattribute value\u003e\n```\n\nThis setting controls what resource attributes are set on telemetry emitted from the created receiver. These attributes can be set from [values in the endpoint](#rule-expressions) that was matched by the `rule`. These attributes vary based on the endpoint type. These defaults can be disabled by setting the attribute to be removed to an empty value. Note that the values can be dynamic and processed the same as in `config`.\n\nNote that the backticks below are not typos--they indicate the value is set dynamically.\n\n`type == \"pod\"`\n\n| Resource Attribute | Default       |\n|--------------------|---------------|\n| k8s.pod.name       | \\`name\\`      |\n| k8s.pod.uid        | \\`uid\\`       |\n| k8s.namespace.name | \\`namespace\\` |\n\n`type == \"port\"`\n\n| Resource Attribute | Default           |\n|--------------------|-------------------|\n| k8s.pod.name       | \\`pod.name\\`      |\n| k8s.pod.uid        | \\`pod.uid\\`       |\n| k8s.namespace.name | \\`pod.namespace\\` |\n\n`type == \"container\"`\n\n| Resource Attribute   | Default           |\n|----------------------|-------------------|\n| container.name       | \\`name\\`          |\n| container.image.name | \\`image\\`         |\n\n`type == \"hostport\"`\n\nNone\n\n`type == \"k8s.node\"`\n\n| Resource Attribute | Default           |\n|--------------------|-------------------|\n| k8s.node.name      | \\`name\\`          |\n| k8s.node.uid       | \\`uid\\`           |\n\nSee `redis/2` in [examples](#examples).\n\n\n**receivers.\u0026lt;receiver_type/id\u0026gt;.resource_attributes**\n\n```yaml\nreceivers:\n  \u003creceiver_type\u003e:\n    resource_attributes:\n      \u003cattribute\u003e: \u003cattribute string value\u003e\n```\n\nSimilar to the per-endpoint type `resource_attributes` described above but for individual receiver instances. Duplicate attribute entries (including the empty string) in this receiver-specific mapping take precedence. These attribute values also support expansion from endpoint environment content. At this time their values must be strings.\n\n## Rule Expressions\n\nEach rule must start with `type == (\"pod\"|\"port\"|\"hostport\"|\"container\"|\"k8s.node\") \u0026\u0026` such that the rule matches\nonly one endpoint type. Depending on the type of endpoint the rule is\ntargeting it will have different variables available.\n\n### Pod\n\n| Variable    | Description                       |\n|-------------|-----------------------------------|\n| type        | `\"pod\"`                           |\n| id          | ID of source endpoint             |\n| name        | name of the pod                   |\n| namespace   | namespace of the pod              |\n| uid         | unique id of the pod              |\n| labels      | map of labels set on the pod      |\n| annotations | map of annotations set on the pod |\n\n### Port\n\n| Variable        | Description                             |\n|-----------------|-----------------------------------------|\n| type            | `\"port\"`                                |\n| id              | ID of source endpoint                   |\n| name            | container port name                     |\n| port            | port number                             |\n| protocol        | The transport protocol (\"TCP\" or \"UDP\") |\n| pod.name        | name of the owning pod                  |\n| pod.namespace   | namespace of the pod                    |\n| pod.uid         | unique id of the pod                    |\n| pod.labels      | map of labels of the owning pod         |\n| pod.annotations | map of annotations of the owning pod    |\n\n### Host Port\n\n| Variable      | Description                                      |\n|---------------|--------------------------------------------------|\n| type          | `\"hostport\"`                                     |\n| id            | ID of source endpoint                            |\n| process_name  | Name of the process                              |\n| command       | Command line with the used to invoke the process |\n| is_ipv6       | true if endpoint is IPv6, otherwise false        |\n| port          | Port number                                      |\n| transport     | The transport protocol (\"TCP\" or \"UDP\")          |\n\n### Container\n\n| Variable       | Description                                                       |\n|----------------|-------------------------------------------------------------------|\n| type           | `\"container\"`                                                     |\n| id             | ID of source endpoint                                             |\n| name           | Primary name of the container                                     |\n| image          | Name of the container image                                       |\n| port           | Exposed port of the container                                     |\n| alternate_port | Exposed port accessed through redirection, such as a mapped port  |\n| command        | The command used to invoke the process of the container           |\n| container_id   | ID of the container                                               |\n| host           | Hostname or IP of the underlying host the container is running on |\n| transport      | Transport protocol used by the endpoint (TCP or UDP)              |\n| labels         | User-specified metadata labels on the container                   |\n\n### Kubernetes Node\n\n| Variable       | Description                                                       |\n|----------------|-------------------------------------------------------------------|\n| type                  | `\"k8s.node\"`                                                                                                           |\n| id                    | ID of source endpoint                                                                                                  |\n| name                  | The name of the Kubernetes node                                                                                        |\n| uid                   | The unique ID for the node                                                                                             |\n| hostname              | The node's hostname as reported by its Status object                                                                   |\n| external_ip           | The node's external IP address as reported by its Status object                                                        |\n| internal_ip           | The node's internal IP address as reported by its Status object                                                        |\n| external_dns          | The node's external DNS record as reported by its Status object                                                        |\n| internal_dns          | The node's internal DNS record as reported by its Status object                                                        |\n| annotations           | A key-value map of non-identifying, user-specified node metadata                                                       |\n| labels                | A key-value map of user-specified node metadata                                                                        |\n| kubelet_endpoint_port | The node Status object's DaemonEndpoints.KubeletEndpoint.Port value                                                    |\n\n## Examples\n\n```yaml\nextensions:\n  # Configures the Kubernetes observer to watch for pod start and stop events.\n  k8s_observer:\n  host_observer:\n\nreceivers:\n  receiver_creator/1:\n    # Name of the extensions to watch for endpoints to start and stop.\n    watch_observers: [k8s_observer]\n    receivers:\n      prometheus_simple:\n        # Configure prometheus scraping if standard prometheus annotations are set on the pod.\n        rule: type == \"pod\" \u0026\u0026 annotations[\"prometheus.io/scrape\"] == \"true\"\n        config:\n          metrics_path: '`\"prometheus.io/path\" in annotations ? annotations[\"prometheus.io/path\"] : \"/metrics\"`'\n          endpoint: '`endpoint`:`\"prometheus.io/port\" in annotations ? annotations[\"prometheus.io/port\"] : 9090`'\n        resource_attributes:\n          an.attribute: a.value\n          # Dynamic configuration values\n          app.version: '`labels[\"app_version\"]`'\n\n      redis/1:\n        # If this rule matches an instance of this receiver will be started.\n        rule: type == \"port\" \u0026\u0026 port == 6379\n        config:\n          # Static receiver-specific config.\n          password: secret\n          # Dynamic configuration value.\n          collection_interval: '`pod.annotations[\"collection_interval\"]`'\n\n      redis/2:\n        # Set a resource attribute based on endpoint value.\n        rule: type == \"port\" \u0026\u0026 port == 6379\n\n    resource_attributes:\n      # Dynamic configuration values, overwriting default attributes`\n      pod:\n        service.name: '`labels[\"service_name\"]`'\n        app: '`labels[\"app\"]`'\n      port:\n        service.name: '`pod.labels[\"service_name\"]`'\n        app: '`pod.labels[\"app\"]`'\n  receiver_creator/2:\n    # Name of the extensions to watch for endpoints to start and stop.\n    watch_observers: [host_observer]\n    receivers:\n      redis/on_host:\n        # If this rule matches an instance of this receiver will be started.\n        rule: type == \"port\" \u0026\u0026 port == 6379 \u0026\u0026 is_ipv6 == true\n        resource_attributes:\n          service.name: redis_on_host\n  receiver_creator/3:\n    watch_observers: [k8s_observer]\n    receivers:\n      kubeletstats:\n        rule: type == \"k8s.node\"\n        config:\n          auth_type: serviceAccount\n          collection_interval: 10s\n          endpoint: '`endpoint`:`kubelet_endpoint_port`'\n          extra_metadata_labels:\n            - container.id\n          metric_groups:\n            - container\n            - pod\n            - node\n\nprocessors:\n  exampleprocessor:\n\nexporters:\n  exampleexporter:\n\nservice:\n  pipelines:\n    metrics:\n      receivers: [receiver_creator/1, receiver_creator/2, receiver_creator/3]\n      processors: [exampleprocessor]\n      exporters: [exampleexporter]\n  extensions: [k8s_observer, host_observer]\n```\n\nThe full list of settings exposed for this receiver are documented [here](./config.go)\nwith detailed sample configurations [here](./testdata/config.yaml).","properties":{"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.receivercreator.resourceAttributes","description":"ResourceAttributes is a map of default resource attributes to add to each resource\nobject received by this receiver from dynamically created receivers.","title":"resource_attributes"},"watch_observers":{"description":"WatchObservers are the extensions to listen to endpoints from.","items":{"type":"string"},"title":"watch_observers","type":"array"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.receivercreator.resourceAttributes":{"patternProperties":{".*":{"patternProperties":{".*":{"type":"string"}},"type":"object"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.Config":{"additionalProperties":false,"markdownDescription":"# Redis Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [contrib], [observiq], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe Redis receiver is designed to retrieve Redis INFO data from a single Redis\ninstance, build metrics from that data, and send them to the next consumer at a\nconfigurable interval.\n\n## Details\n\nThe Redis INFO command returns information and statistics about a Redis\nserver (see [https://redis.io/commands/info](https://redis.io/commands/info) for\ndetails). The Redis receiver extracts values from the result and converts them to open\ntelemetry metrics. Details about the metrics produced by the Redis receiver\ncan be found by browsing [metric_functions.go](metric_functions.go).\n\nFor example, one of the fields returned by the Redis INFO command is\n`used_cpu_sys` which indicates the system CPU consumed by the Redis server,\nexpressed in seconds, since the start of the Redis instance.\n\nThe Redis receiver turns this data into a gauge...\n\n```go\nfunc usedCPUSys() *redisMetric {\n\treturn \u0026redisMetric{\n\t\tkey:    \"used_cpu_sys\",\n\t\tname:   \"redis.cpu.time\",\n\t\tunits:  \"s\",\n\t\tmdType: metricspb.MetricDescriptor_GAUGE_DOUBLE,\n\t\tlabels: map[string]string{\"state\": \"sys\"},\n\t}\n}\n```\n\nwith a metric name of `redis.cpu.time` and a units value of `s` (seconds).\n\n## Configuration\n\n\u003e :information_source: This receiver is in beta and configuration fields are subject to change.\n\nThe following settings are required:\n\n- `endpoint` (no default): The hostname and port of the Redis instance,\nseparated by a colon.\n\nThe following settings are optional:\n\n- `collection_interval` (default = `10s`): This receiver runs on an interval.\nEach time it runs, it queries Redis, creates metrics, and sends them to the\nnext consumer. The `collection_interval` configuration option tells this\nreceiver the duration between runs. This value must be a string readable by\nGolang's `ParseDuration` function (example: `1h30m`). Valid time units are\n`ns`, `us` (or `Âµs`), `ms`, `s`, `m`, `h`.\n- `password` (no default): The password used to access the Redis instance;\nmust match the password specified in the `requirepass` server configuration\noption.\n- `transport` (default = `tcp`) Defines the network to use for connecting to the server. Valid Values are `tcp` or `Unix`\n- `tls`:\n  - `insecure` (default = true): whether to disable client transport security for the exporter's connection.\n  - `ca_file`: path to the CA cert. For a client this verifies the server certificate. Should only be used if `insecure` is set to false.\n  - `cert_file`: path to the TLS cert to use for TLS required connections. Should only be used if `insecure` is set to false.\n  - `key_file`: path to the TLS key to use for TLS required connections. Should only be used if `insecure` is set to false.\n\nExample:\n\n```yaml\nreceivers:\n  redis:\n    endpoint: \"localhost:6379\"\n    collection_interval: 10s\n    password: ${env:REDIS_PASSWORD}\n```\n\n\u003e :information_source: As with all Open Telemetry configuration values, a\nreference to an environment variable is supported. For example, to pick up\nthe value of an environment variable `REDIS_PASSWORD`, you could use a\nconfiguration like the following:\n\n```yaml\nreceivers:\n  redis:\n    endpoint: \"localhost:6379\"\n    collection_interval: 10s\n    password: ${env:REDIS_PASSWORD}\n```\n\nThe full list of settings exposed for this receiver are documented [here](./config.go)\nwith detailed sample configurations [here](./testdata/config.yaml).","properties":{"collection_interval":{"title":"collection_interval","type":"string"},"endpoint":{"description":"Endpoint configures the address for this network connection.\nFor TCP and UDP networks, the address has the form \"host:port\". The host must be a literal IP address,\nor a host name that can be resolved to IP addresses. The port must be a literal port number or a service name.\nIf the host is a literal IPv6 address it must be enclosed in square brackets, as in \"[2001:db8::1]:80\" or\n\"[fe80::1%zone]:80\". The zone specifies the scope of the literal IPv6 address as defined in RFC 4007.","title":"endpoint","type":"string"},"initial_delay":{"title":"initial_delay","type":"string"},"metrics":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricsConfig","title":"metrics"},"password":{"description":"Optional password. Must match the password specified in the\nrequirepass server configuration option.","title":"password","type":"string"},"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","title":"tls"},"transport":{"description":"Transport to use. Known protocols are \"tcp\", \"tcp4\" (IPv4-only), \"tcp6\" (IPv6-only), \"udp\", \"udp4\" (IPv4-only),\n\"udp6\" (IPv6-only), \"ip\", \"ip4\" (IPv4-only), \"ip6\" (IPv6-only), \"unix\", \"unixgram\" and \"unixpacket\".","title":"transport","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig":{"additionalProperties":false,"description":"MetricConfig provides common config for a particular metric.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricsConfig":{"additionalProperties":false,"description":"MetricsConfig provides config for redis metrics.","properties":{"redis.clients.blocked":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.clients.blocked"},"redis.clients.connected":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.clients.connected"},"redis.clients.max_input_buffer":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.clients.max_input_buffer"},"redis.clients.max_output_buffer":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.clients.max_output_buffer"},"redis.cmd.calls":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.cmd.calls"},"redis.cmd.usec":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.cmd.usec"},"redis.commands":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.commands"},"redis.commands.processed":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.commands.processed"},"redis.connections.received":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.connections.received"},"redis.connections.rejected":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.connections.rejected"},"redis.cpu.time":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.cpu.time"},"redis.db.avg_ttl":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.db.avg_ttl"},"redis.db.expires":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.db.expires"},"redis.db.keys":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.db.keys"},"redis.keys.evicted":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.keys.evicted"},"redis.keys.expired":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.keys.expired"},"redis.keyspace.hits":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.keyspace.hits"},"redis.keyspace.misses":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.keyspace.misses"},"redis.latest_fork":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.latest_fork"},"redis.maxmemory":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.maxmemory"},"redis.memory.fragmentation_ratio":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.memory.fragmentation_ratio"},"redis.memory.lua":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.memory.lua"},"redis.memory.peak":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.memory.peak"},"redis.memory.rss":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.memory.rss"},"redis.memory.used":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.memory.used"},"redis.net.input":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.net.input"},"redis.net.output":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.net.output"},"redis.rdb.changes_since_last_save":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.rdb.changes_since_last_save"},"redis.replication.backlog_first_byte_offset":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.replication.backlog_first_byte_offset"},"redis.replication.offset":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.replication.offset"},"redis.role":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.role"},"redis.slaves.connected":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.slaves.connected"},"redis.uptime":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.MetricConfig","title":"redis.uptime"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for redis resource attributes.","properties":{"redis.version":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.internal.metadata.ResourceAttributeConfig","title":"redis.version"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.simpleprometheusreceiver.Config":{"additionalProperties":false,"description":"Config defines configuration for simple prometheus receiver.","markdownDescription":"# Simple Prometheus Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [contrib], [observiq], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe `prometheus_simple` receiver is a wrapper around the [prometheus\nreceiver](../prometheusreceiver).\nThis receiver provides a simple configuration interface to configure the\nprometheus receiver to scrape metrics from a single target.\n\n## Configuration\n\nThe following settings are required:\n\n- `endpoint` (default = `localhost:9090`): The endpoint from which prometheus\nmetrics should be scraped.\n\nThe following settings are optional:\n\n- `collection_interval` (default = `10s`): The internal at which metrics should\nbe emitted by this receiver.\n- `metrics_path` (default = `/metrics`): The path to the metrics endpoint.\n- `params` (default = `{}`): The query parameters to pass to the metrics endpoint. If specified, params are appended to `metrics_path` to form the URL with which the target is scraped.\n- `use_service_account` (default = `false`): Whether or not to use the\nKubernetes Pod service account for authentication.\n- `tls_enabled` (default = `false`): Whether or not to use TLS. Only if\n`tls_enabled` is set to `true`, the values under `tls_config` are accounted\nfor. This setting will be deprecated. Please use `tls` instead.\n\nThe `tls_config` section supports the following options. This setting will be deprecated. Please use `tls` instead:\n\n- `ca_file` (no default): Path to the CA cert that has signed the TLS\ncertificate.\n- `cert_file` (no default): Path to the client TLS certificate to use for TLS\nrequired connections.\n- `key_file` (no default): Path to the client TLS key to use for TLS required\nconnections.\n- `insecure_skip_verify` (default = `false`): Whether or not to skip\ncertificate verification.\n\n- `tls`: see [TLS Configuration Settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/configtls/README.md#tls-configuration-settings) for the full set of available options.\n\nExample:\n\n```yaml\n    receivers:\n      prometheus_simple:\n        collection_interval: 10s\n        use_service_account: true\n        endpoint: \"172.17.0.5:9153\"\n        tls:\n          ca_file: \"/path/to/ca\"\n          cert_file: \"/path/to/cert\"\n          key_file: \"/path/to/key\"\n          insecure_skip_verify: true\n    exporters:\n      signalfx:\n        access_token: \u003cSIGNALFX_ACCESS_TOKEN\u003e\n        url: \u003cSIGNALFX_INGEST_URL\u003e\n\n    service:\n      pipelines:\n        metrics:\n          receivers: [prometheus_simple]\n          exporters: [signalfx]\n```\n\nThe full list of settings exposed for this receiver are documented [here](./config.go)\nwith detailed sample configurations [here](./testdata/config.yaml).","properties":{"CustomRoundTripper":{"description":"Custom Round Tripper to allow for individual components to intercept HTTP requests","title":"CustomRoundTripper"},"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth configuration for outgoing HTTP calls.","title":"auth"},"collection_interval":{"description":"CollectionInterval is the interval at which metrics should be collected","title":"collection_interval","type":"string"},"compression":{"description":"The compression key for supported compression types within collector.","title":"compression","type":"string"},"endpoint":{"description":"The target URL to send data to (e.g.: http://some.url:9411/v1/traces).","title":"endpoint","type":"string"},"headers":{"description":"Additional headers attached to each HTTP request sent by the client.\nExisting header values are overwritten if collision happens.\nHeader values are opaque since they may be sensitive.","patternProperties":{".*":{"type":"string"}},"title":"headers","type":"object"},"idle_conn_timeout":{"description":"IdleConnTimeout is the maximum amount of time a connection will remain open before closing itself.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"idle_conn_timeout","type":"string"},"labels":{"description":"Labels static labels","patternProperties":{".*":{"type":"string"}},"title":"labels","type":"object"},"max_conns_per_host":{"description":"MaxConnsPerHost limits the total number of connections per host, including connections in the dialing,\nactive, and idle states.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_conns_per_host","type":"integer"},"max_idle_conns":{"description":"MaxIdleConns is used to set a limit to the maximum idle HTTP connections the client can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns","type":"integer"},"max_idle_conns_per_host":{"description":"MaxIdleConnsPerHost is used to set a limit to the maximum idle HTTP connections the host can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns_per_host","type":"integer"},"metrics_path":{"description":"MetricsPath the path to the metrics endpoint.","title":"metrics_path","type":"string"},"params":{"$ref":"#/$defs/net.url.Values","description":"Params the parameters to the metrics endpoint.","title":"params"},"read_buffer_size":{"description":"ReadBufferSize for HTTP client. See http.Transport.ReadBufferSize.","title":"read_buffer_size","type":"integer"},"timeout":{"description":"Timeout parameter configures `http.Client.Timeout`.","title":"timeout","type":"string"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","description":"TLSSetting struct exposes TLS client configuration.","title":"tls"},"tls_config":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.simpleprometheusreceiver.tlsConfig","title":"tls_config"},"tls_enabled":{"title":"tls_enabled","type":"boolean"},"use_service_account":{"description":"Whether or not to use pod service account to authenticate.","title":"use_service_account","type":"boolean"},"write_buffer_size":{"description":"WriteBufferSize for HTTP client. See http.Transport.WriteBufferSize.","title":"write_buffer_size","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.simpleprometheusreceiver.tlsConfig":{"additionalProperties":false,"properties":{"ca_file":{"title":"ca_file","type":"string"},"cert_file":{"title":"cert_file","type":"string"},"insecure_skip_verify":{"title":"insecure_skip_verify","type":"boolean"},"key_file":{"title":"key_file","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlqueryreceiver.Config":{"additionalProperties":false,"markdownDescription":"# SQL Query Receiver (Alpha)\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [alpha]: metrics   |\n|               | [development]: logs   |\n| Distributions | [contrib], [observiq], [splunk], [sumo] |\n\n[alpha]: https://github.com/open-telemetry/opentelemetry-collector#alpha\n[development]: https://github.com/open-telemetry/opentelemetry-collector#development\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe SQL Query Receiver uses custom SQL queries to generate metrics from a database connection.\n\n\u003e :construction: This receiver is in **ALPHA**. Behavior, configuration fields, and metric data model are subject to\n\u003e change.\n\n## Configuration\n\nThe configuration supports the following top-level fields:\n\n- `driver`(required): The name of the database driver: one of _postgres_, _mysql_, _snowflake_, _sqlserver_, _hdb_ (SAP\n  HANA), or _oracle_ (Oracle DB).\n- `datasource`(required): The datasource value passed to [sql.Open](https://pkg.go.dev/database/sql#Open). This is\n  a driver-specific string usually consisting of at least a database name and connection information. This is sometimes\n  referred to as the \"connection string\" in driver documentation.\n  e.g. _host=localhost port=5432 user=me password=s3cr3t sslmode=disable_\n- `queries`(required): A list of queries, where a query is a sql statement and one or more `logs` and/or `metrics` sections (details below).\n- `collection_interval`(optional): The time interval between query executions. Defaults to _10s_.\n- `storage` (optional, default `\"\"`): The ID of a [storage][storage_extension] extension to be used to [track processed results](#tracking-processed-results).\n\n[storage_extension]: https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/extension/storage/filestorage\n\n### Queries\n\nA _query_ consists of a sql statement and one or more `logs` and/or `metrics` section.\nAt least one `logs` or one `metrics` section is required.\nNote that technically you can put both `logs` and `metrics` sections in a single query section,\nbut it's probably not a real world use case, as the requirements for logs and metrics queries\nare quite different.\n\nAdditionally, each `query` section supports the following properties:\n\n- `tracking_column` (optional, default `\"\"`) Applies only to logs. In case of a parameterized query,\n  defines the column to retrieve the value of the parameter on subsequent query runs.\n  See the below section [Tracking processed results](#tracking-processed-results).\n- `tracking_start_value` (optional, default `\"\"`) Applies only to logs. In case of a parameterized query, defines the initial value for the parameter.\n  See the below section [Tracking processed results](#tracking-processed-results).\n\nExample:\n\n```yaml\nreceivers:\n  sqlquery:\n    driver: postgres\n    datasource: \"host=localhost port=5432 user=postgres password=s3cr3t sslmode=disable\"\n    queries:\n      - sql: \"select * from my_logs where log_id \u003e $$1\"\n        tracking_start_value: \"10000\"\n        tracking_column: log_id\n        logs:\n          - body_column: log_body\n      - sql: \"select count(*) as count, genre from movie group by genre\"\n        metrics:\n          - metric_name: movie.genres\n            value_column: \"count\"\n```\n\n#### Logs Queries\n\nThe `logs` section is in development.\n\n- `body_column` (required) defines the column to use as the log record's body.\n\n##### Tracking processed results\n\nWith the default configuration and a non-parameterized logs query like `select * from my_logs`,\nthe receiver will run the same query every collection interval, which can cause reading the same rows\nover and over again, unless there's an external actor removing the old rows from the `my_logs` table.\n\nTo prevent reading the same rows on every collection interval, use a parameterized query like `select * from my_logs where id_column \u003e ?`,\ntogether with the `tracking_start_value` and `tracking_column` configuration properties.\nThe receiver will use the configured `tracking_start_value` as the value for the query parameter when running the query for the first time.\nAfter each query run, the receiver will store the value of the `tracking_column` from the last row of the result set and use it as the value for the query parameter on next collection interval. To prevent duplicate log downloads, make sure to sort the query results in ascending order by the tracking_column value.\n\nNote that the notation for the parameter depends on the database backend. For example in MySQL this is `?`, in PostgreSQL this is `$1`, in Oracle this is any string identifier starting with a colon `:`, for example `:my_parameter`.\n\nUse the `storage` configuration property of the receiver to persist the tracking value across collector restarts.\n\n#### Metrics queries\n\nEach `metrics` section consists of a\n`metric_name`, a `value_column`, and additional optional fields.\nEach _metric_ in the configuration will produce one OTel metric per row returned from its sql query.\n\n- `metric_name`(required): the name assigned to the OTel metric.\n- `value_column`(required): the column name in the returned dataset used to set the value of the metric's datapoint.\n  This may be case-sensitive, depending on the driver (e.g. Oracle DB).\n- `attribute_columns`(optional): a list of column names in the returned dataset used to set attibutes on the datapoint.\n  These attributes may be case-sensitive, depending on the driver (e.g. Oracle DB).\n- `data_type` (optional): can be `gauge` or `sum`; defaults to `gauge`.\n- `value_type` (optional): can be `int` or `double`; defaults to `int`.\n- `monotonic` (optional): boolean; whether a cumulative sum's value is monotonically increasing (i.e. never rolls over\n  or resets); defaults to false.\n- `aggregation` (optional): only applicable for `data_type=sum`; can be `cumulative` or `delta`; defaults\n  to `cumulative`.\n- `description` (optional): the description applied to the metric.\n- `unit` (optional): the units applied to the metric.\n- `static_attributes` (optional): static attributes applied to the metrics.\n- `start_ts_column` (optional): the name of the column containing the start timestamp, the value of which is applied to \n  the metric's start timestamp (otherwise the current time is used). Only applies if the metric is of type cumulative \n  sum.\n- `ts_column` (optional): the name of the column containing the timestamp, the value of which is applied to the \n  metric's timestamp. This can be current timestamp depending upon the time of last recorded metric's datapoint.\n\n### Example\n\n```yaml\nreceivers:\n  sqlquery:\n    driver: postgres\n    datasource: \"host=localhost port=5432 user=postgres password=s3cr3t sslmode=disable\"\n    storage: file_storage\n    queries:\n      - sql: \"select * from my_logs where log_id \u003e $$1\"\n        tracking_start_value: \"10000\"\n        tracking_column: log_id\n        logs:\n          - body_column: log_body\n      - sql: \"select count(*) as count, genre from movie group by genre\"\n        metrics:\n          - metric_name: movie.genres\n            value_column: \"count\"\n            attribute_columns: [\"genre\"]\n            static_attributes:\n              dbinstance: mydbinstance\n```\n\nGiven a `movie` table with three rows:\n\n| name      | genre  |\n| --------- | ------ |\n| E.T.      | sci-fi |\n| Star Wars | sci-fi |\n| Die Hard  | action |\n\nIf there are two rows returned from the query `select count(*) as count, genre from movie group by genre`:\n\n| count | genre  |\n| ----- | ------ |\n| 2     | sci-fi |\n| 1     | action |\n\nthen the above config will produce two metrics at each collection interval:\n\n```\nMetric #0\nDescriptor:\n     -\u003e Name: movie.genres\n     -\u003e DataType: Gauge\nNumberDataPoints #0\nData point attributes:\n     -\u003e genre: STRING(sci-fi)\n     -\u003e dbinstance: STRING(mydbinstance)\nValue: 2\n\nMetric #1\nDescriptor:\n     -\u003e Name: movie.genres\n     -\u003e DataType: Gauge\nNumberDataPoints #0\nData point attributes:\n     -\u003e genre: STRING(action)\n     -\u003e dbinstance: STRING(mydbinstance)\nValue: 1\n```\n\n#### NULL values\n\nAvoid queries that produce any NULL values. If a query produces a NULL value, a warning will be logged. Furthermore,\nif a configuration references the column that produces a NULL value, an additional error will be logged. However, in\neither case, the receiver will continue to operate.\n\n#### Oracle DB Driver Example\n\nRefer to the config file [provided](./testdata/oracledb-receiver-config.yaml) for an example of using the\nOracle DB driver to connect and query the same table schema and contents as the example above.\nThe Oracle DB driver documentation can be found [here.](https://github.com/sijms/go-ora)\nAnother usage example is the `go_ora`\nexample [here.](https://blogs.oracle.com/developers/post/connecting-a-go-application-to-oracle-database)","properties":{"collection_interval":{"title":"collection_interval","type":"string"},"datasource":{"title":"datasource","type":"string"},"driver":{"title":"driver","type":"string"},"initial_delay":{"title":"initial_delay","type":"string"},"queries":{"items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlqueryreceiver.Query"},"title":"queries","type":"array"},"storage":{"title":"storage","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlqueryreceiver.LogsCfg":{"additionalProperties":false,"properties":{"body_column":{"title":"body_column","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlqueryreceiver.MetricCfg":{"additionalProperties":false,"properties":{"aggregation":{"title":"aggregation","type":"string"},"attribute_columns":{"items":{"type":"string"},"title":"attribute_columns","type":"array"},"data_type":{"title":"data_type","type":"string"},"description":{"title":"description","type":"string"},"metric_name":{"title":"metric_name","type":"string"},"monotonic":{"title":"monotonic","type":"boolean"},"start_ts_column":{"title":"start_ts_column","type":"string"},"static_attributes":{"patternProperties":{".*":{"type":"string"}},"title":"static_attributes","type":"object"},"ts_column":{"title":"ts_column","type":"string"},"unit":{"title":"unit","type":"string"},"value_column":{"title":"value_column","type":"string"},"value_type":{"title":"value_type","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlqueryreceiver.Query":{"additionalProperties":false,"properties":{"logs":{"items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlqueryreceiver.LogsCfg"},"title":"logs","type":"array"},"metrics":{"items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlqueryreceiver.MetricCfg"},"title":"metrics","type":"array"},"sql":{"title":"sql","type":"string"},"tracking_column":{"title":"tracking_column","type":"string"},"tracking_start_value":{"title":"tracking_start_value","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.Config":{"additionalProperties":false,"description":"Config defines configuration for a sqlserver receiver.","markdownDescription":"# Microsoft SQL Server Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [contrib], [observiq], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe `sqlserver` receiver grabs metrics about a Microsoft SQL Server instance using the Windows Performance Counters.\nBecause of this, it is a Windows only receiver.\n\n## Configuration\n\nThe following settings are optional:\n- `collection_interval` (default = `10s`): The internal at which metrics should be emitted by this receiver.\n\nTo collect from a SQL Server with a named instance, both `computer_name` and `instance_name` are required. For a default SQL Server setup, these settings are optional.\n- `computer_name` (optional): The computer name identifies the SQL Server name or IP address of the computer being monitored.\n- `instance_name` (optional): The instance name identifies the specific SQL Server instance being monitored.\n\nExample:\n\n```yaml\n    receivers:\n      sqlserver:\n        collection_interval: 10s\n```\n\nWhen a named instance is used, a computer name and a instance name must be specified.\nExample with named instance:\n\n```yaml\n    receivers:\n      sqlserver:\n        collection_interval: 10s\n        computer_name: CustomServer\n        instance_name: CustomInstance\n        resource_attributes:\n          sqlserver.computer.name:\n            enabled: true\n          sqlserver.instance.name:\n            enabled: true\n```\n\nThe full list of settings exposed for this receiver are documented [here](./config.go) with detailed sample configurations [here](./testdata/config.yaml).\n\n## Metrics\n\nDetails about the metrics produced by this receiver can be found in [documentation.md](./documentation.md)","properties":{"collection_interval":{"title":"collection_interval","type":"string"},"computer_name":{"title":"computer_name","type":"string"},"initial_delay":{"title":"initial_delay","type":"string"},"instance_name":{"title":"instance_name","type":"string"},"metrics":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.MetricsConfig","title":"metrics"},"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.MetricConfig":{"additionalProperties":false,"description":"MetricConfig provides common config for a particular metric.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.MetricsConfig":{"additionalProperties":false,"description":"MetricsConfig provides config for sqlserver metrics.","properties":{"sqlserver.batch.request.rate":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.MetricConfig","title":"sqlserver.batch.request.rate"},"sqlserver.batch.sql_compilation.rate":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.MetricConfig","title":"sqlserver.batch.sql_compilation.rate"},"sqlserver.batch.sql_recompilation.rate":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.MetricConfig","title":"sqlserver.batch.sql_recompilation.rate"},"sqlserver.lock.wait.rate":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.MetricConfig","title":"sqlserver.lock.wait.rate"},"sqlserver.lock.wait_time.avg":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.MetricConfig","title":"sqlserver.lock.wait_time.avg"},"sqlserver.page.buffer_cache.hit_ratio":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.MetricConfig","title":"sqlserver.page.buffer_cache.hit_ratio"},"sqlserver.page.checkpoint.flush.rate":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.MetricConfig","title":"sqlserver.page.checkpoint.flush.rate"},"sqlserver.page.lazy_write.rate":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.MetricConfig","title":"sqlserver.page.lazy_write.rate"},"sqlserver.page.life_expectancy":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.MetricConfig","title":"sqlserver.page.life_expectancy"},"sqlserver.page.operation.rate":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.MetricConfig","title":"sqlserver.page.operation.rate"},"sqlserver.page.split.rate":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.MetricConfig","title":"sqlserver.page.split.rate"},"sqlserver.transaction.rate":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.MetricConfig","title":"sqlserver.transaction.rate"},"sqlserver.transaction.write.rate":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.MetricConfig","title":"sqlserver.transaction.write.rate"},"sqlserver.transaction_log.flush.data.rate":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.MetricConfig","title":"sqlserver.transaction_log.flush.data.rate"},"sqlserver.transaction_log.flush.rate":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.MetricConfig","title":"sqlserver.transaction_log.flush.rate"},"sqlserver.transaction_log.flush.wait.rate":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.MetricConfig","title":"sqlserver.transaction_log.flush.wait.rate"},"sqlserver.transaction_log.growth.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.MetricConfig","title":"sqlserver.transaction_log.growth.count"},"sqlserver.transaction_log.shrink.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.MetricConfig","title":"sqlserver.transaction_log.shrink.count"},"sqlserver.transaction_log.usage":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.MetricConfig","title":"sqlserver.transaction_log.usage"},"sqlserver.user.connection.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.MetricConfig","title":"sqlserver.user.connection.count"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for sqlserver resource attributes.","properties":{"sqlserver.computer.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.ResourceAttributeConfig","title":"sqlserver.computer.name"},"sqlserver.database.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.ResourceAttributeConfig","title":"sqlserver.database.name"},"sqlserver.instance.name":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.internal.metadata.ResourceAttributeConfig","title":"sqlserver.instance.name"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.statsdreceiver.Config":{"additionalProperties":false,"description":"Config defines configuration for StatsD receiver.","markdownDescription":"# StatsD Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: metrics   |\n| Distributions | [contrib], [aws], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\n\nStatsD receiver for ingesting StatsD messages(https://github.com/statsd/statsd/blob/master/docs/metric_types.md) into the OpenTelemetry Collector.\n\nUse case: it does not support horizontal pool of collectors. Desired work case is that customers use the receiver as an agent with a single input at the same time.\n\n## Configuration\n\nThe following settings are required:\n\n- `endpoint` (default = `localhost:8125`): Address and port to listen on.\n\n\nThe Following settings are optional:\n\n- `aggregation_interval: 70s`(default value is 60s): The aggregation time that the receiver aggregates the metrics (similar to the flush interval in StatsD server)\n\n- `enable_metric_type: true`(default value is false): Enable the statsd receiver to be able to emit the metric type(gauge, counter, timer(in the future), histogram(in the future)) as a label.\n\n- `is_monotonic_counter` (default value is false): Set all counter-type metrics the statsd receiver received as monotonic.\n\n- `timer_histogram_mapping:`(default value is below): Specify what OTLP type to convert received timing/histogram data to.\n\n\n`\"statsd_type\"` specifies received Statsd data type. Possible values for this setting are `\"timing\"`, `\"timer\"` and `\"histogram\"`.\n\n`\"observer_type\"` specifies OTLP data type to convert to. We support `\"gauge\"`, `\"summary\"`, and `\"histogram\"`. For `\"gauge\"`, it does not perform any aggregation.\nFor `\"summary`, the statsD receiver will aggregate to one OTLP summary metric for one metric description (the same metric name with the same tags). It will send percentile 0, 10, 50, 90, 95, 100 to the downstream.  The `\"histogram\"` setting selects an [auto-scaling exponential histogram configured with only a maximum size](https://github.com/lightstep/go-expohisto#readme), as shown in the example below.\nTODO: Add a new option to use a smoothed summary like Prometheus: https://github.com/open-telemetry/opentelemetry-collector-contrib/pull/3261 \n\nExample:\n\n```yaml\nreceivers:\n  statsd:\n  statsd/2:\n    endpoint: \"localhost:8127\"\n    aggregation_interval: 70s\n    enable_metric_type: true\n    is_monotonic_counter: false\n    timer_histogram_mapping:\n      - statsd_type: \"histogram\"\n        observer_type: \"gauge\"\n      - statsd_type: \"timing\"\n        observer_type: \"histogram\"\n        histogram: \n          max_size: 100\n```\n\nThe full list of settings exposed for this receiver are documented [here](./config.go)\nwith detailed sample configurations [here](./testdata/config.yaml).\n\n## Aggregation\n\nAggregation is done in statsD receiver. The default aggregation interval is 60s. The receiver only aggregates the metrics with the same metric name, metric type, label keys and label values. After each aggregation interval, the receiver will send all metrics (after aggregation) in this aggregation interval to the following workflow.\n\nIt supports:\nCounter(transferred to int):\n- statsdTestMetric1:3000|c|#mykey:myvalue\nstatsdTestMetric1:4000|c|#mykey:myvalue\n(get the value after incrementation: 7000)\n- statsdTestMetric1:3000|c|#mykey:myvalue\nstatsdTestMetric1:20|c|@0.25|#mykey:myvalue\n(get the value after incrementation with sample rate: 3000+20/0.25=3080)\n\nWhen the receiver receives valid sample rate (greater than 0 and less than 1), we covert the count value to float, divide by the sample rate and then covert back to integer.\n\nThe official [doc](https://github.com/statsd/statsd/blob/master/docs/metric_types.md#counting) does not support negative counter, we follow this pattern at this time. There are some requests for negative counters, we need to ake a look if we want to support later. For example:\nhttps://github.com/influxdata/telegraf/issues/1898\nhttps://thenewstack.io/collecting-metrics-using-statsd-a-standard-for-real-time-monitoring/\nhttps://docs.datadoghq.com/developers/metrics/dogstatsd_metrics_submission/#count\n\nGauge(transferred to double):\n- statsdTestMetric1:500|g|#mykey:myvalue\nstatsdTestMetric1:400|g|#mykey:myvalue\n(get the latest value: 400)\n- statsdTestMetric1:500|g|#mykey:myvalue\nstatsdTestMetric1:+2|g|#mykey:myvalue\nstatsdTestMetric1:-1|g|#mykey:myvalue\n(get the value after calculation: 501)\n\n## Metrics\n\nGeneral format is:\n\n`\u003cname\u003e:\u003cvalue\u003e|\u003ctype\u003e|@\u003csample-rate\u003e|#\u003ctag1-key\u003e:\u003ctag1-value\u003e,\u003ctag2-k/v\u003e`\n\n### Counter\n\n`\u003cname\u003e:\u003cvalue\u003e|c|@\u003csample-rate\u003e|#\u003ctag1-key\u003e:\u003ctag1-value\u003e`\n\nIt supports sample rate.\nTODO: Need to change the implementation part for sample rate after OTLP supports sample rate as a parameter later.\n\n\n### Gauge\n\n`\u003cname\u003e:\u003cvalue\u003e|g|@\u003csample-rate\u003e|#\u003ctag1-key\u003e:\u003ctag1-value\u003e`\n\n\n### Timer\n\n`\u003cname\u003e:\u003cvalue\u003e|ms|@\u003csample-rate\u003e|#\u003ctag1-key\u003e:\u003ctag1-value\u003e`\n`\u003cname\u003e:\u003cvalue\u003e|h|@\u003csample-rate\u003e|#\u003ctag1-key\u003e:\u003ctag1-value\u003e`\n\nIt supports sample rate.\n\n\n## Testing\n\n### Full sample collector config\n\n```yaml\nreceivers:\n  statsd:\n    endpoint: \"localhost:8125\" # default\n    aggregation_interval: 60s  # default\n    enable_metric_type: false   # default\n    is_monotonic_counter: false # default\n    timer_histogram_mapping:\n      - statsd_type: \"histogram\"\n        observer_type: \"histogram\"\n        histogram:\n          max_size: 50\n      - statsd_type: \"timing\"\n        observer_type: \"summary\"\n\nexporters:\n  file:\n    path: ./test.json\n\nservice:\n  pipelines:\n    metrics:\n     receivers: [statsd]\n     exporters: [file]\n```\n\n### Send StatsD message into the receiver\n\nA simple way to send a metric to `localhost:8125`:\n\n`echo \"test.metric:42|c|#myKey:myVal\" | nc -w 1 -u localhost 8125`","properties":{"aggregation_interval":{"title":"aggregation_interval","type":"string"},"enable_metric_type":{"title":"enable_metric_type","type":"boolean"},"endpoint":{"description":"Endpoint configures the address for this network connection.\nFor TCP and UDP networks, the address has the form \"host:port\". The host must be a literal IP address,\nor a host name that can be resolved to IP addresses. The port must be a literal port number or a service name.\nIf the host is a literal IPv6 address it must be enclosed in square brackets, as in \"[2001:db8::1]:80\" or\n\"[fe80::1%zone]:80\". The zone specifies the scope of the literal IPv6 address as defined in RFC 4007.","title":"endpoint","type":"string"},"is_monotonic_counter":{"title":"is_monotonic_counter","type":"boolean"},"timer_histogram_mapping":{"items":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.statsdreceiver.protocol.TimerHistogramMapping"},"title":"timer_histogram_mapping","type":"array"},"transport":{"description":"Transport to use. Known protocols are \"tcp\", \"tcp4\" (IPv4-only), \"tcp6\" (IPv6-only), \"udp\", \"udp4\" (IPv4-only),\n\"udp6\" (IPv6-only), \"ip\", \"ip4\" (IPv4-only), \"ip6\" (IPv6-only), \"unix\", \"unixgram\" and \"unixpacket\".","title":"transport","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.statsdreceiver.protocol.HistogramConfig":{"additionalProperties":false,"properties":{"max_size":{"title":"max_size","type":"integer"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.statsdreceiver.protocol.TimerHistogramMapping":{"additionalProperties":false,"properties":{"histogram":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.statsdreceiver.protocol.HistogramConfig","title":"histogram"},"observer_type":{"title":"observer_type","type":"string"},"statsd_type":{"title":"statsd_type","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zipkinreceiver.Config":{"additionalProperties":false,"description":"Config defines configuration for Zipkin receiver.","markdownDescription":"# Zipkin Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [beta]: traces   |\n| Distributions | [core], [contrib], [aws], [observiq], [redhat], [splunk], [sumo] |\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[core]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[aws]: https://github.com/aws-observability/aws-otel-collector\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[redhat]: https://github.com/os-observability/redhat-opentelemetry-collector\n[splunk]: https://github.com/signalfx/splunk-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThis receiver receives spans from [Zipkin](https://zipkin.io/) (V1 and V2).\n\n## Getting Started\n\nAll that is required to enable the Zipkin receiver is to include it in the\nreceiver definitions.\n\n```yaml\nreceivers:\n  zipkin:\n```\n\nThe following settings are configurable:\n\n- `endpoint` (default = 0.0.0.0:9411): host:port on which the receiver is going to receive data.\n- `parse_string_tags` (default = false): if enabled, the receiver will attempt to parse string tags/binary annotations into int/bool/float.\n\n## Advanced Configuration\n\nSeveral helper files are leveraged to provide additional capabilities automatically:\n\n- [HTTP server settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/confighttp/README.md#server-configuration) including CORS\n- [TLS and mTLS settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/configtls/README.md)","properties":{"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth for this receiver","title":"auth"},"cors":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.confighttp.CORSSettings","description":"CORS configures the server for HTTP cross-origin resource sharing (CORS).","title":"cors"},"endpoint":{"description":"Endpoint configures the listening address for the server.","title":"endpoint","type":"string"},"include_metadata":{"description":"IncludeMetadata propagates the client metadata from the incoming requests to the downstream consumers\nExperimental: *NOTE* this option is subject to change or removal in the future.","title":"include_metadata","type":"boolean"},"max_request_body_size":{"description":"MaxRequestBodySize sets the maximum request body size in bytes","title":"max_request_body_size","type":"integer"},"parse_string_tags":{"description":"If enabled the zipkin receiver will attempt to parse string tags/binary annotations into int/bool/float.\nDisabled by default","title":"parse_string_tags","type":"boolean"},"response_headers":{"description":"Additional headers attached to each HTTP response sent to the client.\nHeader values are opaque since they may be sensitive.","patternProperties":{".*":{"type":"string"}},"title":"response_headers","type":"object"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSServerSetting","description":"TLSSetting struct exposes TLS client configuration.","title":"tls"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.Config":{"additionalProperties":false,"markdownDescription":"# Zookeeper Receiver\n\n\u003c!-- status autogenerated section --\u003e\n| Status        |           |\n| ------------- |-----------|\n| Stability     | [development]: metrics   |\n| Distributions | [contrib], [observiq], [sumo] |\n\n[development]: https://github.com/open-telemetry/opentelemetry-collector#development\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[observiq]: https://github.com/observIQ/observiq-otel-collector\n[sumo]: https://github.com/SumoLogic/sumologic-otel-collector\n\u003c!-- end autogenerated section --\u003e\n\nThe Zookeeper receiver collects metrics from a Zookeeper instance, using the `mntr` command. The `mntr` 4 letter word command needs\nto be enabled for the receiver to be able to collect metrics.\n\n## Configuration\n\n- `endpoint`: (default = `:2181`) Endpoint to connect to collect metrics. Takes the form `host:port`.\n- `timeout`: (default = `10s`) Timeout within which requests should be completed.\n- `initial_delay` (default = `1s`): defines how long this receiver waits before starting.\n\nExample configuration.\n\n```yaml\nreceivers:\n  zookeeper:\n    endpoint: \"localhost:2181\"\n    collection_interval: 20s\n    initial_delay: 1s\n```\n\n## Metrics\n\nDetails about the metrics produced by this receiver can be found in [metadata.yaml](./metadata.yaml) with further documentation in [documentation.md](./documentation.md)\n\n## Limitations\n\nThis receiver does not support scraping metrics from Zookeeper's [New Metric System](https://zookeeper.apache.org/doc/r3.6.3/zookeeperMonitor.html#Metrics-System).","properties":{"collection_interval":{"title":"collection_interval","type":"string"},"endpoint":{"description":"Endpoint configures the address for this network connection.\nThe address has the form \"host:port\". The host must be a literal IP address, or a host name that can be\nresolved to IP addresses. The port must be a literal port number or a service name.\nIf the host is a literal IPv6 address it must be enclosed in square brackets, as in \"[2001:db8::1]:80\" or\n\"[fe80::1%zone]:80\". The zone specifies the scope of the literal IPv6 address as defined in RFC 4007.","title":"endpoint","type":"string"},"initial_delay":{"title":"initial_delay","type":"string"},"metrics":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.MetricsConfig","title":"metrics"},"resource_attributes":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.ResourceAttributesConfig","title":"resource_attributes"},"timeout":{"description":"Timeout within which requests should be completed.","title":"timeout","type":"string"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.MetricConfig":{"additionalProperties":false,"description":"MetricConfig provides common config for a particular metric.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.MetricsConfig":{"additionalProperties":false,"description":"MetricsConfig provides config for zookeeper metrics.","properties":{"zookeeper.connection.active":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.MetricConfig","title":"zookeeper.connection.active"},"zookeeper.data_tree.ephemeral_node.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.MetricConfig","title":"zookeeper.data_tree.ephemeral_node.count"},"zookeeper.data_tree.size":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.MetricConfig","title":"zookeeper.data_tree.size"},"zookeeper.file_descriptor.limit":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.MetricConfig","title":"zookeeper.file_descriptor.limit"},"zookeeper.file_descriptor.open":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.MetricConfig","title":"zookeeper.file_descriptor.open"},"zookeeper.follower.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.MetricConfig","title":"zookeeper.follower.count"},"zookeeper.fsync.exceeded_threshold.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.MetricConfig","title":"zookeeper.fsync.exceeded_threshold.count"},"zookeeper.latency.avg":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.MetricConfig","title":"zookeeper.latency.avg"},"zookeeper.latency.max":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.MetricConfig","title":"zookeeper.latency.max"},"zookeeper.latency.min":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.MetricConfig","title":"zookeeper.latency.min"},"zookeeper.packet.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.MetricConfig","title":"zookeeper.packet.count"},"zookeeper.request.active":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.MetricConfig","title":"zookeeper.request.active"},"zookeeper.ruok":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.MetricConfig","title":"zookeeper.ruok"},"zookeeper.sync.pending":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.MetricConfig","title":"zookeeper.sync.pending"},"zookeeper.watch.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.MetricConfig","title":"zookeeper.watch.count"},"zookeeper.znode.count":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.MetricConfig","title":"zookeeper.znode.count"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.ResourceAttributeConfig":{"additionalProperties":false,"description":"ResourceAttributeConfig provides common config for a particular resource attribute.","properties":{"enabled":{"title":"enabled","type":"boolean"}},"type":"object"},"github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.ResourceAttributesConfig":{"additionalProperties":false,"description":"ResourceAttributesConfig provides config for zookeeper resource attributes.","properties":{"server.state":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.ResourceAttributeConfig","title":"server.state"},"zk.version":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.internal.metadata.ResourceAttributeConfig","title":"zk.version"}},"type":"object"},"github.com.prometheus.client_golang.prometheus.Labels":{"patternProperties":{".*":{"type":"string"}},"type":"object"},"go.opentelemetry.io.collector.config.configauth.Authentication":{"additionalProperties":false,"description":"Authentication defines the auth settings for the receiver.","markdownDescription":"# Authentication configuration\n\nThis module defines necessary interfaces to implement server and client type authenticators:\n\n- Server type authenticators perform authentication for incoming HTTP/gRPC requests and are typically used in receivers.\n- Client type authenticators perform client-side authentication for outgoing HTTP/gRPC requests and are typically used in exporters.\n\nThe currently known authenticators are:\n\n- Server Authenticators\n  - [oidc](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/extension/oidcauthextension)\n\n- Client Authenticators\n  - [oauth2](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/extension/oauth2clientauthextension)\n  - [BearerToken](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/extension/bearertokenauthextension)\n\nExamples:\n```yaml\nextensions:\n  oidc:\n    # see the blog post on securing the otelcol for information\n    # on how to setup an OIDC server and how to generate the TLS certs\n    # required for this example\n    # https://medium.com/opentelemetry/securing-your-opentelemetry-collector-1a4f9fa5bd6f\n    issuer_url: http://localhost:8080/auth/realms/opentelemetry\n    audience: account\n\n  oauth2client:\n    client_id: someclientid\n    client_secret: someclientsecret\n    token_url: https://example.com/oauth2/default/v1/token\n    scopes: [\"api.metrics\"]\n    # tls settings for the token client\n    tls:\n      insecure: true\n      ca_file: /var/lib/mycert.pem\n      cert_file: certfile\n      key_file: keyfile\n    # timeout for the token client\n    timeout: 2s\n\nreceivers:\n  otlp/with_auth:\n    protocols:\n      grpc:\n        endpoint: localhost:4318\n        tls:\n          cert_file: /tmp/certs/cert.pem\n          key_file: /tmp/certs/cert-key.pem\n        auth:\n          ## oidc is the extension name to use as the authenticator for this receiver\n          authenticator: oidc\n\n  otlphttp/withauth:\n    endpoint: http://localhost:9000\n    auth:\n      authenticator: oauth2client\n\n```\n\n## Creating an authenticator\n\nNew authenticators can be added by creating a new extension that also implements the appropriate interface (`configauth.ServerAuthenticator` or `configauth.ClientAuthenticator`).\n\nGeneric authenticators that may be used by a good number of users might be accepted as part of the contrib distribution. If you have an interest in contributing an authenticator, open an issue with your proposal. For other cases, you'll need to include your custom authenticator as part of your custom OpenTelemetry Collector, perhaps being built using the [OpenTelemetry Collector Builder](https://github.com/open-telemetry/opentelemetry-collector/tree/main/cmd/builder).","properties":{"authenticator":{"description":"AuthenticatorID specifies the name of the extension to use in order to authenticate the incoming data point.","title":"authenticator","type":"string"}},"type":"object"},"go.opentelemetry.io.collector.config.configgrpc.GRPCClientSettings":{"additionalProperties":false,"description":"GRPCClientSettings defines common settings for a gRPC client configuration.","properties":{"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth configuration for outgoing RPCs.","title":"auth"},"balancer_name":{"description":"Sets the balancer in grpclb_policy to discover the servers. Default is pick_first.\nhttps://github.com/grpc/grpc-go/blob/master/examples/features/load_balancing/README.md","title":"balancer_name","type":"string"},"compression":{"description":"The compression key for supported compression types within collector.","title":"compression","type":"string"},"endpoint":{"description":"The target to which the exporter is going to send traces or metrics,\nusing the gRPC protocol. The valid syntax is described at\nhttps://github.com/grpc/grpc/blob/master/doc/naming.md.","title":"endpoint","type":"string"},"headers":{"description":"The headers associated with gRPC requests.","patternProperties":{".*":{"type":"string"}},"title":"headers","type":"object"},"keepalive":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configgrpc.KeepaliveClientConfig","description":"The keepalive parameters for gRPC client. See grpc.WithKeepaliveParams.\n(https://godoc.org/google.golang.org/grpc#WithKeepaliveParams).","title":"keepalive"},"read_buffer_size":{"description":"ReadBufferSize for gRPC client. See grpc.WithReadBufferSize.\n(https://godoc.org/google.golang.org/grpc#WithReadBufferSize).","title":"read_buffer_size","type":"integer"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","description":"TLSSetting struct exposes TLS client configuration.","title":"tls"},"wait_for_ready":{"description":"WaitForReady parameter configures client to wait for ready state before sending data.\n(https://github.com/grpc/grpc/blob/master/doc/wait-for-ready.md)","title":"wait_for_ready","type":"boolean"},"write_buffer_size":{"description":"WriteBufferSize for gRPC gRPC. See grpc.WithWriteBufferSize.\n(https://godoc.org/google.golang.org/grpc#WithWriteBufferSize).","title":"write_buffer_size","type":"integer"}},"type":"object"},"go.opentelemetry.io.collector.config.configgrpc.GRPCServerSettings":{"additionalProperties":false,"description":"GRPCServerSettings defines common settings for a gRPC server configuration.","properties":{"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth for this receiver","title":"auth"},"endpoint":{"description":"Endpoint configures the address for this network connection.\nFor TCP and UDP networks, the address has the form \"host:port\". The host must be a literal IP address,\nor a host name that can be resolved to IP addresses. The port must be a literal port number or a service name.\nIf the host is a literal IPv6 address it must be enclosed in square brackets, as in \"[2001:db8::1]:80\" or\n\"[fe80::1%zone]:80\". The zone specifies the scope of the literal IPv6 address as defined in RFC 4007.","title":"endpoint","type":"string"},"include_metadata":{"description":"Include propagates the incoming connection's metadata to downstream consumers.\nExperimental: *NOTE* this option is subject to change or removal in the future.","title":"include_metadata","type":"boolean"},"keepalive":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configgrpc.KeepaliveServerConfig","description":"Keepalive anchor for all the settings related to keepalive.","title":"keepalive"},"max_concurrent_streams":{"description":"MaxConcurrentStreams sets the limit on the number of concurrent streams to each ServerTransport.\nIt has effect only for streaming RPCs.","title":"max_concurrent_streams","type":"integer"},"max_recv_msg_size_mib":{"description":"MaxRecvMsgSizeMiB sets the maximum size (in MiB) of messages accepted by the server.","title":"max_recv_msg_size_mib","type":"integer"},"read_buffer_size":{"description":"ReadBufferSize for gRPC server. See grpc.ReadBufferSize.\n(https://godoc.org/google.golang.org/grpc#ReadBufferSize).","title":"read_buffer_size","type":"integer"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSServerSetting","description":"Configures the protocol to use TLS.\nThe default value is nil, which will cause the protocol to not use TLS.","title":"tls"},"transport":{"description":"Transport to use. Known protocols are \"tcp\", \"tcp4\" (IPv4-only), \"tcp6\" (IPv6-only), \"udp\", \"udp4\" (IPv4-only),\n\"udp6\" (IPv6-only), \"ip\", \"ip4\" (IPv4-only), \"ip6\" (IPv6-only), \"unix\", \"unixgram\" and \"unixpacket\".","title":"transport","type":"string"},"write_buffer_size":{"description":"WriteBufferSize for gRPC server. See grpc.WriteBufferSize.\n(https://godoc.org/google.golang.org/grpc#WriteBufferSize).","title":"write_buffer_size","type":"integer"}},"type":"object"},"go.opentelemetry.io.collector.config.configgrpc.KeepaliveClientConfig":{"additionalProperties":false,"description":"KeepaliveClientConfig exposes the keepalive.ClientParameters to be used by the exporter.","markdownDescription":"# gRPC Configuration Settings\n\ngRPC exposes a [variety of settings](https://godoc.org/google.golang.org/grpc).\nSeveral of these settings are available for configuration within individual\nreceivers or exporters. In general, none of these settings should need to be\nadjusted.\n\n## Client Configuration\n\n[Exporters](https://github.com/open-telemetry/opentelemetry-collector/blob/main/exporter/README.md)\nleverage client configuration.\n\nNote that client configuration supports TLS configuration, the\nconfiguration parameters are also defined under `tls` like server\nconfiguration. For more information, see [configtls\nREADME](../configtls/README.md).\n\n- [`balancer_name`](https://github.com/grpc/grpc-go/blob/master/examples/features/load_balancing/README.md)\n- `compression` Compression type to use among `gzip`, `snappy`, `zstd`, and `none`.\n- `endpoint`: Valid value syntax available [here](https://github.com/grpc/grpc/blob/master/doc/naming.md)\n- [`tls`](../configtls/README.md)\n- `headers`: name/value pairs added to the request\n- [`keepalive`](https://godoc.org/google.golang.org/grpc/keepalive#ClientParameters)\n  - `permit_without_stream`\n  - `time`\n  - `timeout`\n- [`read_buffer_size`](https://godoc.org/google.golang.org/grpc#ReadBufferSize)\n- [`write_buffer_size`](https://godoc.org/google.golang.org/grpc#WriteBufferSize)\n\nPlease note that [`per_rpc_auth`](https://pkg.go.dev/google.golang.org/grpc#PerRPCCredentials) which allows the credentials to send for every RPC is now moved to become an [extension](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/extension/bearertokenauthextension). Note that this feature isn't about sending the headers only during the initial connection as an `authorization` header under the `headers` would do: this is sent for every RPC performed during an established connection.\n\nExample:\n\n```yaml\nexporters:\n  otlp:\n    endpoint: otelcol2:55690\n    tls:\n      ca_file: ca.pem\n      cert_file: cert.pem\n      key_file: key.pem\n    headers:\n      test1: \"value1\"\n      \"test 2\": \"value 2\"\n```\n\n### Compression Comparison\n\n[configgrpc_benchmark_test.go](./configgrpc_benchmark_test.go) contains benchmarks comparing the supported compression algorithms. It performs compression using `gzip`, `zstd`, and `snappy` compression on small, medium, and large sized log, trace, and metric payloads. Each test case outputs the uncompressed payload size, the compressed payload size, and the average nanoseconds spent on compression. \n\nThe following table summarizes the results, including some additional columns computed from the raw data. The benchmarks were performed on an AWS m5.large EC2 instance with an Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz.\n\n| Request           | Compressor | Raw Bytes | Compressed bytes | Compression ratio | Ns / op | Mb compressed / second | Mb saved / second |\n|-------------------|------------|-----------|------------------|-------------------|---------|------------------------|-------------------|\n| lg_log_request    | gzip       | 5150      | 262              | 19.66             | 49231   | 104.61                 | 99.29             |\n| lg_metric_request | gzip       | 6800      | 201              | 33.83             | 51816   | 131.23                 | 127.35            |\n| lg_trace_request  | gzip       | 9200      | 270              | 34.07             | 65174   | 141.16                 | 137.02            |\n| md_log_request    | gzip       | 363       | 268              | 1.35              | 37609   | 9.65                   | 2.53              |\n| md_metric_request | gzip       | 320       | 145              | 2.21              | 30141   | 10.62                  | 5.81              |\n| md_trace_request  | gzip       | 451       | 288              | 1.57              | 38270   | 11.78                  | 4.26              |\n| sm_log_request    | gzip       | 166       | 168              | 0.99              | 30511   | 5.44                   | -0.07             |\n| sm_metric_request | gzip       | 185       | 142              | 1.30              | 29055   | 6.37                   | 1.48              |\n| sm_trace_request  | gzip       | 233       | 205              | 1.14              | 33466   | 6.96                   | 0.84              |\n| lg_log_request    | snappy     | 5150      | 475              | 10.84             | 1915    | 2,689.30               | 2,441.25          |\n| lg_metric_request | snappy     | 6800      | 466              | 14.59             | 2266    | 3,000.88               | 2,795.23          |\n| lg_trace_request  | snappy     | 9200      | 644              | 14.29             | 3281    | 2,804.02               | 2,607.74          |\n| md_log_request    | snappy     | 363       | 300              | 1.21              | 770.0   | 471.43                 | 81.82             |\n| md_metric_request | snappy     | 320       | 162              | 1.98              | 588.6   | 543.66                 | 268.43            |\n| md_trace_request  | snappy     | 451       | 330              | 1.37              | 907.7   | 496.86                 | 133.30            |\n| sm_log_request    | snappy     | 166       | 184              | 0.90              | 551.8   | 300.83                 | -32.62            |\n| sm_metric_request | snappy     | 185       | 154              | 1.20              | 526.3   | 351.51                 | 58.90             |\n| sm_trace_request  | snappy     | 233       | 251              | 0.93              | 682.1   | 341.59                 | -26.39            |\n| lg_log_request    | zstd       | 5150      | 223              | 23.09             | 17998   | 286.14                 | 273.75            |\n| lg_metric_request | zstd       | 6800      | 144              | 47.22             | 14289   | 475.89                 | 465.81            |\n| lg_trace_request  | zstd       | 9200      | 208              | 44.23             | 17160   | 536.13                 | 524.01            |\n| md_log_request    | zstd       | 363       | 261              | 1.39              | 11216   | 32.36                  | 9.09              |\n| md_metric_request | zstd       | 320       | 145              | 2.21              | 9318    | 34.34                  | 18.78             |\n| md_trace_request  | zstd       | 451       | 301              | 1.50              | 12583   | 35.84                  | 11.92             |\n| sm_log_request    | zstd       | 166       | 165              | 1.01              | 12482   | 13.30                  | 0.08              |\n| sm_metric_request | zstd       | 185       | 139              | 1.33              | 8824    | 20.97                  | 5.21              |\n| sm_trace_request  | zstd       | 233       | 203              | 1.15              | 10134   | 22.99                  | 2.96              |\n\nCompression ratios will vary in practice as they are highly dependent on the data's information entropy. Compression rates are dependent on the speed of the CPU, and the size of payloads being compressed: smaller payloads compress at slower rates relative to larger payloads, which are able to amortize fixed computation costs over more bytes.\n\n`gzip` is the only required compression algorithm required for [OTLP servers](https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/protocol/otlp.md#protocol-details), and is a natural first choice. It is not as fast as `snappy`, but achieves better compression ratios and has reasonable performance. If your collector is CPU bound and your OTLP server supports it, you may benefit from using `snappy` compression. If your collector is CPU bound and has a very fast network link, you may benefit from disabling compression, which is the default.\n\n## Server Configuration\n\n[Receivers](https://github.com/open-telemetry/opentelemetry-collector/blob/main/receiver/README.md)\nleverage server configuration.\n\nNote that transport configuration can also be configured. For more information,\nsee [confignet README](../confignet/README.md).\n\n- [`keepalive`](https://godoc.org/google.golang.org/grpc/keepalive#ServerParameters)\n  - [`enforcement_policy`](https://godoc.org/google.golang.org/grpc/keepalive#EnforcementPolicy)\n    - `min_time`\n    - `permit_without_stream`\n  - [`server_parameters`](https://godoc.org/google.golang.org/grpc/keepalive#ServerParameters)\n    - `max_connection_age`\n    - `max_connection_age_grace`\n    - `max_connection_idle`\n    - `time`\n    - `timeout`\n- [`max_concurrent_streams`](https://godoc.org/google.golang.org/grpc#MaxConcurrentStreams)\n- [`max_recv_msg_size_mib`](https://godoc.org/google.golang.org/grpc#MaxRecvMsgSize)\n- [`read_buffer_size`](https://godoc.org/google.golang.org/grpc#ReadBufferSize)\n- [`tls`](../configtls/README.md)\n- [`write_buffer_size`](https://godoc.org/google.golang.org/grpc#WriteBufferSize)","properties":{"permit_without_stream":{"title":"permit_without_stream","type":"boolean"},"time":{"title":"time","type":"string"},"timeout":{"title":"timeout","type":"string"}},"type":"object"},"go.opentelemetry.io.collector.config.configgrpc.KeepaliveEnforcementPolicy":{"additionalProperties":false,"description":"KeepaliveEnforcementPolicy allow configuration of the keepalive.EnforcementPolicy.","properties":{"min_time":{"title":"min_time","type":"string"},"permit_without_stream":{"title":"permit_without_stream","type":"boolean"}},"type":"object"},"go.opentelemetry.io.collector.config.configgrpc.KeepaliveServerConfig":{"additionalProperties":false,"description":"KeepaliveServerConfig is the configuration for keepalive.","properties":{"enforcement_policy":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configgrpc.KeepaliveEnforcementPolicy","title":"enforcement_policy"},"server_parameters":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configgrpc.KeepaliveServerParameters","title":"server_parameters"}},"type":"object"},"go.opentelemetry.io.collector.config.configgrpc.KeepaliveServerParameters":{"additionalProperties":false,"description":"KeepaliveServerParameters allow configuration of the keepalive.ServerParameters.","properties":{"max_connection_age":{"title":"max_connection_age","type":"string"},"max_connection_age_grace":{"title":"max_connection_age_grace","type":"string"},"max_connection_idle":{"title":"max_connection_idle","type":"string"},"time":{"title":"time","type":"string"},"timeout":{"title":"timeout","type":"string"}},"type":"object"},"go.opentelemetry.io.collector.config.confighttp.CORSSettings":{"additionalProperties":false,"description":"CORSSettings configures a receiver for HTTP cross-origin resource sharing (CORS).","properties":{"allowed_headers":{"description":"AllowedHeaders sets what headers will be allowed in CORS requests.\nThe Accept, Accept-Language, Content-Type, and Content-Language\nheaders are implicitly allowed. If no headers are listed,\nX-Requested-With will also be accepted by default. Include \"*\" to\nallow any request header.","items":{"type":"string"},"title":"allowed_headers","type":"array"},"allowed_origins":{"description":"AllowedOrigins sets the allowed values of the Origin header for\nHTTP/JSON requests to an OTLP receiver. An origin may contain a\nwildcard (*) to replace 0 or more characters (e.g.,\n\"http://*.domain.com\", or \"*\" to allow any origin).","items":{"type":"string"},"title":"allowed_origins","type":"array"},"max_age":{"description":"MaxAge sets the value of the Access-Control-Max-Age response header.\nSet it to the number of seconds that browsers should cache a CORS\npreflight response for.","title":"max_age","type":"integer"}},"type":"object"},"go.opentelemetry.io.collector.config.confighttp.HTTPClientSettings":{"additionalProperties":false,"description":"HTTPClientSettings defines settings for creating an HTTP client.","markdownDescription":"# HTTP Configuration Settings\n\nHTTP exposes a [variety of settings](https://golang.org/pkg/net/http/).\nSeveral of these settings are available for configuration within individual\nreceivers or exporters.\n\n## Client Configuration\n\n[Exporters](https://github.com/open-telemetry/opentelemetry-collector/blob/main/exporter/README.md)\nleverage client configuration.\n\nNote that client configuration supports TLS configuration, the\nconfiguration parameters are also defined under `tls` like server\nconfiguration. For more information, see [configtls\nREADME](../configtls/README.md).\n\n- `endpoint`: address:port\n- [`tls`](../configtls/README.md)\n- `headers`: name/value pairs added to the HTTP request headers\n- [`read_buffer_size`](https://golang.org/pkg/net/http/#Transport)\n- [`timeout`](https://golang.org/pkg/net/http/#Client)\n- [`write_buffer_size`](https://golang.org/pkg/net/http/#Transport)\n- `compression`: Compression type to use among `gzip`, `zstd`, `snappy`, `zlib`, and `deflate`.\n  - look at the documentation for the server-side of the communication.\n  - `none` will be treated as uncompressed, and any other inputs will cause an error.\n- [`max_idle_conns`](https://golang.org/pkg/net/http/#Transport)\n- [`max_idle_conns_per_host`](https://golang.org/pkg/net/http/#Transport)\n- [`max_conns_per_host`](https://golang.org/pkg/net/http/#Transport)\n- [`idle_conn_timeout`](https://golang.org/pkg/net/http/#Transport)\n\nExample:\n\n```yaml\nexporter:\n  otlp:\n    endpoint: otelcol2:55690\n    tls:\n      ca_file: ca.pem\n      cert_file: cert.pem\n      key_file: key.pem\n    headers:\n      test1: \"value1\"\n      \"test 2\": \"value 2\"\n    compression: zstd\n```\n\n## Server Configuration\n\n[Receivers](https://github.com/open-telemetry/opentelemetry-collector/blob/main/receiver/README.md)\nleverage server configuration.\n\n- [`cors`](https://github.com/rs/cors#parameters): Configure [CORS][cors],\nallowing the receiver to accept traces from web browsers, even if the receiver\nis hosted at a different [origin][origin]. If left blank or set to `null`, CORS\nwill not be enabled.\n  - `allowed_origins`: A list of [origins][origin] allowed to send requests to\n  the receiver. An origin may contain a wildcard (`*`) to replace 0 or more\n  characters (e.g., `https://*.example.com`). To allow any origin, set to\n  `[\"*\"]`. If no origins are listed, CORS will not be enabled.\n  - `allowed_headers`: Allow CORS requests to include headers outside the\n  [default safelist][cors-headers]. By default, safelist headers and\n  `X-Requested-With` will be allowed. To allow any request header, set to\n  `[\"*\"]`.\n  - `max_age`: Sets the value of the [`Access-Control-Max-Age`][cors-cache]\n  header, allowing clients to cache the response to CORS preflight requests. If\n  not set, browsers use a default of 5 seconds.\n- `endpoint`: Valid value syntax available [here](https://github.com/grpc/grpc/blob/master/doc/naming.md)\n- [`tls`](../configtls/README.md)\n\nYou can enable [`attribute processor`][attribute-processor] to append any http header to span's attribute using custom key. You also need to enable the \"include_metadata\"\n\nExample:\n\n```yaml\nreceivers:\n  otlp:\n    protocols:\n      http:\n        include_metadata: true\n        cors:\n          allowed_origins:\n            - https://foo.bar.com\n            - https://*.test.com\n          allowed_headers:\n            - Example-Header\n          max_age: 7200\n        endpoint: 0.0.0.0:55690\nprocessors:\n  attributes:\n    actions:\n      - key: http.client_ip\n        from_context: X-Forwarded-For\n        action: upsert\n```\n\n[cors]: https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS\n[cors-headers]: https://developer.mozilla.org/en-US/docs/Glossary/CORS-safelisted_request_header\n[cors-cache]: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Access-Control-Max-Age\n[origin]: https://developer.mozilla.org/en-US/docs/Glossary/Origin\n[attribute-processor]: https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/main/processor/attributesprocessor/README.md","properties":{"CustomRoundTripper":{"description":"Custom Round Tripper to allow for individual components to intercept HTTP requests","title":"CustomRoundTripper"},"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth configuration for outgoing HTTP calls.","title":"auth"},"compression":{"description":"The compression key for supported compression types within collector.","title":"compression","type":"string"},"endpoint":{"description":"The target URL to send data to (e.g.: http://some.url:9411/v1/traces).","title":"endpoint","type":"string"},"headers":{"description":"Additional headers attached to each HTTP request sent by the client.\nExisting header values are overwritten if collision happens.\nHeader values are opaque since they may be sensitive.","patternProperties":{".*":{"type":"string"}},"title":"headers","type":"object"},"idle_conn_timeout":{"description":"IdleConnTimeout is the maximum amount of time a connection will remain open before closing itself.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"idle_conn_timeout","type":"string"},"max_conns_per_host":{"description":"MaxConnsPerHost limits the total number of connections per host, including connections in the dialing,\nactive, and idle states.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_conns_per_host","type":"integer"},"max_idle_conns":{"description":"MaxIdleConns is used to set a limit to the maximum idle HTTP connections the client can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns","type":"integer"},"max_idle_conns_per_host":{"description":"MaxIdleConnsPerHost is used to set a limit to the maximum idle HTTP connections the host can keep open.\nThere's an already set value, and we want to override it only if an explicit value provided","title":"max_idle_conns_per_host","type":"integer"},"read_buffer_size":{"description":"ReadBufferSize for HTTP client. See http.Transport.ReadBufferSize.","title":"read_buffer_size","type":"integer"},"timeout":{"description":"Timeout parameter configures `http.Client.Timeout`.","title":"timeout","type":"string"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","description":"TLSSetting struct exposes TLS client configuration.","title":"tls"},"write_buffer_size":{"description":"WriteBufferSize for HTTP client. See http.Transport.WriteBufferSize.","title":"write_buffer_size","type":"integer"}},"type":"object"},"go.opentelemetry.io.collector.config.confighttp.HTTPServerSettings":{"additionalProperties":false,"description":"HTTPServerSettings defines settings for creating an HTTP server.","properties":{"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth for this receiver","title":"auth"},"cors":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.confighttp.CORSSettings","description":"CORS configures the server for HTTP cross-origin resource sharing (CORS).","title":"cors"},"endpoint":{"description":"Endpoint configures the listening address for the server.","title":"endpoint","type":"string"},"include_metadata":{"description":"IncludeMetadata propagates the client metadata from the incoming requests to the downstream consumers\nExperimental: *NOTE* this option is subject to change or removal in the future.","title":"include_metadata","type":"boolean"},"max_request_body_size":{"description":"MaxRequestBodySize sets the maximum request body size in bytes","title":"max_request_body_size","type":"integer"},"response_headers":{"description":"Additional headers attached to each HTTP response sent to the client.\nHeader values are opaque since they may be sensitive.","patternProperties":{".*":{"type":"string"}},"title":"response_headers","type":"object"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSServerSetting","description":"TLSSetting struct exposes TLS client configuration.","title":"tls"}},"type":"object"},"go.opentelemetry.io.collector.config.confignet.NetAddr":{"additionalProperties":false,"description":"NetAddr represents a network endpoint address.","markdownDescription":"# Network Configuration Settings\n\n[Receivers](https://github.com/open-telemetry/opentelemetry-collector/blob/main/receiver/README.md)\nleverage network configuration to set connection and transport information.\n\n- `endpoint`: Configures the address for this network connection. For TCP and\n  UDP networks, the address has the form \"host:port\". The host must be a\n  literal IP address, or a host name that can be resolved to IP addresses. The\n  port must be a literal port number or a service name. If the host is a\n  literal IPv6 address it must be enclosed in square brackets, as in\n  \"[2001:db8::1]:80\" or \"[fe80::1%zone]:80\". The zone specifies the scope of\n  the literal IPv6 address as defined in RFC 4007.\n- `transport`: Known protocols are \"tcp\", \"tcp4\" (IPv4-only), \"tcp6\"\n  (IPv6-only), \"udp\", \"udp4\" (IPv4-only), \"udp6\" (IPv6-only), \"ip\", \"ip4\"\n  (IPv4-only), \"ip6\" (IPv6-only), \"unix\", \"unixgram\" and \"unixpacket\".\n\nNote that for TCP receivers only the `endpoint` configuration setting is\nrequired.","properties":{"endpoint":{"description":"Endpoint configures the address for this network connection.\nFor TCP and UDP networks, the address has the form \"host:port\". The host must be a literal IP address,\nor a host name that can be resolved to IP addresses. The port must be a literal port number or a service name.\nIf the host is a literal IPv6 address it must be enclosed in square brackets, as in \"[2001:db8::1]:80\" or\n\"[fe80::1%zone]:80\". The zone specifies the scope of the literal IPv6 address as defined in RFC 4007.","title":"endpoint","type":"string"},"transport":{"description":"Transport to use. Known protocols are \"tcp\", \"tcp4\" (IPv4-only), \"tcp6\" (IPv6-only), \"udp\", \"udp4\" (IPv4-only),\n\"udp6\" (IPv6-only), \"ip\", \"ip4\" (IPv4-only), \"ip6\" (IPv6-only), \"unix\", \"unixgram\" and \"unixpacket\".","title":"transport","type":"string"}},"type":"object"},"go.opentelemetry.io.collector.config.configtls.TLSClientSetting":{"additionalProperties":false,"description":"TLSClientSetting contains TLS configurations that are specific to client connections in addition to the common configurations.","properties":{"ca_file":{"description":"Path to the CA cert. For a client this verifies the server certificate.\nFor a server this verifies client certificates. If empty uses system root CA.\n(optional)","title":"ca_file","type":"string"},"ca_pem":{"description":"In memory PEM encoded cert. (optional)","title":"ca_pem","type":"string"},"cert_file":{"description":"Path to the TLS cert to use for TLS required connections. (optional)","title":"cert_file","type":"string"},"cert_pem":{"description":"In memory PEM encoded TLS cert to use for TLS required connections. (optional)","title":"cert_pem","type":"string"},"insecure":{"description":"In gRPC when set to true, this is used to disable the client transport security.\nSee https://godoc.org/google.golang.org/grpc#WithInsecure.\nIn HTTP, this disables verifying the server's certificate chain and host name\n(InsecureSkipVerify in the tls Config). Please refer to\nhttps://godoc.org/crypto/tls#Config for more information.\n(optional, default false)","title":"insecure","type":"boolean"},"insecure_skip_verify":{"description":"InsecureSkipVerify will enable TLS but not verify the certificate.","title":"insecure_skip_verify","type":"boolean"},"key_file":{"description":"Path to the TLS key to use for TLS required connections. (optional)","title":"key_file","type":"string"},"key_pem":{"description":"In memory PEM encoded TLS key to use for TLS required connections. (optional)","title":"key_pem","type":"string"},"max_version":{"description":"MaxVersion sets the maximum TLS version that is acceptable.\nIf not set, refer to crypto/tls for defaults. (optional)","title":"max_version","type":"string"},"min_version":{"description":"MinVersion sets the minimum TLS version that is acceptable.\nIf not set, TLS 1.2 will be used. (optional)","title":"min_version","type":"string"},"reload_interval":{"description":"ReloadInterval specifies the duration after which the certificate will be reloaded\nIf not set, it will never be reloaded (optional)","title":"reload_interval","type":"string"},"server_name_override":{"description":"ServerName requested by client for virtual hosting.\nThis sets the ServerName in the TLSConfig. Please refer to\nhttps://godoc.org/crypto/tls#Config for more information. (optional)","title":"server_name_override","type":"string"}},"type":"object"},"go.opentelemetry.io.collector.config.configtls.TLSServerSetting":{"additionalProperties":false,"description":"TLSServerSetting contains TLS configurations that are specific to server connections in addition to the common configurations.","properties":{"ca_file":{"description":"Path to the CA cert. For a client this verifies the server certificate.\nFor a server this verifies client certificates. If empty uses system root CA.\n(optional)","title":"ca_file","type":"string"},"ca_pem":{"description":"In memory PEM encoded cert. (optional)","title":"ca_pem","type":"string"},"cert_file":{"description":"Path to the TLS cert to use for TLS required connections. (optional)","title":"cert_file","type":"string"},"cert_pem":{"description":"In memory PEM encoded TLS cert to use for TLS required connections. (optional)","title":"cert_pem","type":"string"},"client_ca_file":{"description":"Path to the TLS cert to use by the server to verify a client certificate. (optional)\nThis sets the ClientCAs and ClientAuth to RequireAndVerifyClientCert in the TLSConfig. Please refer to\nhttps://godoc.org/crypto/tls#Config for more information. (optional)","title":"client_ca_file","type":"string"},"client_ca_file_reload":{"description":"Reload the ClientCAs file when it is modified\n(optional, default false)","title":"client_ca_file_reload","type":"boolean"},"key_file":{"description":"Path to the TLS key to use for TLS required connections. (optional)","title":"key_file","type":"string"},"key_pem":{"description":"In memory PEM encoded TLS key to use for TLS required connections. (optional)","title":"key_pem","type":"string"},"max_version":{"description":"MaxVersion sets the maximum TLS version that is acceptable.\nIf not set, refer to crypto/tls for defaults. (optional)","title":"max_version","type":"string"},"min_version":{"description":"MinVersion sets the minimum TLS version that is acceptable.\nIf not set, TLS 1.2 will be used. (optional)","title":"min_version","type":"string"},"reload_interval":{"description":"ReloadInterval specifies the duration after which the certificate will be reloaded\nIf not set, it will never be reloaded (optional)","title":"reload_interval","type":"string"}},"type":"object"},"go.opentelemetry.io.collector.exporter.exporterhelper.QueueSettings":{"additionalProperties":false,"description":"QueueSettings defines configuration for queueing batches before sending to the consumerSender.","markdownDescription":"# Exporter Helper\n\nThis is a helper exporter that other exporters can depend on. Today, it primarily offers queued retry capabilities.\n\n\u003e :warning: This exporter should not be added to a service pipeline.\n\n## Configuration\n\nThe following configuration options can be modified:\n\n- `retry_on_failure`\n  - `enabled` (default = true)\n  - `initial_interval` (default = 5s): Time to wait after the first failure before retrying; ignored if `enabled` is `false`\n  - `max_interval` (default = 30s): Is the upper bound on backoff; ignored if `enabled` is `false`\n  - `max_elapsed_time` (default = 300s): Is the maximum amount of time spent trying to send a batch; ignored if `enabled` is `false`\n- `sending_queue`\n  - `enabled` (default = true)\n  - `num_consumers` (default = 10): Number of consumers that dequeue batches; ignored if `enabled` is `false`\n  - `queue_size` (default = 1000): Maximum number of batches kept in memory before dropping; ignored if `enabled` is `false`\n  User should calculate this as `num_seconds * requests_per_second / requests_per_batch` where:\n    - `num_seconds` is the number of seconds to buffer in case of a backend outage\n    - `requests_per_second` is the average number of requests per seconds\n    - `requests_per_batch` is the average number of requests per batch (if \n      [the batch processor](https://github.com/open-telemetry/opentelemetry-collector/tree/main/processor/batchprocessor)\n      is used, the metric `batch_send_size` can be used for estimation)\n- `timeout` (default = 5s): Time to wait per individual attempt to send data to a backend\n\nThe `initial_interval`, `max_interval`, `max_elapsed_time`, and `timeout` options accept \n[duration strings](https://pkg.go.dev/time#ParseDuration),\nvalid time units are \"ns\", \"us\" (or \"Âµs\"), \"ms\", \"s\", \"m\", \"h\".\n\n### Persistent Queue\n\n**Status: [alpha]**\n\n\u003e :warning: The capability is under development. To use it, a storage extension needs to be set up.\n\nTo use the persistent queue, the following setting needs to be set:\n\n- `sending_queue`\n  - `storage` (default = none): When set, enables persistence and uses the component specified as a storage extension for the persistent queue\n\nThe maximum number of batches stored to disk can be controlled using `sending_queue.queue_size` parameter (which,\nsimilarly as for in-memory buffering, defaults to 1000 batches).\n\nWhen persistent queue is enabled, the batches are being buffered using the provided storage extension - [filestorage] is a popular and safe choice. If the collector instance is killed while having some items in the persistent queue, on restart the items will be be picked and the exporting is continued.\n\n```\n                                                              â”Œâ”€Consumer #1â”€â”\n                                                              â”‚    â”Œâ”€â”€â”€â”    â”‚\n                              â”€â”€â”€â”€â”€â”€Deletedâ”€â”€â”€â”€â”€â”€        â”Œâ”€â”€â”€â–ºâ”‚    â”‚ 1 â”‚    â”œâ”€â”€â”€â–º Success\n        Waiting in channel    x           x     x        â”‚    â”‚    â””â”€â”€â”€â”˜    â”‚\n        for consumer â”€â”€â”€â”     x           x     x        â”‚    â”‚             â”‚\n                        â”‚     x           x     x        â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                        â–¼     x           x     x        â”‚\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€xâ”€â”€â”€â”€â”€xâ”€â”€â”€â”    â”‚    â”Œâ”€Consumer #2â”€â”\nâ”‚                             x           x     x   â”‚    â”‚    â”‚    â”Œâ”€â”€â”€â”    â”‚\nâ”‚     â”Œâ”€â”€â”€â”     â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€xâ”€â” â”Œâ”€â”€â”€â” â”Œâ”€xâ”€â” â”Œâ”€xâ”€â” â”‚    â”‚    â”‚    â”‚ 2 â”‚    â”œâ”€â”€â”€â–º Permanent -\u003e X\nâ”‚ n+1 â”‚ n â”‚ ... â”‚ 6 â”‚ â”‚ 5 â”‚ â”‚ 4 â”‚ â”‚ 3 â”‚ â”‚ 2 â”‚ â”‚ 1 â”‚ â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â–ºâ”‚    â””â”€â”€â”€â”˜    â”‚      failure\nâ”‚     â””â”€â”€â”€â”˜     â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â””â”€â”€â”€â”˜ â”‚    â”‚    â”‚             â”‚\nâ”‚                                                   â”‚    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\n   â–²              â–²     â–²           â–²                    â”‚    â”Œâ”€Consumer #3â”€â”\n   â”‚              â”‚     â”‚           â”‚                    â”‚    â”‚    â”Œâ”€â”€â”€â”    â”‚\n   â”‚              â”‚     â”‚           â”‚                    â”‚    â”‚    â”‚ 3 â”‚    â”œâ”€â”€â”€â–º (in progress)\n write          read    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                    â”œâ”€â”€â”€â–ºâ”‚    â””â”€â”€â”€â”˜    â”‚\n index          index         â”‚                          â”‚    â”‚             â”‚\n   â–²                          â”‚                          â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n   â”‚                          â”‚                          â”‚\n   â”‚                      currently                      â”‚    â”Œâ”€Consumer #4â”€â”\n   â”‚                      dispatched                     â”‚    â”‚    â”Œâ”€â”€â”€â”    â”‚     Temporary\n   â”‚                                                     â””â”€â”€â”€â–ºâ”‚    â”‚ 4 â”‚    â”œâ”€â”€â”€â–º  failure\n   â”‚                                                          â”‚    â””â”€â”€â”€â”˜    â”‚         â”‚\n   â”‚                                                          â”‚             â”‚         â”‚\n   â”‚                                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚\n   â”‚                                                                 â–²                â”‚\n   â”‚                                                                 â””â”€â”€ Retry â”€â”€â”€â”€â”€â”€â”€â”¤\n   â”‚                                                                                  â”‚\n   â”‚                                                                                  â”‚\n   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Requeuing  â—„â”€â”€â”€â”€â”€â”€ Retry limit exceeded â”€â”€â”€â”˜\n```\n\nExample:\n\n```\nreceivers:\n  otlp:\n    protocols:\n      grpc:\nexporters:\n  otlp:\n    endpoint: \u003cENDPOINT\u003e\n    sending_queue:\n      storage: file_storage/otc\nextensions:\n  file_storage/otc:\n    directory: /var/lib/storage/otc\n    timeout: 10s\nservice:\n  extensions: [file_storage]\n  pipelines:\n    metrics:\n      receivers: [otlp]\n      exporters: [otlp]\n    logs:\n      receivers: [otlp]\n      exporters: [otlp]\n    traces:\n      receivers: [otlp]\n      exporters: [otlp]\n\n```\n\n[filestorage]: https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/extension/storage/filestorage\n[alpha]: https://github.com/open-telemetry/opentelemetry-collector#alpha","properties":{"enabled":{"description":"Enabled indicates whether to not enqueue batches before sending to the consumerSender.","title":"enabled","type":"boolean"},"num_consumers":{"description":"NumConsumers is the number of consumers from the queue.","title":"num_consumers","type":"integer"},"queue_size":{"description":"QueueSize is the maximum number of batches allowed in queue at a given time.","title":"queue_size","type":"integer"},"storage":{"description":"StorageID if not empty, enables the persistent storage and uses the component specified\nas a storage extension for the persistent queue","title":"storage","type":"string"}},"type":"object"},"go.opentelemetry.io.collector.exporter.exporterhelper.RetrySettings":{"additionalProperties":false,"description":"RetrySettings defines configuration for retrying batches in case of export failure.","properties":{"enabled":{"description":"Enabled indicates whether to not retry sending batches in case of export failure.","title":"enabled","type":"boolean"},"initial_interval":{"description":"InitialInterval the time to wait after the first failure before retrying.","title":"initial_interval","type":"string"},"max_elapsed_time":{"description":"MaxElapsedTime is the maximum amount of time (including retries) spent trying to send a request/batch.\nOnce this value is reached, the data is discarded.","title":"max_elapsed_time","type":"string"},"max_interval":{"description":"MaxInterval is the upper bound on backoff interval. Once this value is reached the delay between\nconsecutive retries will always be `MaxInterval`.","title":"max_interval","type":"string"},"multiplier":{"description":"Multiplier is the value multiplied by the backoff interval bounds","title":"multiplier","type":"number"},"randomization_factor":{"description":"RandomizationFactor is a random factor used to calculate next backoffs\nRandomized interval = RetryInterval * (1 Â± RandomizationFactor)","title":"randomization_factor","type":"number"}},"type":"object"},"go.opentelemetry.io.collector.exporter.otlpexporter.Config":{"additionalProperties":false,"description":"Config defines configuration for OTLP exporter.","markdownDescription":"# OTLP gRPC Exporter\n\n| Status                   |                       |\n| ------------------------ | --------------------- |\n| Stability                | traces [stable]       |\n|                          | metrics [stable]      |\n|                          | logs [beta]           |\n| Supported pipeline types | traces, metrics, logs |\n| Distributions            | [core], [contrib]     |\n\nExport data via gRPC using [OTLP](\nhttps://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/protocol/otlp.md)\nformat. By default, this exporter requires TLS and offers queued retry capabilities.\n\n## Getting Started\n\nThe following settings are required:\n\n- `endpoint` (no default): host:port to which the exporter is going to send OTLP trace data,\nusing the gRPC protocol. The valid syntax is described\n[here](https://github.com/grpc/grpc/blob/master/doc/naming.md).\nIf a scheme of `https` is used then client transport security is enabled and overrides the `insecure` setting.\n- `tls`: see [TLS Configuration Settings](../../config/configtls/README.md) for the full set of available options.\n\nExample:\n\n```yaml\nexporters:\n  otlp:\n    endpoint: otelcol2:4317\n    tls:\n      cert_file: file.cert\n      key_file: file.key\n  otlp/2:\n    endpoint: otelcol2:4317\n    tls:\n      insecure: true\n```\n\nBy default, `gzip` compression is enabled. See [compression comparison](../../config/configgrpc/README.md#compression-comparison) for details benchmark information. To disable, configure as follows:\n\n```yaml\nexporters:\n  otlp:\n    ...\n    compression: none\n```\n\n## Advanced Configuration\n\nSeveral helper files are leveraged to provide additional capabilities automatically:\n\n- [gRPC settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/configgrpc/README.md)\n- [TLS and mTLS settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/config/configtls/README.md)\n- [Queuing, retry and timeout settings](https://github.com/open-telemetry/opentelemetry-collector/blob/main/exporter/exporterhelper/README.md)\n\n[beta]: https://github.com/open-telemetry/opentelemetry-collector#beta\n[contrib]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib\n[core]: https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol\n[stable]: https://github.com/open-telemetry/opentelemetry-collector#stable","properties":{"auth":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configauth.Authentication","description":"Auth configuration for outgoing RPCs.","title":"auth"},"balancer_name":{"description":"Sets the balancer in grpclb_policy to discover the servers. Default is pick_first.\nhttps://github.com/grpc/grpc-go/blob/master/examples/features/load_balancing/README.md","title":"balancer_name","type":"string"},"compression":{"description":"The compression key for supported compression types within collector.","title":"compression","type":"string"},"endpoint":{"description":"The target to which the exporter is going to send traces or metrics,\nusing the gRPC protocol. The valid syntax is described at\nhttps://github.com/grpc/grpc/blob/master/doc/naming.md.","title":"endpoint","type":"string"},"headers":{"description":"The headers associated with gRPC requests.","patternProperties":{".*":{"type":"string"}},"title":"headers","type":"object"},"keepalive":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configgrpc.KeepaliveClientConfig","description":"The keepalive parameters for gRPC client. See grpc.WithKeepaliveParams.\n(https://godoc.org/google.golang.org/grpc#WithKeepaliveParams).","title":"keepalive"},"read_buffer_size":{"description":"ReadBufferSize for gRPC client. See grpc.WithReadBufferSize.\n(https://godoc.org/google.golang.org/grpc#WithReadBufferSize).","title":"read_buffer_size","type":"integer"},"retry_on_failure":{"$ref":"#/$defs/go.opentelemetry.io.collector.exporter.exporterhelper.RetrySettings","title":"retry_on_failure"},"sending_queue":{"$ref":"#/$defs/go.opentelemetry.io.collector.exporter.exporterhelper.QueueSettings","title":"sending_queue"},"timeout":{"description":"Timeout is the timeout for every attempt to send data to the backend.","title":"timeout","type":"string"},"tls":{"$ref":"#/$defs/go.opentelemetry.io.collector.config.configtls.TLSClientSetting","description":"TLSSetting struct exposes TLS client configuration.","title":"tls"},"wait_for_ready":{"description":"WaitForReady parameter configures client to wait for ready state before sending data.\n(https://github.com/grpc/grpc/blob/master/doc/wait-for-ready.md)","title":"wait_for_ready","type":"boolean"},"write_buffer_size":{"description":"WriteBufferSize for gRPC gRPC. See grpc.WithWriteBufferSize.\n(https://godoc.org/google.golang.org/grpc#WithWriteBufferSize).","title":"write_buffer_size","type":"integer"}},"type":"object"},"go.opentelemetry.io.collector.service.Config":{"additionalProperties":false,"properties":{"extensions":{"$ref":"#/$defs/go.opentelemetry.io.collector.service.extensions.Config","title":"extensions"},"pipelines":{"$ref":"#/$defs/go.opentelemetry.io.collector.service.pipelines.Config","title":"pipelines"},"telemetry":{"$ref":"#/$defs/go.opentelemetry.io.collector.service.telemetry.Config","title":"telemetry"}},"type":"object"},"go.opentelemetry.io.collector.service.extensions.Config":{"items":{"type":"string"},"type":"array"},"go.opentelemetry.io.collector.service.pipelines.Config":{"patternProperties":{".*":{"$ref":"#/$defs/go.opentelemetry.io.collector.service.pipelines.PipelineConfig"}},"type":"object"},"go.opentelemetry.io.collector.service.pipelines.PipelineConfig":{"additionalProperties":false,"properties":{"exporters":{"items":{"type":"string"},"title":"exporters","type":"array"},"processors":{"items":{"type":"string"},"title":"processors","type":"array"},"receivers":{"items":{"type":"string"},"title":"receivers","type":"array"}},"type":"object"},"go.opentelemetry.io.collector.service.telemetry.Config":{"additionalProperties":false,"properties":{"logs":{"$ref":"#/$defs/go.opentelemetry.io.collector.service.telemetry.LogsConfig","title":"logs"},"metrics":{"$ref":"#/$defs/go.opentelemetry.io.collector.service.telemetry.MetricsConfig","title":"metrics"},"resource":{"patternProperties":{".*":{"type":"string"}},"title":"resource","type":"object"},"traces":{"$ref":"#/$defs/go.opentelemetry.io.collector.service.telemetry.TracesConfig","title":"traces"}},"type":"object"},"go.opentelemetry.io.collector.service.telemetry.LogsConfig":{"additionalProperties":false,"properties":{"development":{"title":"development","type":"boolean"},"disable_caller":{"title":"disable_caller","type":"boolean"},"disable_stacktrace":{"title":"disable_stacktrace","type":"boolean"},"encoding":{"title":"encoding","type":"string"},"error_output_paths":{"items":{"type":"string"},"title":"error_output_paths","type":"array"},"initial_fields":{"patternProperties":{".*":true},"title":"initial_fields","type":"object"},"level":{"title":"level","type":"integer"},"output_paths":{"items":{"type":"string"},"title":"output_paths","type":"array"},"sampling":{"$ref":"#/$defs/go.opentelemetry.io.collector.service.telemetry.LogsSamplingConfig","title":"sampling"}},"type":"object"},"go.opentelemetry.io.collector.service.telemetry.LogsSamplingConfig":{"additionalProperties":false,"properties":{"initial":{"title":"initial","type":"integer"},"thereafter":{"title":"thereafter","type":"integer"}},"type":"object"},"go.opentelemetry.io.collector.service.telemetry.MetricReader":{"additionalProperties":false,"properties":{"args":{"title":"args"},"type":{"title":"type","type":"string"}},"type":"object"},"go.opentelemetry.io.collector.service.telemetry.MetricsConfig":{"additionalProperties":false,"properties":{"address":{"title":"address","type":"string"},"level":{"title":"level","type":"integer"},"metric_readers":{"items":{"$ref":"#/$defs/go.opentelemetry.io.collector.service.telemetry.MetricReader"},"title":"metric_readers","type":"array"}},"type":"object"},"go.opentelemetry.io.collector.service.telemetry.TracesConfig":{"additionalProperties":false,"properties":{"propagators":{"items":{"type":"string"},"title":"propagators","type":"array"}},"type":"object"},"net.url.Values":{"patternProperties":{".*":{"items":{"type":"string"},"type":"array"}},"type":"object"}},"$schema":"https://json-schema.org/draft/2020-12/schema","properties":{"exporters":{"minProperties":1,"patternProperties":{"^carbon(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.carbonexporter.Config"},"^file(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.fileexporter.Config"},"^jaeger(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.jaegerexporter.Config"},"^jaegerthrift(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.jaegerthrifthttpexporter.Config"},"^kafka(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.kafkaexporter.Config"},"^loadbalancing(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.loadbalancingexporter.Config"},"^opencensus(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.opencensusexporter.Config"},"^parquet(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.parquetexporter.Config"},"^prometheus(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.prometheusexporter.Config"},"^prometheusremotewrite(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.prometheusremotewriteexporter.Config"},"^pulsar(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.pulsarexporter.Config"},"^zipkin(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.exporter.zipkinexporter.Config"}},"type":"object"},"extensions":{"minProperties":1,"patternProperties":{"^basicauth(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.extension.basicauthextension.Config"},"^bearertokenauth(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.extension.bearertokenauthextension.Config"},"^dockerobserver(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.extension.observer.dockerobserver.Config"},"^ecsobserver(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.extension.observer.ecsobserver.Config"},"^ecstaskobserver(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.extension.observer.ecstaskobserver.Config"},"^healthcheck(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.extension.healthcheckextension.Config"},"^hostobserver(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.extension.observer.hostobserver.Config"},"^httpforwarder(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.extension.httpforwarder.Config"},"^jaegerremotesampling(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.extension.jaegerremotesampling.Config"},"^k8sobserver(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.extension.observer.k8sobserver.Config"},"^oauth2clientauth(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.extension.oauth2clientauthextension.Config"},"^oidcauth(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.extension.oidcauthextension.Config"},"^pprof(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.extension.pprofextension.Config"}},"type":"object"},"processors":{"minProperties":1,"patternProperties":{"^attributes(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.attributesprocessor.Config"},"^cumulativetodelta(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.cumulativetodeltaprocessor.Config"},"^deltatorate(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.deltatorateprocessor.Config"},"^filter(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.filterprocessor.Config"},"^groupbyattrs(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.groupbyattrsprocessor.Config"},"^groupbytrace(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.groupbytraceprocessor.Config"},"^k8sattributes(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.k8sattributesprocessor.Config"},"^logstransform(\\/.+)?$":true,"^metricsgeneration(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.metricsgenerationprocessor.Config"},"^metricstransform(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.metricstransformprocessor.Config"},"^probabilisticsampler(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.probabilisticsamplerprocessor.Config"},"^redaction(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.redactionprocessor.Config"},"^resource(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourceprocessor.Config"},"^resourcedetection(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.resourcedetectionprocessor.Config"},"^routing(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.routingprocessor.Config"},"^schema(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.schemaprocessor.Config"},"^servicegraph(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.servicegraphprocessor.Config"},"^span(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.spanprocessor.Config"},"^spanmetrics(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.spanmetricsprocessor.Config"},"^tailsampling(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.tailsamplingprocessor.Config"},"^transform(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.processor.transformprocessor.Config"}},"type":"object"},"receivers":{"minProperties":1,"patternProperties":{"^apache(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.apachereceiver.Config"},"^awscloudwatch(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.awscloudwatchreceiver.Config"},"^awscontainerinsight(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.awscontainerinsightreceiver.Config"},"^awsecscontainermetrics(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.awsecscontainermetricsreceiver.Config"},"^awsxray(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.awsxrayreceiver.Config"},"^carbon(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.carbonreceiver.Config"},"^collectd(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.collectdreceiver.Config"},"^couchdb(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.couchdbreceiver.Config"},"^dockerstats(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dockerstatsreceiver.Config"},"^dotnetdiagnostics(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.dotnetdiagnosticsreceiver.Config"},"^elasticsearch(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.elasticsearchreceiver.Config"},"^filelog(\\/.+)?$":true,"^fluentforward(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.fluentforwardreceiver.Config"},"^hostmetrics(\\/.+)?$":true,"^httpcheck(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.httpcheckreceiver.Config"},"^jaeger(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.jaegerreceiver.Config"},"^jmx(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.jmxreceiver.Config"},"^journald(\\/.+)?$":true,"^k8scluster(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.k8sclusterreceiver.Config"},"^k8sevents(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.k8seventsreceiver.Config"},"^k8sobjects(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.k8sobjectsreceiver.Config"},"^kafka(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kafkareceiver.Config"},"^kafkametrics(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kafkametricsreceiver.Config"},"^kubeletstats(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.kubeletstatsreceiver.Config"},"^memcached(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.memcachedreceiver.Config"},"^mongodb(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbreceiver.Config"},"^mongodbatlas(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mongodbatlasreceiver.Config"},"^mysql(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.mysqlreceiver.Config"},"^nginx(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.nginxreceiver.Config"},"^opencensus(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.opencensusreceiver.Config"},"^oracledb(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.oracledbreceiver.Config"},"^otlpjsonfile(\\/.+)?$":true,"^podman(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.podmanreceiver.Config"},"^postgresql(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.postgresqlreceiver.Config"},"^prometheus(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.prometheusreceiver.Config"},"^prometheusexec(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.prometheusexecreceiver.Config"},"^pulsar(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.pulsarreceiver.Config"},"^rabbitmq(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.rabbitmqreceiver.Config"},"^receivercreator(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.receivercreator.Config"},"^redis(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.redisreceiver.Config"},"^simpleprometheus(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.simpleprometheusreceiver.Config"},"^sqlquery(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlqueryreceiver.Config"},"^sqlserver(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.sqlserverreceiver.Config"},"^statsd(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.statsdreceiver.Config"},"^syslog(\\/.+)?$":true,"^tcplog(\\/.+)?$":true,"^udplog(\\/.+)?$":true,"^zipkin(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zipkinreceiver.Config"},"^zookeeper(\\/.+)?$":{"$ref":"#/$defs/github.com.open-telemetry.opentelemetry-collector-contrib.receiver.zookeeperreceiver.Config"}},"type":"object"},"service":{"$ref":"#/$defs/go.opentelemetry.io.collector.service.Config"}},"required":["receivers","exporters","service"],"title":"OpenTelemetry Collector Config Schema","type":"object"}